{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtoolbox.transform as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## config(kernel使うときに変更すべき変数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "melanoma_external_malignant_256 = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/melanoma_external_malignant_256/\"\n",
    "SIIM_ISIC_Melanoma_Classification = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/SIIM-ISIC-Melanoma-Classification/\"\n",
    "Output = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/Output/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ加工部"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN(画像＋テーブル)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "train_concat&メタデータ込み：CV:0.974, LB:????<br>\n",
    "__ver2__<br>\n",
    "256*256：CV:0.885, LB:0.890<br>\n",
    "__verSN:1__<br>\n",
    "metaval:resizeのみ<br>\n",
    "192_192：OOF: 0.869 Wall time:  1h 33min LB: 0.861<br>\n",
    "224_224：OOF: 0.883 Wall time:  2h 07min LB: 0.862<br>\n",
    "256_256：OOF: 0.875 Wall time:  2h 36min LB: 0.882<br>\n",
    "382_382：OOF: 0.869 Wall time:  5h 10min LB: 0.854<br>\n",
    "512_512：OOF: 0.848 Wall time: 10h 29min LB: 0.852<br>\n",
    "__verSN:2__<br>\n",
    "metaval:metaの組み込み<br>\n",
    "64_64  ：OOF: 0.856 Wall time: 20min 50s LB: 0.852<br>\n",
    "256_256：OOF: 0.874 Wall time: 2h 31min 55s LB: 0.885<br>\n",
    "__verSN:3__<br>\n",
    "stackingに切り替え<br>\n",
    "64_64  ：OOF: 0.876 Wall time: 30min 59s    LB: 0.8779<br>\n",
    "128_128：OOF: 0.881 Wall time: about 50min  LB: 0.8756<br>\n",
    "192_192：OOF: 0.893 Wall time: 2h 10min 17s LB: 0.8813<br>\n",
    "224_224：OOF: 0.892 Wall time: 2h 41min 8s  LB: 0.8807<br>\n",
    "256_256：OOF: 0.897 Wall time: 3h 24min 25s LB: 0.8760<br>\n",
    "384_384：OOF: 0.872 Wall time: 7h 26min 48s LB: 0.8676<br>\n",
    "__verSN:4__<br>\n",
    "tfrecordによるfold + epoch20<br>\n",
    "64_64  ：OOF: 0.873 Wall time: 38min 15s    LB:0.8856 <br>\n",
    "96_96  ：OOF: 0.879 Wall time: 54min 34s    LB:0.8719 <br>\n",
    "128_128：OOF: 0.882 Wall time: 1h 20min 49s LB:0.8929 <br>\n",
    "160_160：OOF: 0.884 Wall time: 2h 8min 24s  LB:0.8678 <br>\n",
    "192_192：OOF: 0.885 Wall time: 不明         LB:0.8704 <br>\n",
    "__verSN:5__<br>\n",
    "2019データ<br>\n",
    "64_64  ：OOF: 0.903 Wall time: 30min 37s    LB:0.7135 <br>\n",
    "128_128：OOF: 0.924 Wall time: 不明         LB:0.7449 <br>\n",
    "__verSN:6__<br>\n",
    "train + malignant2019 merge<br>\n",
    "64_64  ：OOF: 0.821 Wall time: 24min 19s    LB:0.8924 <br>\n",
    "128_128：OOF: 0.891 Wall time: 1h 12min 48s LB:0.8891 <br>\n",
    "256_256：OOF: 0.900 Wall time: 4h 19min 32s LB:0.8857 <br>\n",
    "__verSN:7__<br>\n",
    "train + malignant2019 merge → BGR2GRAY<br>\n",
    "64_64  ：OOF: 0.812 Wall time: 27min        LB:0.8396 <br>\n",
    "128_128：OOF: 0.889 Wall time: 1h 5min 16s  LB:0.8633 <br>\n",
    "256_256：OOF: 0.897 Wall time: 3h 44min 52s LB:0.8523 <br>\n",
    "__verSN:8__<br>\n",
    "pad BGR2GRAY<br>\n",
    "64_64  ：OOF: 0.948 Wall time: 28min        LB:0.8758 <br>\n",
    "128_128：OOF: 0.959 Wall time: 1h 9min 39s  LB:0.8898 <br>\n",
    "256_256：OOF: 0.960 Wall time: 4h 37min 32s LB:0.9037 <br>\n",
    "__verSN:9__<br>\n",
    "pad ROTATE_90<br>\n",
    "64_64  ：OOF: 0.948 Wall time: 33min 23s    LB:0.8765 <br>\n",
    "128_128：OOF: 0.955 Wall time: 1h 13min 50s LB:0.8972 <br>\n",
    "256_256：OOF: 0.960 Wall time: 4h 35min 39s LB:0.8690 <br>\n",
    "__verSN:9__<br>\n",
    "train_roman<br>\n",
    "256_256：OOF: 0.976 Wall time: 5h 26min 26s LB:0.8339 <br>\n",
    "__verSN:10__<br>\n",
    "TTA: 公式testfile + ROTATE_270 + ROTATE_90<br>\n",
    "256_256 pad BGR2GRAY：OOF: ???? Wall time: 5h 26min 26s LB:???? <br>\n",
    "256_256 TrainRoman  ：OOF: ???? Wall time: 5h 26min 26s LB:???? <br>\n",
    "__verSN:11__<br>\n",
    "centerCrop + shades of Gray color constancy<br>\n",
    "64_64  ：OOF: 0.865 Wall time: 16min 23s    LB:0.8800 <br>\n",
    "256_256：OOF: 0.880 Wall time: 2h 2min 17s  LB:0.9058 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least fixing some random seeds. \n",
    "# It is still impossible to make results 100% reproducible when using GPU\n",
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, \n",
    "                 transforms = None,  meta_features = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description→学習に使わない\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n",
    "        x = cv2.imread(im_path)\n",
    "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
    "\n",
    "        if self.transforms:\n",
    "            #X_data_np = np.array(x)\n",
    "            #print(\"transfor前\")\n",
    "            #print(X_data_np.shape)\n",
    "            #y_data_np = np.array(y)\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.loc[index]['target']\n",
    "            #return (x, meta), y\n",
    "            #print(y)\n",
    "            #X_data_np = np.array(x)\n",
    "            #print(\"transform後\")\n",
    "            #print(X_data_np.shape)\n",
    "            #y_data_np = np.array(y)\n",
    "            #print(y_data_np.shape)\n",
    "            return (x, meta), y\n",
    "        else:\n",
    "            return (x, meta)\n",
    "            #return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, arch, n_meta_features: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        if 'ResNet' in str(arch.__class__):\n",
    "            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
    "        if 'EfficientNet' in str(arch.__class__):\n",
    "            self.arch._fc = nn.Linear(in_features=1280, out_features=500, bias=True)\n",
    "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
    "                                  nn.BatchNorm1d(500),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(500, 250),  # FC layer output will have 50 features\n",
    "                                  nn.BatchNorm1d(250),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2))\n",
    "        self.ouput = nn.Linear(500 + 250, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x, meta = inputs\n",
    "        cnn_features = self.arch(x)\n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.Cutout(scale=(0.05, 0.007), value=(0, 0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.Cutout(scale=(0.05, 0.007), value=(0, 0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableDataPreprocess2020(dt):\n",
    "    # One-hot encoding of anatom_site_general_challenge feature\n",
    "    concat = pd.concat([dt[0]['anatom_site_general_challenge'], dt[1]['anatom_site_general_challenge']], ignore_index=True)\n",
    "    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "    dt[0] = pd.concat([dt[0], dummies.iloc[:dt[0].shape[0]]], axis=1)\n",
    "    dt[1] = pd.concat([dt[1], dummies.iloc[dt[0].shape[0]:].reset_index(drop=True)], axis=1)\n",
    "    for df in dt:\n",
    "        df['sex'] = df['sex'].map({'male': 1, 'female': 0})\n",
    "        df['sex'] = df['sex'].fillna(-1)\n",
    "        df['age_approx'] /= df['age_approx'].max()\n",
    "        df['age_approx'] = df['age_approx'].fillna(0)\n",
    "        df['patient_id'] = df['patient_id'].fillna(0)\n",
    "    return dt\n",
    "\n",
    "def TableDataPreprocess2019(dt):\n",
    "    # One-hot encoding of anatom_site_general_challenge feature\n",
    "    concat = pd.concat([dt[0]['anatom_site_general_challenge'], dt[1]['anatom_site_general_challenge']], ignore_index=True)\n",
    "    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "    dt[0] = pd.concat([dt[0], dummies.iloc[:dt[0].shape[0]]], axis=1)\n",
    "    dt[1] = pd.concat([dt[1], dummies.iloc[dt[0].shape[0]:].reset_index(drop=True)], axis=1)\n",
    "    for df in dt:\n",
    "        df['sex'] = df['sex'].map({'male': 1, 'female': 0})\n",
    "        df['sex'] = df['sex'].fillna(-1)\n",
    "        df['age_approx'] /= df['age_approx'].max()\n",
    "        df['age_approx'] = df['age_approx'].fillna(0)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord = None):\n",
    "    \n",
    "    meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "    meta_features.remove('anatom_site_general_challenge')\n",
    "    \n",
    "    #sample_sub_metaval_stacking.csv用Imagename\n",
    "    ImgNm = train_df[['image_name']]\n",
    "    \n",
    "    \n",
    "    test = MelanomaDataset(df=test_df,\n",
    "                           imfolder = SIIM_ISIC_Melanoma_Classification + test_folder, \n",
    "                           train=False,\n",
    "                           transforms=test_transform,\n",
    "                           meta_features=meta_features)\n",
    "    oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "    \n",
    "    # We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "    # We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "    # since we only need `y` to stratify the data\n",
    "    # for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "    #for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=tfrecord['tfrecord'].tolist()), 1):\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        \n",
    "        best_val = None  # Best validation score within this fold\n",
    "        patience = es_patience  # Current patience counter\n",
    "        arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "        model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "        model = model.to(device)\n",
    "        \n",
    "        \n",
    "        optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True),  \n",
    "                                imfolder = SIIM_ISIC_Melanoma_Classification + train_folder, \n",
    "                                train=True, \n",
    "                                transforms=train_transform,\n",
    "                                meta_features=meta_features)\n",
    "        val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True),\n",
    "                              imfolder = SIIM_ISIC_Melanoma_Classification + train_folder,\n",
    "                              train=True,\n",
    "                              transforms=test_transform,\n",
    "                              meta_features=meta_features)\n",
    "    \n",
    "        train_loader = DataLoader(dataset=train, batch_size=bat_size[0], shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(dataset=val, batch_size=bat_size[1], shuffle=False, num_workers=2)\n",
    "        test_loader = DataLoader(dataset=test, batch_size=bat_size[2], shuffle=False, num_workers=2)\n",
    "        \n",
    "        del train, val\n",
    "        gc.collect()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            correct = 0\n",
    "            epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for x, y in train_loader:\n",
    "                x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "                x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "                y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "                \n",
    "                \n",
    "                optim.zero_grad()\n",
    "                z = model(x)\n",
    "                loss = criterion(z, y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "                correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "                \n",
    "            train_acc = correct / len(train_idx)\n",
    "    \n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "                val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "                val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "                \n",
    "                print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "                epoch + 1, \n",
    "                epoch_loss, \n",
    "                train_acc, \n",
    "                val_acc, \n",
    "                val_roc, \n",
    "                str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "                \n",
    "                scheduler.step(val_roc)\n",
    "                # During the first iteration (first epoch) best validation is set to None\n",
    "                if not best_val:\n",
    "                    best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                    torch.save(model, model_path)  # Saving the model\n",
    "                    continue\n",
    "                    \n",
    "                if val_roc >= best_val:\n",
    "                    best_val = val_roc\n",
    "                    patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                    torch.save(model, model_path)  # Saving current best model\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                    if patience == 0:\n",
    "                        print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                        break\n",
    "        \n",
    "        del train_loader, x, y\n",
    "        gc.collect()\n",
    "        \n",
    "        model = torch.load(model_path)  # Loading best model of this fold\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        test_preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test set\n",
    "        with torch.no_grad():\n",
    "            # Predicting on validation set once again to obtain data for OOF\n",
    "            for _ in range(TTA):\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "            val_preds /= TTA\n",
    "            oof[val_idx] = val_preds.cpu()\n",
    "            del val_loader, x_val, y_val\n",
    "            gc.collect()\n",
    "            \n",
    "            # Predicting on test set\n",
    "            for _ in range(TTA):\n",
    "                for i, x_test in enumerate(test_loader):\n",
    "                    x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                    x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                    z_test = model(x_test)\n",
    "                    z_test = torch.sigmoid(z_test)\n",
    "                    test_preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "            test_preds /= TTA\n",
    "            del test_loader, x_test, z_test\n",
    "            gc.collect()\n",
    "        \n",
    "    test_preds /= skf.n_splits\n",
    "    \n",
    "    print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))\n",
    "    \n",
    "    return test_preds, oof, ImgNm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exec_TTAmod_roman(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, test_imfolder, tfrecord = None):\n",
    "    \n",
    "    meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "    meta_features.remove('anatom_site_general_challenge')\n",
    "    \n",
    "    #sample_sub_metaval_stacking.csv用Imagename\n",
    "    ImgNm = train_df[['image_name']]\n",
    "    \n",
    "    oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "    test_preds = torch.zeros((len(test_df), 1), dtype=torch.float32, device=device)  # Predictions for test set\n",
    "    \n",
    "    # We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "    # We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "    # since we only need `y` to stratify the data\n",
    "    # for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "    #for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=tfrecord['tfrecord'].tolist()), 1):\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        \n",
    "        best_val = None  # Best validation score within this fold\n",
    "        patience = es_patience  # Current patience counter\n",
    "        arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "        model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "        model = model.to(device)\n",
    "        \n",
    "        \n",
    "        optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True),  \n",
    "                                imfolder = SIIM_ISIC_Melanoma_Classification + train_folder, \n",
    "                                train=True, \n",
    "                                transforms=train_transform,\n",
    "                                meta_features=meta_features)\n",
    "        val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True),\n",
    "                              imfolder = SIIM_ISIC_Melanoma_Classification + train_folder,\n",
    "                              train=True,\n",
    "                              transforms=test_transform,\n",
    "                              meta_features=meta_features)\n",
    "    \n",
    "        train_loader = DataLoader(dataset=train, batch_size=bat_size[0], shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(dataset=val, batch_size=bat_size[1], shuffle=False, num_workers=2)\n",
    "        \n",
    "        del train, val\n",
    "        gc.collect()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            correct = 0\n",
    "            epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for x, y in train_loader:\n",
    "                x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "                x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "                y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "                \n",
    "                \n",
    "                optim.zero_grad()\n",
    "                z = model(x)\n",
    "                loss = criterion(z, y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "                correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "                \n",
    "            train_acc = correct / len(train_idx)\n",
    "    \n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "                val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "                val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "                \n",
    "                print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "                epoch + 1, \n",
    "                epoch_loss, \n",
    "                train_acc, \n",
    "                val_acc, \n",
    "                val_roc, \n",
    "                str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "                \n",
    "                scheduler.step(val_roc)\n",
    "                # During the first iteration (first epoch) best validation is set to None\n",
    "                if not best_val:\n",
    "                    best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                    torch.save(model, model_path)  # Saving the model\n",
    "                    continue\n",
    "                    \n",
    "                if val_roc >= best_val:\n",
    "                    best_val = val_roc\n",
    "                    patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                    torch.save(model, model_path)  # Saving current best model\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                    if patience == 0:\n",
    "                        print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                        break\n",
    "        \n",
    "        del train_loader, x, y\n",
    "        gc.collect()\n",
    "        \n",
    "        model = torch.load(model_path)  # Loading best model of this fold\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Predicting on validation set once again to obtain data for OOF\n",
    "            for _ in range(TTA):\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "            val_preds /= TTA\n",
    "            oof[val_idx] = val_preds.cpu()\n",
    "            del val_loader, x_val, y_val\n",
    "            gc.collect()\n",
    "            \n",
    "            # Predicting on test set   \n",
    "            test_preds_tmp = torch.zeros((len(test_df), 1), dtype=torch.float32, device=device)\n",
    "            for pth in test_imfolder:\n",
    "                test = MelanomaDataset(df=test_df,\n",
    "                                       imfolder = pth, \n",
    "                                       train=False,\n",
    "                                       transforms=test_transform,\n",
    "                                       meta_features=meta_features)\n",
    "                test_loader = DataLoader(dataset=test, batch_size=bat_size[2], shuffle=False, num_workers=2)\n",
    "                \n",
    "                for i, x_test in enumerate(test_loader):\n",
    "                    x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                    x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                    z_test = model(x_test)\n",
    "                    z_test = torch.sigmoid(z_test)\n",
    "                    test_preds_tmp[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "                \n",
    "                del test_loader, x_test, z_test\n",
    "                gc.collect()\n",
    "            \n",
    "            test_preds_tmp /= len(test_imfolder)\n",
    "            test_preds = test_preds + test_preds_tmp\n",
    "            \n",
    "            del test_preds_tmp\n",
    "            \n",
    "    test_preds /= skf.n_splits\n",
    "    \n",
    "    print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))\n",
    "    \n",
    "    return test_preds, oof, ImgNm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, test_imfolder, arch, tfrecord = None):\n",
    "    \n",
    "    meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "    meta_features.remove('anatom_site_general_challenge')\n",
    "    \n",
    "    #sample_sub_metaval_stacking.csv用Imagename\n",
    "    ImgNm = train_df[['image_name']]\n",
    "    \n",
    "    oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "    test_preds = torch.zeros((len(test_df), 1), dtype=torch.float32, device=device)  # Predictions for test set\n",
    "    \n",
    "    # We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "    # We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "    # since we only need `y` to stratify the data\n",
    "    # for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=tfrecord['tfrecord'].tolist()), 1):\n",
    "    #for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        \n",
    "        best_val = None  # Best validation score within this fold\n",
    "        patience = es_patience  # Current patience counter\n",
    "        model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "        model = model.to(device)\n",
    "        \n",
    "        \n",
    "        optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True),  \n",
    "                                imfolder = SIIM_ISIC_Melanoma_Classification + train_folder, \n",
    "                                train=True, \n",
    "                                transforms=train_transform,\n",
    "                                meta_features=meta_features)\n",
    "        val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True),\n",
    "                              imfolder = SIIM_ISIC_Melanoma_Classification + train_folder,\n",
    "                              train=True,\n",
    "                              transforms=test_transform,\n",
    "                              meta_features=meta_features)\n",
    "    \n",
    "        train_loader = DataLoader(dataset=train, batch_size=bat_size[0], shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(dataset=val, batch_size=bat_size[1], shuffle=False, num_workers=2)\n",
    "        \n",
    "        del train, val\n",
    "        gc.collect()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            correct = 0\n",
    "            epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for x, y in train_loader:\n",
    "                x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "                x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "                y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "                \n",
    "                \n",
    "                optim.zero_grad()\n",
    "                z = model(x)\n",
    "                loss = criterion(z, y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "                correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "                \n",
    "            train_acc = correct / len(train_idx)\n",
    "    \n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "                val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "                val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "                \n",
    "                print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "                epoch + 1, \n",
    "                epoch_loss, \n",
    "                train_acc, \n",
    "                val_acc, \n",
    "                val_roc, \n",
    "                str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "                \n",
    "                scheduler.step(val_roc)\n",
    "                # During the first iteration (first epoch) best validation is set to None\n",
    "                if not best_val:\n",
    "                    best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                    torch.save(model, model_path)  # Saving the model\n",
    "                    continue\n",
    "                    \n",
    "                if val_roc >= best_val:\n",
    "                    best_val = val_roc\n",
    "                    patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                    torch.save(model, model_path)  # Saving current best model\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                    if patience == 0:\n",
    "                        print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                        break\n",
    "        \n",
    "        del train_loader, x, y\n",
    "        gc.collect()\n",
    "        \n",
    "        model = torch.load(model_path)  # Loading best model of this fold\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Predicting on validation set once again to obtain data for OOF\n",
    "            #for _ in range(TTA):\n",
    "            for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                z_val = model(x_val)\n",
    "                val_pred = torch.sigmoid(z_val)\n",
    "                val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "            #val_preds /= TTA\n",
    "            oof[val_idx] = val_preds.cpu()\n",
    "            del val_loader, x_val, y_val\n",
    "            gc.collect()\n",
    "            \n",
    "            # Predicting on test set\n",
    "            test_preds_tmp = torch.zeros((len(test_df), 1), dtype=torch.float32, device=device)\n",
    "            for pth in test_imfolder:\n",
    "                test = MelanomaDataset(df=test_df,\n",
    "                                       imfolder = pth, \n",
    "                                       train=False,\n",
    "                                       transforms=test_transform,\n",
    "                                       meta_features=meta_features)\n",
    "                test_loader = DataLoader(dataset=test, batch_size=bat_size[2], shuffle=False, num_workers=2)\n",
    "                \n",
    "                for i, x_test in enumerate(test_loader):\n",
    "                    x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                    x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                    z_test = model(x_test)\n",
    "                    z_test = torch.sigmoid(z_test)\n",
    "                    test_preds_tmp[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "                \n",
    "                del test_loader, x_test, z_test\n",
    "                gc.collect()\n",
    "            \n",
    "            test_preds_tmp /= len(test_imfolder)\n",
    "            test_preds = test_preds + test_preds_tmp\n",
    "            \n",
    "            del test_preds_tmp\n",
    "            \n",
    "    test_preds /= skf.n_splits\n",
    "    \n",
    "    print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))\n",
    "    \n",
    "    return test_preds, oof, ImgNm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initData2020(Pre = None):\n",
    "    #train(train+2019malig)\n",
    "    train_malig = pd.read_csv(SIIM_ISIC_Melanoma_Classification + \"train_malig_2.csv\")\n",
    "    train_malig = train_malig[train_malig.tfrecord != -1]\n",
    "    train_malig = train_malig.drop(['diagnosis', 'benign_malignant', 'width', 'height', 'source', 'ext'], axis=1)\n",
    "    train_malig = train_malig.reset_index(drop=True)\n",
    "    tfrecord_malig = train_malig.loc[:,['tfrecord']]\n",
    "    tfrecord_malig = tfrecord_malig-15\n",
    "    \n",
    "    \n",
    "    train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train.csv')\n",
    "    train_df = train_df.drop(['diagnosis','benign_malignant'], axis=1)\n",
    "    train_df = train_df[train_df.tfrecord != -1]\n",
    "    train_df = train_df.drop(['width','height','patient_code'], axis=1)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    tfrecord = train_df.loc[:,['tfrecord']]\n",
    "    \n",
    "    #concate(train+2019malig)\n",
    "    train_df = pd.concat([train_df, train_malig], axis=0)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    \n",
    "    #padding (malignantOnly)\n",
    "    #train_pad = train_df[train_df.target == 1]\n",
    "    #train_pad = train_pad.reset_index(drop=True)\n",
    "    #train_pad[['image_name']] = Pre + '_' + train_pad[['image_name']]\n",
    "    #tfrecord_pad = train_pad.loc[:,['tfrecord']]\n",
    "    \n",
    "    #concate(train+2019malig) + BGR2GRAY(malignantOnly)\n",
    "    #train_df = pd.concat([train_df, train_pad], axis=0)\n",
    "    \n",
    "    #tfrecord concate\n",
    "    train_df = train_df.drop(['tfrecord'], axis=1)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    #tfrecord = pd.concat([tfrecord, tfrecord_malig, tfrecord_pad], axis=0)\n",
    "    tfrecord = pd.concat([tfrecord, tfrecord_malig], axis=0)\n",
    "    tfrecord = tfrecord.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #test\n",
    "    test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "    \n",
    "    return train_df, test_df, tfrecord\n",
    "\n",
    "def initData2019():\n",
    "    train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train_2019year.csv')\n",
    "    train_df = train_df.drop(['diagnosis','benign_malignant'], axis=1)\n",
    "    train_df = train_df[train_df.tfrecord != -1]\n",
    "    train_df = train_df.drop(['width','height'], axis=1) \n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    tfrecord = train_df.loc[:,['tfrecord']]\n",
    "    train_df = train_df.drop(['tfrecord'], axis=1)\n",
    "    \n",
    "    test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "    \n",
    "    train_df = train_df.drop(['patient_id'], axis=1)\n",
    "    test_df = test_df.drop(['patient_id'], axis=1)\n",
    "    \n",
    "    return train_df, test_df, tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 105.389 | Train acc: 0.968 | Val acc: 0.925 | Val roc_auc: 0.968 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 86.870 | Train acc: 0.974 | Val acc: 0.954 | Val roc_auc: 0.966 | Training time: 0:04:29\n",
      "Epoch 003: | Loss: 79.274 | Train acc: 0.976 | Val acc: 0.959 | Val roc_auc: 0.970 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 76.450 | Train acc: 0.977 | Val acc: 0.954 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 75.616 | Train acc: 0.978 | Val acc: 0.960 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 69.669 | Train acc: 0.979 | Val acc: 0.962 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 70.591 | Train acc: 0.978 | Val acc: 0.961 | Val roc_auc: 0.974 | Training time: 0:04:29\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 55.526 | Train acc: 0.982 | Val acc: 0.967 | Val roc_auc: 0.980 | Training time: 0:04:29\n",
      "Epoch 009: | Loss: 51.126 | Train acc: 0.983 | Val acc: 0.968 | Val roc_auc: 0.980 | Training time: 0:04:30\n",
      "Epoch 010: | Loss: 46.464 | Train acc: 0.985 | Val acc: 0.967 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 41.471 | Train acc: 0.986 | Val acc: 0.966 | Val roc_auc: 0.980 | Training time: 0:04:30\n",
      "Early stopping. Best Val roc_auc: 0.980\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 116.327 | Train acc: 0.965 | Val acc: 0.974 | Val roc_auc: 0.964 | Training time: 0:04:29\n",
      "Epoch 002: | Loss: 93.323 | Train acc: 0.972 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 86.927 | Train acc: 0.974 | Val acc: 0.979 | Val roc_auc: 0.955 | Training time: 0:04:30\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 68.229 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 61.471 | Train acc: 0.980 | Val acc: 0.981 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 57.277 | Train acc: 0.981 | Val acc: 0.981 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 52.690 | Train acc: 0.983 | Val acc: 0.981 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch 008: | Loss: 50.132 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 37.470 | Train acc: 0.987 | Val acc: 0.980 | Val roc_auc: 0.979 | Training time: 0:04:30\n",
      "Epoch 010: | Loss: 34.839 | Train acc: 0.988 | Val acc: 0.980 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Epoch 011: | Loss: 31.267 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "Epoch    11: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 012: | Loss: 30.125 | Train acc: 0.989 | Val acc: 0.979 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Early stopping. Best Val roc_auc: 0.979\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 111.378 | Train acc: 0.966 | Val acc: 0.970 | Val roc_auc: 0.952 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 93.753 | Train acc: 0.971 | Val acc: 0.969 | Val roc_auc: 0.957 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 83.949 | Train acc: 0.974 | Val acc: 0.968 | Val roc_auc: 0.949 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 80.229 | Train acc: 0.975 | Val acc: 0.974 | Val roc_auc: 0.966 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 74.499 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.964 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 73.860 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.966 | Training time: 0:04:30\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 58.241 | Train acc: 0.981 | Val acc: 0.969 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch 008: | Loss: 51.324 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.972 | Training time: 0:04:30\n",
      "Epoch 009: | Loss: 47.658 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 40.667 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.974 | Training time: 0:04:30\n",
      "Epoch 011: | Loss: 38.597 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch 012: | Loss: 36.084 | Train acc: 0.987 | Val acc: 0.975 | Val roc_auc: 0.973 | Training time: 0:04:29\n",
      "Epoch    12: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 013: | Loss: 34.468 | Train acc: 0.988 | Val acc: 0.976 | Val roc_auc: 0.974 | Training time: 0:04:30\n",
      "Epoch 014: | Loss: 34.256 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch    14: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 015: | Loss: 33.635 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.973 | Training time: 0:04:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0bf389c76bd6>\u001b[0m in \u001b[0;36mExec_TTAmod\u001b[0;34m(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, test_imfolder, tfrecord)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# round off sigmoid to obtain predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#trainRoman\n",
    "model_name = \"train_roman\"\n",
    "train_folder = \"jpeg/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"256_256\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"256_256_BGR2GRAY\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"256_256_ROTATE_90\"]\n",
    "\n",
    "#データ整形\n",
    "#train_df, test_df, tfrecord = initData2020()\n",
    "train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train_roman.csv')\n",
    "test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod_roman(epochs, model_path, es_patience, TTA, bat_size, train_df, \n",
    "                                                          test_df, test_imfolder)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 80.691 | Train acc: 0.977 | Val acc: 0.894 | Val roc_auc: 0.914 | Training time: 0:04:16\n",
      "Epoch 002: | Loss: 67.538 | Train acc: 0.982 | Val acc: 0.875 | Val roc_auc: 0.866 | Training time: 0:04:14\n",
      "Epoch 003: | Loss: 66.132 | Train acc: 0.981 | Val acc: 0.898 | Val roc_auc: 0.915 | Training time: 0:04:15\n",
      "Epoch 004: | Loss: 62.295 | Train acc: 0.983 | Val acc: 0.897 | Val roc_auc: 0.925 | Training time: 0:04:08\n",
      "Epoch 005: | Loss: 63.013 | Train acc: 0.982 | Val acc: 0.893 | Val roc_auc: 0.917 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 60.156 | Train acc: 0.983 | Val acc: 0.900 | Val roc_auc: 0.933 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 59.891 | Train acc: 0.983 | Val acc: 0.897 | Val roc_auc: 0.922 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 56.821 | Train acc: 0.983 | Val acc: 0.897 | Val roc_auc: 0.941 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 60.950 | Train acc: 0.982 | Val acc: 0.898 | Val roc_auc: 0.935 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 57.960 | Train acc: 0.983 | Val acc: 0.897 | Val roc_auc: 0.944 | Training time: 0:04:06\n",
      "Epoch 011: | Loss: 56.684 | Train acc: 0.983 | Val acc: 0.901 | Val roc_auc: 0.948 | Training time: 0:04:06\n",
      "Epoch 012: | Loss: 55.253 | Train acc: 0.983 | Val acc: 0.898 | Val roc_auc: 0.933 | Training time: 0:04:06\n",
      "Epoch 013: | Loss: 55.105 | Train acc: 0.983 | Val acc: 0.898 | Val roc_auc: 0.927 | Training time: 0:04:06\n",
      "Epoch    13: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 014: | Loss: 51.392 | Train acc: 0.983 | Val acc: 0.899 | Val roc_auc: 0.935 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 91.152 | Train acc: 0.971 | Val acc: 0.981 | Val roc_auc: 0.894 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 75.529 | Train acc: 0.977 | Val acc: 0.980 | Val roc_auc: 0.901 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 66.465 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.898 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 64.704 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.913 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 64.947 | Train acc: 0.980 | Val acc: 0.982 | Val roc_auc: 0.911 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 59.564 | Train acc: 0.980 | Val acc: 0.982 | Val roc_auc: 0.911 | Training time: 0:04:06\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 52.428 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.914 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 48.142 | Train acc: 0.984 | Val acc: 0.981 | Val roc_auc: 0.915 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 45.438 | Train acc: 0.983 | Val acc: 0.982 | Val roc_auc: 0.917 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 42.194 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.908 | Training time: 0:04:07\n",
      "Epoch 011: | Loss: 41.050 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.915 | Training time: 0:04:07\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 35.585 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.912 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.917\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.727 | Train acc: 0.972 | Val acc: 0.983 | Val roc_auc: 0.883 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 75.373 | Train acc: 0.976 | Val acc: 0.981 | Val roc_auc: 0.896 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 70.506 | Train acc: 0.979 | Val acc: 0.982 | Val roc_auc: 0.909 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 66.186 | Train acc: 0.979 | Val acc: 0.982 | Val roc_auc: 0.914 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 65.710 | Train acc: 0.979 | Val acc: 0.982 | Val roc_auc: 0.902 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 66.079 | Train acc: 0.979 | Val acc: 0.982 | Val roc_auc: 0.917 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 61.459 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.918 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 61.960 | Train acc: 0.980 | Val acc: 0.981 | Val roc_auc: 0.919 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 58.920 | Train acc: 0.981 | Val acc: 0.982 | Val roc_auc: 0.925 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 58.190 | Train acc: 0.980 | Val acc: 0.982 | Val roc_auc: 0.916 | Training time: 0:04:06\n",
      "Epoch 011: | Loss: 57.160 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.922 | Training time: 0:04:07\n",
      "Epoch    11: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 012: | Loss: 47.712 | Train acc: 0.983 | Val acc: 0.982 | Val roc_auc: 0.926 | Training time: 0:04:07\n",
      "Epoch 013: | Loss: 43.755 | Train acc: 0.984 | Val acc: 0.982 | Val roc_auc: 0.932 | Training time: 0:04:07\n",
      "Epoch 014: | Loss: 41.637 | Train acc: 0.984 | Val acc: 0.982 | Val roc_auc: 0.933 | Training time: 0:04:07\n",
      "Epoch 015: | Loss: 37.593 | Train acc: 0.986 | Val acc: 0.980 | Val roc_auc: 0.926 | Training time: 0:04:07\n",
      "Epoch 016: | Loss: 34.856 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.931 | Training time: 0:04:07\n",
      "Epoch    16: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 017: | Loss: 31.961 | Train acc: 0.988 | Val acc: 0.979 | Val roc_auc: 0.928 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.933\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.801 | Train acc: 0.971 | Val acc: 0.974 | Val roc_auc: 0.883 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 70.141 | Train acc: 0.978 | Val acc: 0.955 | Val roc_auc: 0.874 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 64.712 | Train acc: 0.980 | Val acc: 0.974 | Val roc_auc: 0.881 | Training time: 0:04:06\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 53.078 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.910 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 50.211 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.910 | Training time: 0:04:06\n",
      "Epoch 006: | Loss: 47.560 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.917 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 44.981 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.908 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 42.985 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.914 | Training time: 0:04:07\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 36.151 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.916 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.917\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.957 | Train acc: 0.972 | Val acc: 0.980 | Val roc_auc: 0.876 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 74.042 | Train acc: 0.977 | Val acc: 0.978 | Val roc_auc: 0.885 | Training time: 0:04:07\n",
      "Epoch 003: | Loss: 68.395 | Train acc: 0.979 | Val acc: 0.982 | Val roc_auc: 0.905 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 69.313 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.903 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 64.711 | Train acc: 0.979 | Val acc: 0.980 | Val roc_auc: 0.904 | Training time: 0:04:06\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 53.979 | Train acc: 0.982 | Val acc: 0.982 | Val roc_auc: 0.920 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 50.181 | Train acc: 0.983 | Val acc: 0.982 | Val roc_auc: 0.924 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 48.045 | Train acc: 0.983 | Val acc: 0.982 | Val roc_auc: 0.913 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 45.868 | Train acc: 0.983 | Val acc: 0.981 | Val roc_auc: 0.917 | Training time: 0:04:06\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 40.154 | Train acc: 0.985 | Val acc: 0.982 | Val roc_auc: 0.916 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.924\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0bf389c76bd6>\u001b[0m in \u001b[0;36mExec_TTAmod\u001b[0;34m(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, test_imfolder, tfrecord)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Predicting on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Predictions for test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         test = MelanomaDataset(df=test_df,\n\u001b[1;32m    136\u001b[0m                                \u001b[0mimfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_256_256_merge_BGR2GRAY(malignantOnly)  TTA有り\n",
    "model_name = \"PADDING_256_256_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"256_256\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"256_256_BGR2GRAY\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"256_256_ROTATE_90\"]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.784 | Train acc: 0.964 | Val acc: 0.972 | Val roc_auc: 0.931 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 19.195 | Train acc: 0.976 | Val acc: 0.977 | Val roc_auc: 0.930 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.203 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.934 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.051 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 14.926 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.934 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 14.691 | Train acc: 0.980 | Val acc: 0.975 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 12.473 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.945\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 27.025 | Train acc: 0.965 | Val acc: 0.972 | Val roc_auc: 0.932 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 19.063 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 19.061 | Train acc: 0.975 | Val acc: 0.975 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.072 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.961 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.950 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 15.789 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:00:30\n",
      "Epoch 007: | Loss: 15.346 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.946 | Training time: 0:00:30\n",
      "Epoch 008: | Loss: 14.984 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.955 | Training time: 0:00:29\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 12.443 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:00:29\n",
      "Epoch 010: | Loss: 11.660 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:00:29\n",
      "Epoch 011: | Loss: 10.796 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.956 | Training time: 0:00:29\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 9.314 | Train acc: 0.986 | Val acc: 0.976 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.966\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.004 | Train acc: 0.966 | Val acc: 0.974 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.243 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.921 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 16.948 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.929 | Training time: 0:00:29\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 14.755 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Epoch 005: | Loss: 13.502 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:30\n",
      "Epoch 006: | Loss: 12.845 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 11.911 | Train acc: 0.983 | Val acc: 0.974 | Val roc_auc: 0.934 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 11.869 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 9.971 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.946\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.227 | Train acc: 0.963 | Val acc: 0.974 | Val roc_auc: 0.914 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.830 | Train acc: 0.974 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.879 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.244 | Train acc: 0.976 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.013 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.173 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.471 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.391 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.535 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 11.099 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 10.353 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 9.374 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch    12: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 013: | Loss: 8.043 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.951\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.991 | Train acc: 0.965 | Val acc: 0.973 | Val roc_auc: 0.891 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 18.498 | Train acc: 0.977 | Val acc: 0.965 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.738 | Train acc: 0.978 | Val acc: 0.974 | Val roc_auc: 0.916 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.284 | Train acc: 0.978 | Val acc: 0.968 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 15.180 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.529 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 13.063 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 11.925 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.951\n",
      "OOF: 0.950\n",
      "CPU times: user 20min 45s, sys: 3min 36s, total: 24min 22s\n",
      "Wall time: 25min 42s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り\n",
    "arch = EfficientNet.from_pretrained('efficientnet-b1')  # Going to use efficientnet-b0 NN architecture\n",
    "skf = GroupKFold(n_splits=5)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64\" + \"_BGR2GRAY\"]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 27.019 | Train acc: 0.961 | Val acc: 0.972 | Val roc_auc: 0.931 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.108 | Train acc: 0.975 | Val acc: 0.974 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.411 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.876 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.621 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.315 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 13.064 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.943\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.767 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.634 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.645 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.849 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.516 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.548 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 12.453 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.962 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.657 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.958 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 10.184 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.958 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.964\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.468 | Train acc: 0.963 | Val acc: 0.975 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.461 | Train acc: 0.975 | Val acc: 0.978 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.619 | Train acc: 0.978 | Val acc: 0.967 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.612 | Train acc: 0.978 | Val acc: 0.971 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.514 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 14.830 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.202 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.256 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.094 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.640 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 9.268 | Train acc: 0.986 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 8.893 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 7.892 | Train acc: 0.988 | Val acc: 0.974 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 014: | Loss: 6.711 | Train acc: 0.990 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.949\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 27.368 | Train acc: 0.963 | Val acc: 0.972 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.782 | Train acc: 0.977 | Val acc: 0.969 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.326 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 15.886 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.058 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.359 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.111 | Train acc: 0.980 | Val acc: 0.967 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.253 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 11.345 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.950\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.001 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.927 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.326 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.534 | Train acc: 0.978 | Val acc: 0.974 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.270 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.970 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.494 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 12.679 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 11.475 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.954\n",
      "OOF: 0.949\n",
      "CPU times: user 19min 23s, sys: 3min 28s, total: 22min 51s\n",
      "Wall time: 24min 11s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り　(元のテストフォルダのみ設定)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\"]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "##test用submit\n",
    "#api = KaggleApi()\n",
    "#api.authenticate()  # 認証を通す\n",
    "#csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "#message = 'Imgprocessing Stacking' + model_name\n",
    "#competition_id = 'siim-isic-melanoma-classification'\n",
    "#api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.111 | Train acc: 0.966 | Val acc: 0.975 | Val roc_auc: 0.927 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 19.039 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.085 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.408 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.589 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.001 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 11.605 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.207 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 10.074 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.944\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 24.993 | Train acc: 0.967 | Val acc: 0.972 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.452 | Train acc: 0.976 | Val acc: 0.971 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.066 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.956 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.752 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.467 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 14.807 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.696 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 15.162 | Train acc: 0.981 | Val acc: 0.968 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 12.423 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.967 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.887 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 9.822 | Train acc: 0.985 | Val acc: 0.976 | Val roc_auc: 0.962 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 8.289 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.967\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.916 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.923 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.610 | Train acc: 0.976 | Val acc: 0.970 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.135 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.158 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.104 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 14.851 | Train acc: 0.980 | Val acc: 0.975 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.186 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.174 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.992 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 9.999 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 8.844 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.946\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.948 | Train acc: 0.965 | Val acc: 0.973 | Val roc_auc: 0.912 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.813 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 18.362 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.738 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.806 | Train acc: 0.979 | Val acc: 0.970 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.286 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.909 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.841 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.480 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.714 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 9.001 | Train acc: 0.986 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.952\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.217 | Train acc: 0.965 | Val acc: 0.972 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.635 | Train acc: 0.977 | Val acc: 0.966 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.140 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.910 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.460 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.952 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 13.493 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 12.851 | Train acc: 0.982 | Val acc: 0.975 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 12.249 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 10.649 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.954\n",
      "OOF: 0.951\n",
      "CPU times: user 21min 20s, sys: 3min 48s, total: 25min 9s\n",
      "Wall time: 26min 35s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXgc1Z3u8e9RS92tXbYlr7KRbWyDAwSDQtgJu5MQTIDJsCSBQEKYuVknzzDJzXMns+TeZOZmskwWJ4QkwA3DEhImDjOQAAFMYjAWtjEGYxtj40WSJdvat9Zy7h/VLcuyll6q1dVd7+d5+il1d6nqZ1l6dXTq1DnGWouIiGSfvEwXICIiyVGAi4hkKQW4iEiWUoCLiGQpBbiISJbKn8qTVVZW2pqamqk8pYhI1nvllVcOWWurRr8+pQFeU1NDXV3dVJ5SRCTrGWPeGet1daGIiGQpBbiISJZSgIuIZCkFuIhIllKAi4hkKQW4iEiWUoCLiGQpBbiISJZSgAOsPh9e/mmmqxARSYgCvK8DDr4GW3+T6UpERBKiAO9odLb7N0CkO7O1iIgkQAHeXu9sh/ph3/rM1iIikgAFeKwFDrB7bebqEBFJ0KQBboz5uTGmyRizdcRr/9cY86YxZosx5jFjTEV6y0yjjgZnO/NdsOeFzNYiIpKAeFrg9wIrR732FHCKtfY0YAfwFZfrmjodjRAshWUr4cBG56KmiEgWmDTArbVrgSOjXvuDtXYg+vQloDoNtU2NjnoonQ01F4AdhL0vZboiEZG4uNEHfhvwxHhvGmPuMMbUGWPqmpubXTidyzoanQCf/17IK4Ddz2e6IhGRuKQU4MaYrwIDwAPj7WOtvdtaW2utra2qOm5FoMzraICyuRAsgur3wG71g4tIdkg6wI0xtwBXATdba617JU0ha4+2wAFqzofGLRoPLiJZIakAN8asBP4OuNpam71p130EBiNQOsd5Xl4Ndgi6D2e2LhGROMQzjPBB4EVgmTFmvzHmduAHQCnwlDFmszHmx2muMz1iQwhjLfDC6GjI3rbM1CMikoBJV6W31t44xss/S0MtUy92E0/pXGcbjgV4a2bqERFJgL/vxByvBd6jABcR7/N5gMda4NEAD5c7W7XARSQL+DzA66FwOuSHnOdhtcBFJHv4PMAbnTHgMaEywKgFLiJZwecB3nC0+wQgL8/pRlELXESygM8DvPHYAAfnQqZa4CKSBfwb4IMD0Hnw6E08MeEKjQMXkazg3wDvanbuuhwd4IUV6kIRkazg3wAfHgM+VgtcAS4i3ufjAB81BjxGFzFFJEv4OMCjixmP1YXS2+rMVCgi4mH+DfCuQ862eNQc5eEKZ4bC/p6pr0lEJAH+DfC+DigohsCo+bwKNaGViGQHfwd4qOT413U7vYhkCX8HeHCMANec4CKSJfwb4JFOCJUe/7rmBBeRLOHfAO8bJ8A1J7iIZAkfB3iHWuAiktX8G+CRcfrAY4s6qAUuIh7n3wAfbxRKXsCZF1wtcBHxOB8H+Dh94OB0o6gFLiIe588AH4jAYB8ExwnwwnINIxQRz/NngEc6ne1ELXB1oYiIx/kzwPs6nO1YfeCgOcFFJCtMGuDGmJ8bY5qMMVtHvDbdGPOUMWZndDstvWW6LBbgY41CAbXARSQrxNMCvxdYOeq1LwPPWGuXAM9En2ePybpQ1AIXkSwwaYBba9cCR0a9vAq4L/rxfcA1LteVXn2T9YGXw0APDPRNXU0iIglKtg98lrW2ASC6nTnejsaYO4wxdcaYuubm5iRP57K+dmc7URcKqBUuIp6W9ouY1tq7rbW11traqqqqyT9hKkzahRLt0lc/uIh4WLIBftAYMwcgum1yr6QpMNkolLCmlBUR70s2wNcAt0Q/vgX4rTvlTJFYH/i4N/KoC0VEvC+eYYQPAi8Cy4wx+40xtwPfBC43xuwELo8+zx6RDsgvPH45tRjNSCgiWWCcBDvKWnvjOG9d6nItU2e8iaxi1AIXkSzg0zsxJ5jICo5OKasWuIh4mE8DfJy5wGMCBc6K9WqBi4iH+TPAI53OnN8TCZcdHS8uIuJB/gzwyfrAwWmhx8aLi4h4kH8DfKIuFHD6yGPjxUVEPMifAR6Z5CImOC30PrXARcS7/BngcXWhlKoLRUQ8zX8BPjgAA72TX8QMlagLRUQ8zX8BHplkMYeYkFrgIuJt/gvwySayigmqBS4i3ubDAJ9kKtmYUAkMRpwV7EVEPMiHAR7rQpkkwGPvqxtFRDzKfwEeibMLJdZCVzeKiHiU/wI8kS4UUICLiGf5MMDjHIUSe19dKCLiUf4L8MnWw4wZ7kJRgIuIN/kvwOPtQhlugasLRUS8yYcB3g6BkDPn90R0EVNEPM5/AR7PRFYw4iKmulBExJv8F+DxTGQFGgcuIp7nwwCPswUeyIf8sLpQRMSz/Bfgkc7J78KM0aIOIuJh/gvwvvb4ulBAy6qJiKf5MMDj7EIBrcojIp6WUoAbY75ojHndGLPVGPOgMSbsVmFpE896mDFalUdEPCzpADfGzAM+B9Raa08BAsANbhWWNvEOIwT1gYuIp6XahZIPFBpj8oEioD71ktJoaBD6u+NvgWtZNRHxsKQD3Fp7APgWsBdoANqstX9wq7C0GJ4HRRcxRST7pdKFMg1YBSwE5gLFxpiPjrHfHcaYOmNMXXNzc/KVuiHS5WzjboGX6iKmiHhWKl0olwG7rbXN1tp+4DfAuaN3stbeba2ttdbWVlVVpXA6FyQa4MES6O9yul5ERDwmlQDfC5xtjCkyxhjgUmCbO2WlSbwLGseEdDu9iHhXKn3g64FHgY3Aa9Fj3e1SXekx3AIvjm9/TWglIh6Wn8onW2u/BnzNpVrSL9aSjjfAtSqPiHiYv+7EHG6BJzAOHNQCFxFP8lmAJ9gCHw7w9vTUIyKSAn8FeJ+6UEQkd/grwBMeB66LmCLiXT4L8A5nkYZAnNdutSqPiHiYzwK8K/7WN2hhYxHxNB8GeJz93wD5IcjLV4CLiCf5K8D7OhNrgRujCa1ExLP8FeCRzvhvo4/RhFYi4lH+C/BEulDACfCIulBExHt8FuAJXsQEZ3/1gYuIBynAJ6OFjUXEo/wV4H0diXeh6CKmiHiUvwI80qWLmCKSM/wT4AN9MNSf3EVM9YGLiAf5J8ATnUo2JljijEKx1v2aRERS4KMAT3AmwphQCdgh6O9xvyYRkRT4J8ATnUo2RvOhiIhH+SfAY10ooQS7UEJlzlYBLiIe46MAjwZwwi3waID3trlbj4hIinwU4Aku5hATLne2fQpwEfEWHwZ4gi3wcKwFrnUxRcRb/BPgsT7shG+lj/WBK8BFxFv8E+DDFzET7UJRC1xEvMlHAd4JGCgoSuzzgqXO56kFLiIek1KAG2MqjDGPGmPeNMZsM8ac41ZhrovNRGhMYp+Xl+cMPVQLXEQ8Js7l2cf1PeBJa+31xpggkGDzdgols5hDTKhMwwhFxHOSDnBjTBlwIXArgLU2AkTcKSsN+lII8HC5ulBExHNS6UJZBDQDvzDGbDLG3GOMOS4hjTF3GGPqjDF1zc3NKZwuRclMJRsTVgtcRLwnlQDPB84AVltrVwBdwJdH72StvdtaW2utra2qqkrhdClKZjWemFCZWuAi4jmpBPh+YL+1dn30+aM4ge5NkSRW44kJl+kipoh4TtIBbq1tBPYZY5ZFX7oUeMOVqtJBLXARyTGpjkL5LPBAdATK28AnUi8pTVK6iBntA7c28WGIIiJpklKAW2s3A7Uu1ZJeka7Ep5KNCZXB0ICzqEPQuyMlRcRf/HEnprWpjQMfnpFQ3Sgi4h3+CPD+bsCmHuC6kCkiHuKPAE92LvAYzUgoIh7kjwBPdirZmLBW5RER7/FHgCc7lWyMWuAi4kH+CvBUhhGCWuAi4ik+CfBOZ5tqH7guYoqIhyjA4xEsAZOnLhQR8RR/BHhfLMCT7ELRog4i4kH+CPDhi5hJ3okJENKc4CLiLT4J8BRb4KAZCUXEc/wT4Hn5EAgmfwzNSCgiHuOPAO9tc26HT2UmwXAZ9La6V5OISIr8FeCpCKkLRUS8RQEeLy1sLCIeowCPV+wiprXu1CQikiKfBHi7O10odjA6Na2ISOb5JMBdaoGD+sFFxDMU4PEKaUIrEfGW3A/wgT4Y6HHnIiboQqaIeEbuB3isyyNckdpxNCOhiHiMDwI82uXhWgtcXSgi4g0K8HjpIqaIeIwPAjx6+7tbFzHVBy4iHpFygBtjAsaYTcaYx90oyHVutcCDxWACaoGLiGe40QL/PLDNheOkh1sBbkx0UQf1gYuIN6QU4MaYauCDwD3ulJMGbgU4QOE06GlJ/TgiIi5ItQX+XeAuYGi8HYwxdxhj6owxdc3NzSmeLgm9bc5c4AVFqR+ruAq6D6V+HBERFyQd4MaYq4Ama+0rE+1nrb3bWltrra2tqqpK9nTJc2Mu8JjiKujMwC8hEZExpNICPw+42hizB3gIuMQY80tXqnKTG7fRxxRXQpcCXES8IekAt9Z+xVpbba2tAW4A/mit/ahrlbnF1QCPdqEMjdtjJCIyZXwwDtzFAC+ZCXZIFzJFxBNcCXBr7XPW2qvcOJbr3O5CAehqcud4IiIpUAs8EcXRi7DqBxcRD1CAJ0IBLiIektsB7tZc4DHDAa6x4CKSebkd4G7NBR5TOB1MnlrgIuIJOR7gLt5GD5CXB0WV0KmLmCKSeQrwRBVXqQtFRDwhxwPcpbnAR9LdmCLiETke4OlqgSvARSTzFOCJKpmpABcRT1CAJ6q4EiKdEOl275giIknI/QB3ay7wmNhYcM0LLiIZlvsB7tZc4DG6G1NEPMIfAe4m3Y0pIh6Rn+kC0sqFAK9v7eH5Hc28uq+VLfvbOKmwhW8DtvMgLrbrRUQSpgCfwFtNHVz7o3W09w5QXljAadXl1DU4f7Tc93QdC4qu5JKTZrlVrYhIQnI/wMvmJPWpzR193PqLDQTzA/z3587h5DmlGGPoGxik/xuFFPe3cNu9dXz2khP54mVLyctTe1xEplbuB3gSLfDuyAC337eBw50RHv702SyfWzb8Xig/AKUzubY6xAaq+f4f32JbQwff+ct3UxoucLN6EZEJ6SLmGL70yKtsPdDG929cwWnVY8xkWFxFoPsQ/3Ldafzj1e/i2e1NXL/6RRrbel0oWkQkPrkb4AMRZy7wUGIBvnFvC09sbeRvLl/KZcvH6d+O3o1pjOGWc2u47xNncaC1h+tWr2P3oS4XihcRmVzuBnhsnHbxjIQ+7UfP7qKiqIBPnLdw/J1GTWh1/pJKHvzU2fT2D3L96nVsPdCWTMUiIgnJ3QDvaHC2pXPj/pTtjR08ve0gt55bQ3FogssDsSllh4aGXzq1upxf3XkO4YIAf/mTF1m7Qzf6iEh65W6At9c72wRGofz4+V0UBQPcem7NxDsWV4EdPDpdbdSiqhJ+/VfnMn96Ebfdu4FH6vYlWLSISPxyN8A7Gp1taXwBvu9IN2tereemsxZQURSceOfS2c62bf9xb80uD/OrO8/hnMUzuOvRLXz7qR0MDdlEKhcRiUsOB3g95BU4S6DF4e61b5Nn4JMXLJp85xknOtvDO8d8uzRcwM9vfQ9/cWY1//7MTj51fx1t3f3xVi4iEpekA9wYM98Y86wxZpsx5nVjzOfdLCxl7Q1OSzlv8n9iW08/j9Tt49oV1cwuD09+7OmLne3hXePuUhDI41+vd4YZrt3ZzFU/eEEXN0XEVam0wAeAL1lrTwbOBv6HMWa5O2W5oKPhaFfHJJ54rYG+gSFueu+C+I4dLIKyajg0dgs8JjbM8OFPn8PAoOXaH63j+8/sJDIwNOHniYjEI+kAt9Y2WGs3Rj/uALYB89wqLGUdDXH3fz+26QCLKos5rTqBMeOVJ47bhTLaGQum8V+fu4Ar3jWLf3tqBx/6/p/YtLcl/nOJiIzBlT5wY0wNsAJY78bxXNHeAGWTDyHc39LN+t1H+PCKeZhE5g2fsQQOvQU2vguU04uD/OCmM/jpx2tp6+nn2tXr+MJDm9h7WCv7iEhyUp4LxRhTAvwa+IK1tn2M9+8A7gBYsCDOLopU9XVApCOuLpTfbnaGG16zIsE/HiqXOOfobILS+GckvHz5LM5eNJ0fPruLe9ft5vEtDdxw1nw+feFi5k93ceUgEcl5KbXAjTEFOOH9gLX2N2PtY62921pba62traqqSuV08RseQjhxC9xay2ObDvCemmmJh+ckI1EmUhou4MvvP4nn//ZibjhrPg+9vI/3fes5PvMfG9myv3XyA4iIkNooFAP8DNhmrf22eyW5IM6beF6vb+etpk4+vKI68XPEAnySC5kTmVUW5uvXnMoLf3cxnzx/Ic9vb+bqH/yZ61avY82r9brYKSITSqUFfh7wMeASY8zm6OMDLtWVmjhv4vnNxgMEA3l88NQk5gwvnw/5YTj8VhIFHmtOeSFf+cDJrPvKJfyvq5ZzuLOPzz24ifP+5Y989+kdNHf0pXwOEck9SfeBW2v/BB5dVawj2gKfIMAHBodY82o9l5w0k/KiJObxzstzxoOn0AIfrTRcwO3nL+QT59bw/M5m7lu3h+8+vZMfPbuLD717Lp+8YCEnzymb/EAi4gu5uaBDRyOEyiBUMu4u63Yd5lBnH9esiH+yq+NUngiNW5P//HHk5RkuXjaTi5fNZFdzJ/ev28OvXtnPrzfu58KlVXz6wkWcu3hGYqNmRCTn5Oat9O31k45AWfNqPaWhfN63bGby55mxBFr2OHOPp8niqhL+cdUpvPiVS7lr5TLeqG/n5nvWs+qHf+bJrY2aZ0XEx3IzwCe5iae3f5Dfb23kinfNJlwQSP48M050ZiVs2ZP8MeJUXljAX7/vRP70dxfzfz58Kq3d/dz5y1dY+b21PLZpPwODuuAp4jc5GuCNEwb4c9ub6egb4OrTU+g+AWcsOCQ1lDBZ4YIAN713AX/80kV874bTAfjiw6/yvm89x/0v7qEnMjhltYhIZuVegA8NOS3wCYYQ/u7VemYUBzlvcWKr9RxneCx46iNREpUfyGPV6fN48vMXcs/Ha5lZGuLvf/s653zzGb7xxDb2HdEdniK5LvcuYnYfgqGBcW/i6ewb4OltB/lI7XzyAyn+/iqscBZ3aN6R2nFSkJdnuGz5LC49eSYb9rTwiz/v5p4XdvPTtW9z0dIqrlkxj8tOnjXxCkMikpVy76d6eCm1sS9iPvVGI30DQ6xKtfskpvo9sHutMydKBkeFGGM4a+F0zlo4nfrWHh5Y/w6PbTzA5x/aTGFBgEtOmsmFSyu5YEkVcysKM1aniLgn9wK8PRrg40xktWZzPfMqCjljwTR3zrf0Stj+39D8Jsw82Z1jpmhuRSF/e+VJfOnyZdS908J/bj7AM9sO8l+vOV+bmhlFnD6/gtOqKzitupxls0spDScxFl5EMir3AnyCm3iOdEV4Yechbr9gIXl5LrWWl1zhbHc86ZkAj8nLO9oqt9ecws6mTtbuaObl3Ud46e0j/Gd0Ii+A6mmFnDS7lGWzS1k6q5STZpexuKo49W4mEUmbHAzwRsBAyfHjux99ZR8DQ5brzkhi7pPxlM2F2afCjj/A+V9077guM8awdJYTzrFl4xrbetl6oI3tBzt4s7GDNxvaeW57MwPRseWh/DxOmlPGKXPLePf8Cs5YUMGiyhL3fvmJSEpyL8Cbt0PFfAgc2yUwNGR5YP1ezqqZztJZpe6ec8mV8KfvQE8LFLrUNTMFZpeHmV0e5rLlR6fD7RsY5O3mLt5sbOf1A+1srW9jzeZ6Hli/F4DScD4rFkzjzAXTOPOEabx7frm6X0QyJPcCfH8dLHjvcS//edch3jnczd9cvtT9cy69El74Frz1DJx6vfvHn0Kh/AAnzynj5DllfHiF89rQkOXtQ51s2tvKpn2tbHynhe8+s2P4uu2SmSWsmD+NU6rLOWWu87kp3SAlInHJrQBvr4f2/VD92ePeeuClvUwvDrLylPjWyUzIvDOhaAbs+H3WB/hY8vIMJ84s5cSZpfxF7XwA2nv72by3NRrqLTz5eiMP1+1z9jdQU1nMkpklLJlZyqKqYmoqi1k4o5hpxcFM/lNEckpuBfj+Dc62+j3HvNzY1stT2w7yyQsWEspPQ8swLwAnXg47/wBDg87zHFcWLuDCpVVcuNRZpMNay/6WHl6vb+eN+jZ2HOxkZ1MHT29rYnDEfC1l4XxOmFHMCTOKqJkRDfbKYhZVKtxFEpV7AR4IORcVR3h4wz4Ghyw3nZXGJd2WvR+2PARv/BZOuTZ95/EoYwzzpxcxf3rRMX/lRAaG2NfSzZ5DXew+1MU7h7t550g3rx1o44mtjceE+/TiIIsqi1lcVcLimc52UVUJ1dMKKdBoGJHj5FiA18Gcd0P+0ZbcwOAQD768lwuXVnHCjOL0nfvkD8GsU+CprzlhXqCbZQCC+XlOIFcdP7Vv/+AQ+450szsa7ruaO9nV1MXT2w7ycN3RGR4DeYbqaYUsmF5E9bRC5pYXMqeikKrSEJUlQapKQlQUBQnmK+TFX3InwAf7oX4T1N5+zMuPbTpAY3sv/7TqXek9f14AVn4T7rsK1n0fLrorvefLAQWBPBZFW9mjtXZH2NXshPrew93sOdzF3iPdbGto51Dn2NP3FgUDTCsKUl5YQHlhARVFBUwrDjIj+phVFmZWeZg55WFmloYJaDhkegwNwb71sPXXkJcPp9/oNKzEdbkT4I2vwUAvVNcOv9TVN8C//n47KxZUcPny+FeOT9rCC2D5Knjh23D6TVDu4nhzn6koCnLmCUHOPOH4YZm9/YM0tvVyqLOPQ519NHdGaOuO0NLdT0t3hPaeflq7+9nZ1ElLV4SW7gijp00PBvKcVv2MIqcPvqqExVXFnFhVQlVpSItlJOuddfDYndD6DuQXgh2C9audAL9mNcxKc0PKZ3InwPfXOdsRFzBXP7eL5o4+fvKxM6fuB/Lyf4btT8JvPwM3PqiulDQIFwSoqXQugMZjcMjS2h3hYHsfje09NLT1su9ID3uPOH3yL+8+QveIaXhLw/mcONPp9llYWczi6CiaBdOLKArmzo+M67Y9Do/e5jRcPvwTOOmDzsRyrz0Ka78F934QPvprZ9SWuCJ3vhv3b3Bun4+2eve3dHP3C29zzelz3Zv3JB7TToAP/hus+Sz88jq48SEIax3LTArkGWaUhJhREmL53OP/L6y1NLb38lZTJ283d/FWUydvNXXyws5mHn1l/zH7VpaEOGGG0xfvPIqYV1HI3IpC5lUUUhjM/RFIY3rlXnj8izD3DLjpESgeMVXzWZ+CEy+D+1fBfavgpoeh5ryMlZpLcivAq2uHZwT85hNvkmfgrpUnTX0tZ3zMaXk/9mmnT/zae6AqDTcQiSuMMcwpL2ROeSEXLKk65r3OvgF2N3cN98G/E91u3NvC41sajhlFAzCtqCB6LKe/fXaZ85hVHmZWWYjZZWHKCwtyq4tm4/3wu887Q2k/ch8Ex/jLaPpCuO1JuP8a+I+PwC2/g3lnTH2tOSY3Arx5O7TshtpPAPD71xt5fEsDn790SeamTj31egiVwqO3w+pznIurF90FxZWZqUeSUhLK59Tqck6tLj/uvYHBIRrbe6lv7aW+tYcDrT00tPXQ0NpLfVsvm/a1cqTr+Auuwfy84TCfHQv7sjBzy8PMqShkbkWYyuJQdsw5s+URWPM5WHwp3PAA5IfG37dsLtyyBn52OTxwPdz2B2dhcEmasXbqFsWtra21dXV17h/4l9c7V70/u5E/NRhuu3cDJ88p5aE7zsn8n7SdzfDs/4aN9zlX5Je9H06/GRZeBAXhzNYmadfbP0hTex9NHb00tvfS2NZLU0cfB6MfH2zvpaGtl76BY9c0DQbymFMRZm55IfOmxbpowsOt+9nl4czPQbPxfvjdF+CEc51uk2BRfJ93eBf87AooKIJP/BdUpPH+jBxhjHnFWlt73OtZH+A7n3J+m1/xdV6ZdzMfvedlFkwv4qE7zvbWnX3N251+wi0PQ/dhyA/DgnOg5nznT8k5p0PR9ExXKRlgraW1u5/64da705qvb+3lQEs39a29HOzoZfSPalEwQFVpiKqSENOLg0wrClJR7AyhLA3lUxLOpyRUQHEwQHEon+JQPqVh51FYEEi+G2doEJ76e3jxB7DoYvjLX0Lo+KGgE6rf5PSHFxTCzb+COaclV4tP5GaAD/bD6nOxQ4M8edFj3PXYm8woDvLInecws9SjrduBCOx+Hnb9EXY9C83bjr5XMtvpK5++2JlRsXwBlM6CkllQVOks4eaD2/TleP2DQzS2Oa34hrZeGlp7aOroo7nDad23dDlDKFu7+4kMDk16vIKAobwwyLToWPmqkuhNUaUhZkb77WdHu3bKwvlHw77xNfj9V53v4bPugCu/AYEke2KbtjkX+nvb4S9+AUsuT+44PpCWADfGrAS+BwSAe6y135xof9cD/KXV8OSX+XrZ17inaRnLZpXys1trqZ4W559yXtDTAvWboWGzs7bmoe1wZDf0HBl7/3A5hCuckS3hCqefPVQW3ZY422CJcyEpWAwFsW3hiNeKnG0gmNFl4MR91lr6Bobo6B2gs2+Azt4BuiIDdPU5zzt6nUd7bz+t3RFauvo50h1xxtN39NHRO3DcMacHB7isaBerzPOc1/McvYFSNi77Au3Lb2ZWWZiZZWGqSkLJ3QnbXu90gTa9Dss+AJf9A1QtS/nrkGtcD3BjTADYAVwO7Ac2ADdaa98Y73OSDfD+wSFauiIc6oxwuKuPPYe6qHunhSVv/YKlfVv5WuH/5ItXLOO6M6pz5+66vk5oPwCdB6GzCboOOWHfcwR6244++jqcFkxfO0Q6nXG38TKBaNgXHQ32gkLnkR92LkgFQs7c6nn5zsPkRR/G2TLi6x37ZRB775hHwNnmRT/OCxz7+vAxjXPMY7Yc+1rc/z5z7PmHz50fPX/g2HowR+s4ehBgop+RkbWO+nfEnh9z3An+jcM/i9b52A6BHXS6LOyg83xoKPr6iMfof/Por1vseMPHHXGsoQHnMRiBwQj9PZ10drTS03aIoda9FLTvY0bHm+TbCL2EeCRwFd/tWS7viVIAAAWmSURBVMmRoeNHmkwrKqCyJMSMkqCzLQ5SUeS08suLCigNFVAadrpyCoMBCgsChAsC5A/1ULjxHvLXfQciXZh5Z8Ki9zn3dJTNdRYoL5ru68ZGOgL8HOAfrLVXRp9/BcBa+43xPifZAP/yr7fw0IZ9x7w2szTEe2qmc+7i6Vx35nzNPw3OD+dAL0S6IdLhbPu7IdJ1dDvy4+Nei+7f3+McZzAS3Q7AUP+xQWIZFR6jQgLr7D9yK9kjLx/K5jkXGGefBosvcS5WBosYGrIc7opwsN25COt04zhdOYc6IsN3yB7pitA+Rot+PNNo5+OBp7gwsIV3m13km6PfX18bup1HrLN84WQ5PjLS7IjvOzd6i0ee24xoTIxX08iXf/yxM48bphr/ed0P8OuBldbaT0affwx4r7X2M6P2uwO4I/p0GbA9qROmVyVwKNNFxEm1podqTQ/V6o4TrLXHpX8q48DH+p1z3G8Da+3dwN0pnCftjDF1Y/128yLVmh6qNT1Ua3qlMv/mfmD+iOfVQP04+4qIiMtSCfANwBJjzEJjTBC4AVjjTlkiIjKZpLtQrLUDxpjPAL/HGUb4c2vt665VNrU83cUzimpND9WaHqo1jab0Rh4REXGP1qASEclSCnARkSzlqwA3xqw0xmw3xrxljPnyGO+HjDEPR99fb4ypmfoqh2uZrNa/Mca8YYzZYox5xhhzQibqjNYyYa0j9rveGGONMRkbqhVPrcaYj0S/tq8bY/5jqmscUcdk3wMLjDHPGmM2Rb8PPpCJOqO1/NwY02SM2TrO+8YY8+/Rf8sWY0xGJgOPo86bo/VtMcasM8Z4ezFPa60vHjgXWncBi4Ag8CqwfNQ+fw38OPrxDcDDHq71YqAo+vFfebnW6H6lwFrgJaDWq7UCS4BNwLTo85kervVu4K+iHy8H9mSi1uj5LwTOALaO8/4HgCdw7h85G1jv0TrPHfF///5M1Rnvw08t8LOAt6y1b1trI8BDwKpR+6wC7ot+/ChwqcnM0imT1mqtfdZa2x19+hLOOPxMiOfrCvDPwL8CvVNZ3Cjx1Pop4IfW2hYAa23TFNcYE0+tFoitEVdOBu/DsNauBcaZgQ1war/fOl4CKowxc6amuqMmq9Nauy72f09mf67i4qcAnweMnFBlf/S1Mfex1g4AbcAMpl48tY50O07rJhMmrdUYswKYb619fCoLG0M8X9elwFJjzJ+NMS9FZ9zMhHhq/Qfgo8aY/cB/A5+dmtKSkuj3tBdk8ucqLrmxpFp84rn1P67pAaZA3HUYYz4K1AIXpbWi8U1YqzEmD/gOcOtUFTSBeL6u+TjdKO/DaX29YIw5xVrbmubaRoun1huBe621/xadXO7/RWudfELwqeeVn624GGMuxgnw8zNdy0T81AKP59b/4X2MMfk4f5ZO9GdhusQ1TYEx5jLgq8DV1tq+KapttMlqLQVOAZ4zxuzB6f9ck6ELmfF+D/zWWttvrd2NM/nakimqb3Qdk9V6O/AIgLX2RSCMMyGTF2XN1BvGmNOAe4BV1trDma5nIn4K8Hhu/V8D3BL9+HrgjzZ6NWOKTVprtFviJzjhnal+WpikVmttm7W20lpbY62twelXvNpam4bFUVOrNeo/cS4QY4ypxOlSeXtKq3TEU+te4FIAY8zJOAHePKVVxm8N8PHoaJSzgTZrbUOmixrNGLMA+A3wMWvtjkzXM6lMX0WdygfOlfAdOFf3vxp97Z9wAgWcH4BfAW8BLwOLPFzr08BBYHP0scartY7a9zkyNAolzq+rAb4NvAG8Btzg4VqXA3/GGaGyGbgig7U+CDQA/Tit7duBO4E7R3xdfxj9t7yWqe+BOOq8B2gZ8XNVl6mvaTwP3UovIpKl/NSFIiKSUxTgIiJZSgEuIpKlFOAiIllKAS4ikqUU4CIiWUoBLiKSpf4/5gydrf1F7r4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り　(元のテストフォルダのみ設定)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_90\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_90\",]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "##test用submit\n",
    "#api = KaggleApi()\n",
    "#api.authenticate()  # 認証を通す\n",
    "#csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "#message = 'Imgprocessing Stacking' + model_name\n",
    "#competition_id = 'siim-isic-melanoma-classification'\n",
    "#api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.485 | Train acc: 0.966 | Val acc: 0.975 | Val roc_auc: 0.923 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.601 | Train acc: 0.976 | Val acc: 0.973 | Val roc_auc: 0.931 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.373 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.420 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.716 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.107 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 12.751 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.310 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.385 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.296 | Train acc: 0.985 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 8.923 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.404 | Train acc: 0.968 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.442 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.454 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.071 | Train acc: 0.979 | Val acc: 0.969 | Val roc_auc: 0.966 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.375 | Train acc: 0.980 | Val acc: 0.975 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 16.278 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 13.395 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.966\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.852 | Train acc: 0.964 | Val acc: 0.965 | Val roc_auc: 0.926 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.179 | Train acc: 0.977 | Val acc: 0.968 | Val roc_auc: 0.921 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 16.673 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.142 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.245 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.763 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.623 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.121 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.945\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.272 | Train acc: 0.966 | Val acc: 0.973 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.412 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.924 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.559 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.323 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.925 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.331 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.540 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 12.461 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.497 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.978 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 9.207 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.956 | Train acc: 0.965 | Val acc: 0.971 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.069 | Train acc: 0.978 | Val acc: 0.971 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.481 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.180 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.027 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 12.705 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 11.880 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 10.571 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.956\n",
      "OOF: 0.950\n",
      "CPU times: user 18min 20s, sys: 3min 12s, total: 21min 32s\n",
      "Wall time: 22min 46s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り　(元のテストフォルダのみ設定)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_BGR2GRAY\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_BGR2GRAY\",]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "##test用submit\n",
    "#api = KaggleApi()\n",
    "#api.authenticate()  # 認証を通す\n",
    "#csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "#message = 'Imgprocessing Stacking' + model_name\n",
    "#competition_id = 'siim-isic-melanoma-classification'\n",
    "#api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.582 | Train acc: 0.963 | Val acc: 0.975 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.826 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.965 | Train acc: 0.977 | Val acc: 0.977 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 15.970 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.798 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 16.888 | Train acc: 0.977 | Val acc: 0.977 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.125 | Train acc: 0.980 | Val acc: 0.968 | Val roc_auc: 0.932 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.811 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.548 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.942 | Training time: 0:00:29\n",
      "Epoch 010: | Loss: 10.844 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 9.470 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.636 | Train acc: 0.966 | Val acc: 0.975 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.974 | Train acc: 0.977 | Val acc: 0.968 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.464 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.493 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.825 | Train acc: 0.980 | Val acc: 0.975 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.547 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.240 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 11.869 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.725 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.034 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 9.126 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 7.804 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.963\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.584 | Train acc: 0.965 | Val acc: 0.964 | Val roc_auc: 0.912 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.704 | Train acc: 0.977 | Val acc: 0.973 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.007 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.369 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.558 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.927 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.737 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.666 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.102 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.927 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 12.017 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.951\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.895 | Train acc: 0.965 | Val acc: 0.975 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.404 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.709 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.771 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.021 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.011 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 13.137 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.627 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.968 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 9.771 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.944\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.498 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.456 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.549 | Train acc: 0.977 | Val acc: 0.973 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.733 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.875 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 14.747 | Train acc: 0.981 | Val acc: 0.973 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 12.817 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.309 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.369 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 9.812 | Train acc: 0.985 | Val acc: 0.975 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.956\n",
      "OOF: 0.949\n",
      "CPU times: user 22min 4s, sys: 3min 48s, total: 25min 52s\n",
      "Wall time: 27min 19s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り　(元のテストフォルダのみ設定)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_90\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_270\"]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "##test用submit\n",
    "#api = KaggleApi()\n",
    "#api.authenticate()  # 認証を通す\n",
    "#csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "#message = 'Imgprocessing Stacking' + model_name\n",
    "#competition_id = 'siim-isic-melanoma-classification'\n",
    "#api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 28.726 | Train acc: 0.960 | Val acc: 0.971 | Val roc_auc: 0.926 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.153 | Train acc: 0.975 | Val acc: 0.977 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.711 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.119 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.399 | Train acc: 0.979 | Val acc: 0.973 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.085 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.597 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 13.851 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.927 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 11.547 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.203 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 9.488 | Train acc: 0.986 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 8.533 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 7.672 | Train acc: 0.988 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 014: | Loss: 7.183 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch    14: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 015: | Loss: 7.267 | Train acc: 0.988 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.137 | Train acc: 0.966 | Val acc: 0.970 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 19.386 | Train acc: 0.975 | Val acc: 0.975 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 16.582 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.189 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.662 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 14.809 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.956 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.713 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.524 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.965 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 11.109 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 10.685 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.965 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 9.017 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 9.039 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 8.157 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.962 | Training time: 0:00:29\n",
      "Epoch    13: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 014: | Loss: 7.675 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.963 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.966\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.470 | Train acc: 0.964 | Val acc: 0.973 | Val roc_auc: 0.920 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.799 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.939 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.135 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.031 | Train acc: 0.978 | Val acc: 0.971 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.332 | Train acc: 0.980 | Val acc: 0.974 | Val roc_auc: 0.935 | Training time: 0:00:28\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.132 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 11.890 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.273 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 10.456 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 9.943 | Train acc: 0.985 | Val acc: 0.975 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 8.093 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 27.566 | Train acc: 0.962 | Val acc: 0.972 | Val roc_auc: 0.929 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 19.382 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.629 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.324 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.498 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 15.264 | Train acc: 0.980 | Val acc: 0.975 | Val roc_auc: 0.942 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 14.400 | Train acc: 0.981 | Val acc: 0.971 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 11.874 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.949\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.635 | Train acc: 0.965 | Val acc: 0.969 | Val roc_auc: 0.918 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 19.092 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.939 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.286 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.283 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.921 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.279 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:29\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.581 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "OOF: 0.949\n",
      "CPU times: user 23min 45s, sys: 3min 58s, total: 27min 44s\n",
      "Wall time: 29min 14s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)  TTA有り　(元のテストフォルダのみ設定)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + \"64_64\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_90\",\n",
    "                 SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test_agm/\" + \"64_64_ROTATE_270\"]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259k/259k [00:03<00:00, 83.8kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.877 | Train acc: 0.964 | Val acc: 0.974 | Val roc_auc: 0.925 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.488 | Train acc: 0.976 | Val acc: 0.978 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 16.740 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.789 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.104 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 14.957 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.933 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 15.052 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 14.803 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.939 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 13.653 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 010: | Loss: 13.263 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:29\n",
      "Epoch 011: | Loss: 12.652 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.940 | Training time: 0:00:29\n",
      "Epoch    11: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 012: | Loss: 10.363 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 013: | Loss: 8.605 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:00:29\n",
      "Epoch 014: | Loss: 7.603 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 015: | Loss: 6.945 | Train acc: 0.989 | Val acc: 0.973 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch    15: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 016: | Loss: 5.558 | Train acc: 0.991 | Val acc: 0.975 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.768 | Train acc: 0.966 | Val acc: 0.974 | Val roc_auc: 0.935 | Training time: 0:00:30\n",
      "Epoch 002: | Loss: 18.830 | Train acc: 0.976 | Val acc: 0.976 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.815 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.407 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.959 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.851 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.955 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 15.739 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.960 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 14.986 | Train acc: 0.981 | Val acc: 0.973 | Val roc_auc: 0.962 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 14.223 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.959 | Training time: 0:00:29\n",
      "Epoch 009: | Loss: 14.718 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:00:29\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 010: | Loss: 11.488 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:00:29\n",
      "Epoch 011: | Loss: 10.712 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:00:30\n",
      "Epoch 012: | Loss: 9.422 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch    12: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 013: | Loss: 8.589 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.966\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.670 | Train acc: 0.965 | Val acc: 0.972 | Val roc_auc: 0.913 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.945 | Train acc: 0.977 | Val acc: 0.968 | Val roc_auc: 0.934 | Training time: 0:00:30\n",
      "Epoch 003: | Loss: 17.983 | Train acc: 0.977 | Val acc: 0.971 | Val roc_auc: 0.935 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 17.524 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.935 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.356 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.945 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 16.173 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.931 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 14.646 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.924 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 11.365 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:00:30\n",
      "Epoch 010: | Loss: 10.951 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.939 | Training time: 0:00:29\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 9.849 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 9.335 | Train acc: 0.985 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 8.942 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:00:29\n",
      "Epoch    13: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 014: | Loss: 8.557 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.160 | Train acc: 0.965 | Val acc: 0.971 | Val roc_auc: 0.931 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.672 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.990 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.856 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.929 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.263 | Train acc: 0.979 | Val acc: 0.970 | Val roc_auc: 0.931 | Training time: 0:00:29\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.635 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 12.726 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 11.720 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 10.434 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.873 | Train acc: 0.967 | Val acc: 0.972 | Val roc_auc: 0.936 | Training time: 0:00:30\n",
      "Epoch 002: | Loss: 19.225 | Train acc: 0.977 | Val acc: 0.973 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.626 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.030 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 15.676 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 16.026 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.666 | Train acc: 0.980 | Val acc: 0.974 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.026 | Train acc: 0.981 | Val acc: 0.972 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 13.679 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 010: | Loss: 10.864 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "OOF: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281k/281k [00:02<00:00, 109kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 49s, sys: 4min 47s, total: 30min 36s\n",
      "Wall time: 32min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"64_64\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [127, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.672 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.928 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 18.408 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.589 | Train acc: 0.977 | Val acc: 0.972 | Val roc_auc: 0.932 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.706 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.138 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 13.286 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 12.605 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 12.364 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 11.697 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 10.545 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.946\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 24.880 | Train acc: 0.968 | Val acc: 0.975 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 18.668 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.767 | Train acc: 0.978 | Val acc: 0.967 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.420 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.436 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.086 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.380 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.284 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 14.266 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.958 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 13.767 | Train acc: 0.982 | Val acc: 0.975 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 13.628 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 12.658 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 12.098 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch    13: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 014: | Loss: 10.499 | Train acc: 0.986 | Val acc: 0.980 | Val roc_auc: 0.962 | Training time: 0:00:28\n",
      "Epoch 015: | Loss: 8.247 | Train acc: 0.988 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Epoch 016: | Loss: 7.377 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 017: | Loss: 6.594 | Train acc: 0.990 | Val acc: 0.973 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 018: | Loss: 6.344 | Train acc: 0.990 | Val acc: 0.977 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 019: | Loss: 5.607 | Train acc: 0.992 | Val acc: 0.978 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 020: | Loss: 5.203 | Train acc: 0.993 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.120 | Train acc: 0.967 | Val acc: 0.977 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.488 | Train acc: 0.977 | Val acc: 0.977 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.390 | Train acc: 0.979 | Val acc: 0.958 | Val roc_auc: 0.911 | Training time: 0:00:28\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 15.411 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 13.816 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.221 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 007: | Loss: 12.165 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.659 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 009: | Loss: 11.322 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 11.203 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 11.256 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 012: | Loss: 11.293 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 24.774 | Train acc: 0.968 | Val acc: 0.973 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.763 | Train acc: 0.976 | Val acc: 0.976 | Val roc_auc: 0.929 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 18.163 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 15.406 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 14.010 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.144 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 007: | Loss: 12.120 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.949\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.178 | Train acc: 0.967 | Val acc: 0.967 | Val roc_auc: 0.914 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.696 | Train acc: 0.976 | Val acc: 0.972 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.651 | Train acc: 0.978 | Val acc: 0.973 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.799 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.994 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.792 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.637 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.016 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 14.475 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 13.373 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 12.920 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 012: | Loss: 9.888 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 8.813 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 014: | Loss: 8.068 | Train acc: 0.988 | Val acc: 0.974 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch    14: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 015: | Loss: 6.876 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF: 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282k/282k [00:05<00:00, 56.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 17s, sys: 4min 46s, total: 31min 3s\n",
      "Wall time: 33min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_64_64_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"64_64\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [127, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.032 | Train acc: 0.972 | Val acc: 0.962 | Val roc_auc: 0.930 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 33.780 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 32.439 | Train acc: 0.978 | Val acc: 0.980 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 29.797 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.947 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 28.804 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.759 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:01:15\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 23.448 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.949 | Training time: 0:01:14\n",
      "Epoch 008: | Loss: 20.699 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch 009: | Loss: 19.018 | Train acc: 0.985 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch 010: | Loss: 17.695 | Train acc: 0.987 | Val acc: 0.974 | Val roc_auc: 0.947 | Training time: 0:01:16\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.572 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.951 | Training time: 0:01:14\n",
      "Epoch 012: | Loss: 12.875 | Train acc: 0.990 | Val acc: 0.978 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Epoch 013: | Loss: 11.805 | Train acc: 0.991 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:01:14\n",
      "Epoch 014: | Loss: 11.324 | Train acc: 0.991 | Val acc: 0.977 | Val roc_auc: 0.953 | Training time: 0:01:14\n",
      "Epoch 015: | Loss: 10.261 | Train acc: 0.992 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch    15: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 016: | Loss: 8.907 | Train acc: 0.993 | Val acc: 0.976 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.554 | Train acc: 0.972 | Val acc: 0.972 | Val roc_auc: 0.938 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.433 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 31.661 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 33.129 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.961 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 30.326 | Train acc: 0.980 | Val acc: 0.980 | Val roc_auc: 0.967 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.272 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.963 | Training time: 0:01:14\n",
      "Epoch 007: | Loss: 28.235 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.400 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.969 | Training time: 0:01:14\n",
      "Epoch 009: | Loss: 20.450 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.968 | Training time: 0:01:14\n",
      "Epoch 010: | Loss: 18.052 | Train acc: 0.986 | Val acc: 0.976 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.651 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.969\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.167 | Train acc: 0.970 | Val acc: 0.977 | Val roc_auc: 0.924 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 32.737 | Train acc: 0.979 | Val acc: 0.973 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 31.603 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 29.660 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.934 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 29.193 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.935 | Training time: 0:01:14\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 23.019 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.009 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Epoch 008: | Loss: 18.119 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.948 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 15.317 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.959\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.295 | Train acc: 0.971 | Val acc: 0.970 | Val roc_auc: 0.934 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.470 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 31.976 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 30.258 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 28.737 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 23.106 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.086 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 18.181 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 14.286 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.951\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 45.403 | Train acc: 0.972 | Val acc: 0.969 | Val roc_auc: 0.916 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.448 | Train acc: 0.978 | Val acc: 0.966 | Val roc_auc: 0.938 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 32.587 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 30.519 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 31.215 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.963 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:01:14\n",
      "Epoch 007: | Loss: 28.040 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.953 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.862 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 19.557 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 010: | Loss: 18.101 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:01:14\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.379 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.961\n",
      "OOF: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280k/280k [00:03<00:00, 89.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 35s, sys: 15min 37s, total: 1h 10min 12s\n",
      "Wall time: 1h 13min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_128_128_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [65, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.895 | Train acc: 0.972 | Val acc: 0.969 | Val roc_auc: 0.940 | Training time: 0:04:10\n",
      "Epoch 002: | Loss: 70.968 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 69.316 | Train acc: 0.979 | Val acc: 0.980 | Val roc_auc: 0.940 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 66.868 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:04:06\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 54.191 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.946 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 50.400 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.949 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 48.606 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.952 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 46.038 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 44.063 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 40.454 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 33.433 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 92.104 | Train acc: 0.971 | Val acc: 0.967 | Val roc_auc: 0.916 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 71.832 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 003: | Loss: 66.830 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 65.457 | Train acc: 0.980 | Val acc: 0.966 | Val roc_auc: 0.942 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 65.154 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 63.603 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 62.862 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.967 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 61.945 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.968 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 58.095 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.957 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 58.847 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.967 | Training time: 0:04:07\n",
      "Epoch    10: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 011: | Loss: 49.370 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.973 | Training time: 0:04:07\n",
      "Epoch 012: | Loss: 46.953 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.971 | Training time: 0:04:07\n",
      "Epoch 013: | Loss: 44.294 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.971 | Training time: 0:04:08\n",
      "Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 014: | Loss: 39.701 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.972 | Training time: 0:04:08\n",
      "Early stopping. Best Val roc_auc: 0.973\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.852 | Train acc: 0.971 | Val acc: 0.946 | Val roc_auc: 0.912 | Training time: 0:04:08\n",
      "Epoch 002: | Loss: 73.239 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.941 | Training time: 0:04:08\n",
      "Epoch 003: | Loss: 71.404 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:04:08\n",
      "Epoch 004: | Loss: 65.970 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:04:08\n",
      "Epoch 005: | Loss: 64.609 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:04:08\n",
      "Epoch 006: | Loss: 61.150 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:04:08\n",
      "Epoch 007: | Loss: 60.459 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:04:08\n",
      "Epoch 008: | Loss: 59.639 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:04:08\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 50.294 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:04:08\n",
      "Epoch 010: | Loss: 46.707 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.954 | Training time: 0:04:08\n",
      "Epoch 011: | Loss: 44.619 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 012: | Loss: 42.266 | Train acc: 0.985 | Val acc: 0.976 | Val roc_auc: 0.956 | Training time: 0:04:08\n",
      "Epoch 013: | Loss: 40.753 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:04:08\n",
      "Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 014: | Loss: 35.554 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:04:09\n",
      "Epoch 015: | Loss: 33.474 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 016: | Loss: 32.057 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:09\n",
      "Epoch    16: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 017: | Loss: 31.418 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:09\n",
      "Early stopping. Best Val roc_auc: 0.959\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.858 | Train acc: 0.972 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:04:09\n",
      "Epoch 002: | Loss: 73.937 | Train acc: 0.977 | Val acc: 0.980 | Val roc_auc: 0.948 | Training time: 0:04:09\n",
      "Epoch 003: | Loss: 67.279 | Train acc: 0.979 | Val acc: 0.973 | Val roc_auc: 0.952 | Training time: 0:04:09\n",
      "Epoch 004: | Loss: 63.748 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:04:09\n",
      "Epoch 005: | Loss: 64.036 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.941 | Training time: 0:04:09\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 53.900 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 007: | Loss: 49.826 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 008: | Loss: 46.889 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:09\n",
      "Epoch 009: | Loss: 43.053 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.950 | Training time: 0:04:09\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 38.201 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.954 | Training time: 0:04:10\n",
      "Early stopping. Best Val roc_auc: 0.958\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.534 | Train acc: 0.972 | Val acc: 0.977 | Val roc_auc: 0.937 | Training time: 0:04:10\n",
      "Epoch 002: | Loss: 74.204 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:04:10\n",
      "Epoch 003: | Loss: 69.021 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.937 | Training time: 0:04:09\n",
      "Epoch 004: | Loss: 68.137 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:04:09\n",
      "Epoch 005: | Loss: 63.874 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.952 | Training time: 0:04:10\n",
      "Epoch 006: | Loss: 63.363 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 007: | Loss: 62.850 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.956 | Training time: 0:04:10\n",
      "Epoch 008: | Loss: 61.216 | Train acc: 0.980 | Val acc: 0.943 | Val roc_auc: 0.952 | Training time: 0:04:10\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 53.193 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.965 | Training time: 0:04:10\n",
      "Epoch 010: | Loss: 47.047 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.964 | Training time: 0:04:10\n",
      "Epoch 011: | Loss: 45.022 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:10\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 41.640 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:04:10\n",
      "Early stopping. Best Val roc_auc: 0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278k/278k [00:05<00:00, 56.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 41s, sys: 1h 13min 58s, total: 4h 35min 39s\n",
      "Wall time: 4h 35min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_256_256_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.927 | Train acc: 0.971 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.554 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.255 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.942 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 31.940 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.941 | Training time: 0:01:15\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 26.005 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 23.328 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.954 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.292 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 19.646 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 16.567 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.954\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.711 | Train acc: 0.973 | Val acc: 0.975 | Val roc_auc: 0.934 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 35.135 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 31.939 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.915 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 30.017 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.967 | Training time: 0:01:16\n",
      "Epoch 006: | Loss: 28.968 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:01:16\n",
      "Epoch 007: | Loss: 29.322 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.965 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.935 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.968 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 20.796 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.971 | Training time: 0:01:15\n",
      "Epoch 010: | Loss: 17.961 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.967 | Training time: 0:01:15\n",
      "Epoch 011: | Loss: 16.816 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 12.530 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.963 | Training time: 0:01:16\n",
      "Early stopping. Best Val roc_auc: 0.971\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.844 | Train acc: 0.972 | Val acc: 0.974 | Val roc_auc: 0.940 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.610 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.021 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.295 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.949 | Training time: 0:01:16\n",
      "Epoch 005: | Loss: 28.635 | Train acc: 0.981 | Val acc: 0.967 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch 006: | Loss: 27.869 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:01:16\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 22.159 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:01:16\n",
      "Epoch 008: | Loss: 19.112 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 17.107 | Train acc: 0.987 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:01:16\n",
      "Epoch 010: | Loss: 15.875 | Train acc: 0.988 | Val acc: 0.970 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 12.664 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 45.002 | Train acc: 0.971 | Val acc: 0.974 | Val roc_auc: 0.933 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.860 | Train acc: 0.978 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 33.039 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 31.003 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.944 | Training time: 0:01:16\n",
      "Epoch 005: | Loss: 29.689 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 24.511 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.373 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.948 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 19.602 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.952 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 15.939 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.579 | Train acc: 0.973 | Val acc: 0.973 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.826 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.947 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.623 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.895 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 29.714 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.563 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 24.721 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:01:16\n",
      "Epoch 008: | Loss: 21.443 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.962 | Training time: 0:01:16\n",
      "Epoch 009: | Loss: 20.386 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:01:16\n",
      "Epoch 010: | Loss: 17.798 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.105 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.960 | Training time: 0:01:16\n",
      "Early stopping. Best Val roc_auc: 0.962\n",
      "OOF: 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281k/281k [00:03<00:00, 81.8kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 39s, sys: 14min 41s, total: 1h 6min 20s\n",
      "Wall time: 1h 9min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_128_128_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [65, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.475 | Train acc: 0.972 | Val acc: 0.978 | Val roc_auc: 0.936 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 74.465 | Train acc: 0.977 | Val acc: 0.980 | Val roc_auc: 0.937 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 66.486 | Train acc: 0.979 | Val acc: 0.980 | Val roc_auc: 0.945 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 66.889 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.938 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 63.380 | Train acc: 0.980 | Val acc: 0.980 | Val roc_auc: 0.936 | Training time: 0:04:06\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 52.995 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 49.486 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 46.823 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 44.841 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 41.863 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 36.103 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.952 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.009 | Train acc: 0.972 | Val acc: 0.975 | Val roc_auc: 0.947 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 70.192 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 70.119 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 68.307 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 65.614 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:04:06\n",
      "Epoch 006: | Loss: 67.500 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 61.093 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:04:06\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 52.809 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.969 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 50.425 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.972 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 47.979 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.970 | Training time: 0:04:06\n",
      "Epoch 011: | Loss: 46.206 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.971 | Training time: 0:04:06\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 42.974 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.969 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.972\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.327 | Train acc: 0.971 | Val acc: 0.976 | Val roc_auc: 0.940 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 76.511 | Train acc: 0.975 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 66.024 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 66.049 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 64.303 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:04:06\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 54.505 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 50.404 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.955 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 48.299 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 46.542 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 44.772 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 37.852 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:04:06\n",
      "Epoch 012: | Loss: 36.166 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 013: | Loss: 34.061 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:06\n",
      "Epoch 014: | Loss: 32.971 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Epoch 015: | Loss: 31.350 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    15: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 016: | Loss: 29.441 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.958\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 91.444 | Train acc: 0.971 | Val acc: 0.975 | Val roc_auc: 0.935 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 71.589 | Train acc: 0.978 | Val acc: 0.968 | Val roc_auc: 0.937 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 68.689 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 66.262 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 65.316 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.954 | Training time: 0:04:06\n",
      "Epoch 006: | Loss: 59.599 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 59.461 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 51.603 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.960 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 46.863 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 45.415 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 40.424 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.960\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.409 | Train acc: 0.971 | Val acc: 0.973 | Val roc_auc: 0.948 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 69.343 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.946 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 69.309 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 64.233 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 66.281 | Train acc: 0.978 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 53.144 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 49.259 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 47.846 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.965 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 45.021 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.965 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 42.781 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch 011: | Loss: 40.446 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 32.722 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.965 | Training time: 0:04:07\n",
      "Epoch 013: | Loss: 31.632 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch 014: | Loss: 28.787 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:04:06\n",
      "Epoch    14: reducing learning rate of group 0 to 8.0000e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015: | Loss: 26.306 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.965\n",
      "OOF: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282k/282k [00:03<00:00, 87.7kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 43s, sys: 1h 15min 27s, total: 4h 37min 11s\n",
      "Wall time: 4h 37min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_256_256_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "==================== Fold 1 ====================\n",
      "Epoch 001: | Loss: 25.507 | Train acc: 0.965 | Val acc: 0.973 | Val roc_auc: 0.871 | Training time: 0:00:20\n",
      "Epoch 002: | Loss: 19.840 | Train acc: 0.972 | Val acc: 0.972 | Val roc_auc: 0.876 | Training time: 0:00:20\n",
      "Epoch 003: | Loss: 18.592 | Train acc: 0.974 | Val acc: 0.972 | Val roc_auc: 0.883 | Training time: 0:00:21\n",
      "Epoch 004: | Loss: 17.672 | Train acc: 0.975 | Val acc: 0.975 | Val roc_auc: 0.908 | Training time: 0:00:20\n",
      "Epoch 005: | Loss: 16.349 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.864 | Training time: 0:00:20\n",
      "Epoch 006: | Loss: 15.759 | Train acc: 0.976 | Val acc: 0.973 | Val roc_auc: 0.885 | Training time: 0:00:20\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 13.394 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.911 | Training time: 0:00:20\n",
      "Epoch 008: | Loss: 11.835 | Train acc: 0.982 | Val acc: 0.973 | Val roc_auc: 0.906 | Training time: 0:00:20\n",
      "Epoch 009: | Loss: 10.848 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.911 | Training time: 0:00:21\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 9.347 | Train acc: 0.985 | Val acc: 0.973 | Val roc_auc: 0.914 | Training time: 0:00:20\n",
      "Epoch 011: | Loss: 8.636 | Train acc: 0.986 | Val acc: 0.974 | Val roc_auc: 0.898 | Training time: 0:00:20\n",
      "Epoch 012: | Loss: 7.936 | Train acc: 0.988 | Val acc: 0.974 | Val roc_auc: 0.893 | Training time: 0:00:20\n",
      "Epoch    12: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 013: | Loss: 8.085 | Train acc: 0.987 | Val acc: 0.972 | Val roc_auc: 0.891 | Training time: 0:00:20\n",
      "Early stopping. Best Val roc_auc: 0.914\n",
      "==================== Fold 2 ====================\n",
      "Epoch 001: | Loss: 18.970 | Train acc: 0.972 | Val acc: 0.973 | Val roc_auc: 0.803 | Training time: 0:00:20\n",
      "Epoch 002: | Loss: 15.194 | Train acc: 0.978 | Val acc: 0.969 | Val roc_auc: 0.819 | Training time: 0:00:20\n",
      "Epoch 003: | Loss: 14.585 | Train acc: 0.978 | Val acc: 0.970 | Val roc_auc: 0.808 | Training time: 0:00:21\n",
      "Epoch 004: | Loss: 13.994 | Train acc: 0.979 | Val acc: 0.970 | Val roc_auc: 0.803 | Training time: 0:00:20\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 9.991 | Train acc: 0.984 | Val acc: 0.970 | Val roc_auc: 0.819 | Training time: 0:00:21\n",
      "Epoch 006: | Loss: 8.439 | Train acc: 0.987 | Val acc: 0.971 | Val roc_auc: 0.819 | Training time: 0:00:20\n",
      "Epoch 007: | Loss: 7.442 | Train acc: 0.989 | Val acc: 0.970 | Val roc_auc: 0.816 | Training time: 0:00:20\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 6.208 | Train acc: 0.990 | Val acc: 0.969 | Val roc_auc: 0.818 | Training time: 0:00:20\n",
      "Early stopping. Best Val roc_auc: 0.819\n",
      "==================== Fold 3 ====================\n",
      "Epoch 001: | Loss: 15.045 | Train acc: 0.974 | Val acc: 0.975 | Val roc_auc: 0.838 | Training time: 0:00:20\n",
      "Epoch 002: | Loss: 11.999 | Train acc: 0.982 | Val acc: 0.974 | Val roc_auc: 0.835 | Training time: 0:00:21\n",
      "Epoch 003: | Loss: 11.450 | Train acc: 0.982 | Val acc: 0.975 | Val roc_auc: 0.843 | Training time: 0:00:20\n",
      "Epoch 004: | Loss: 10.940 | Train acc: 0.982 | Val acc: 0.972 | Val roc_auc: 0.800 | Training time: 0:00:20\n",
      "Epoch 005: | Loss: 9.870 | Train acc: 0.984 | Val acc: 0.962 | Val roc_auc: 0.810 | Training time: 0:00:20\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 6.969 | Train acc: 0.989 | Val acc: 0.975 | Val roc_auc: 0.837 | Training time: 0:00:20\n",
      "Early stopping. Best Val roc_auc: 0.843\n",
      "==================== Fold 4 ====================\n",
      "Epoch 001: | Loss: 12.543 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.856 | Training time: 0:00:20\n",
      "Epoch 002: | Loss: 9.239 | Train acc: 0.985 | Val acc: 0.974 | Val roc_auc: 0.849 | Training time: 0:00:20\n",
      "Epoch 003: | Loss: 8.882 | Train acc: 0.986 | Val acc: 0.971 | Val roc_auc: 0.840 | Training time: 0:00:20\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 6.164 | Train acc: 0.990 | Val acc: 0.979 | Val roc_auc: 0.857 | Training time: 0:00:20\n",
      "Epoch 005: | Loss: 4.294 | Train acc: 0.993 | Val acc: 0.981 | Val roc_auc: 0.861 | Training time: 0:00:20\n",
      "Epoch 006: | Loss: 3.462 | Train acc: 0.994 | Val acc: 0.979 | Val roc_auc: 0.859 | Training time: 0:00:20\n",
      "Epoch 007: | Loss: 3.193 | Train acc: 0.994 | Val acc: 0.979 | Val roc_auc: 0.859 | Training time: 0:00:20\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 2.972 | Train acc: 0.995 | Val acc: 0.979 | Val roc_auc: 0.857 | Training time: 0:00:20\n",
      "Early stopping. Best Val roc_auc: 0.861\n",
      "==================== Fold 5 ====================\n",
      "Epoch 001: | Loss: 9.084 | Train acc: 0.985 | Val acc: 0.984 | Val roc_auc: 0.874 | Training time: 0:00:20\n",
      "Epoch 002: | Loss: 7.305 | Train acc: 0.988 | Val acc: 0.979 | Val roc_auc: 0.871 | Training time: 0:00:20\n",
      "Epoch 003: | Loss: 6.600 | Train acc: 0.989 | Val acc: 0.979 | Val roc_auc: 0.869 | Training time: 0:00:20\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 4.251 | Train acc: 0.993 | Val acc: 0.986 | Val roc_auc: 0.874 | Training time: 0:00:20\n",
      "Epoch 005: | Loss: 3.142 | Train acc: 0.995 | Val acc: 0.984 | Val roc_auc: 0.876 | Training time: 0:00:20\n",
      "Epoch 006: | Loss: 2.630 | Train acc: 0.996 | Val acc: 0.985 | Val roc_auc: 0.876 | Training time: 0:00:20\n",
      "Epoch 007: | Loss: 2.152 | Train acc: 0.996 | Val acc: 0.987 | Val roc_auc: 0.876 | Training time: 0:00:20\n",
      "Epoch 008: | Loss: 1.985 | Train acc: 0.997 | Val acc: 0.985 | Val roc_auc: 0.875 | Training time: 0:00:20\n",
      "Epoch 009: | Loss: 2.024 | Train acc: 0.997 | Val acc: 0.983 | Val roc_auc: 0.874 | Training time: 0:00:20\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 1.349 | Train acc: 0.998 | Val acc: 0.986 | Val roc_auc: 0.875 | Training time: 0:00:20\n",
      "Early stopping. Best Val roc_auc: 0.876\n",
      "OOF: 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278k/278k [00:02<00:00, 104kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 28s, sys: 2min 10s, total: 14min 39s\n",
      "Wall time: 16min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#64_64_GrayColorConstancy\n",
    "arch = EfficientNet.from_pretrained('efficientnet-b0')  # Going to use efficientnet-b0 NN architecture\n",
    "#EfficientNet.from_pretrained('efficientnet-b0',num_classes=targetのクラス数（今回だと2?）) \n",
    "skf = GroupKFold(n_splits=5)\n",
    "model_name = \"64_64_GrayColorConstancy\"\n",
    "train_folder = \"pad_jpg/train/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [128, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + model_name]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, arch, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "==================== Fold 1 ====================\n",
      "Epoch 001: | Loss: 43.676 | Train acc: 0.970 | Val acc: 0.973 | Val roc_auc: 0.892 | Training time: 0:02:17\n",
      "Epoch 002: | Loss: 37.208 | Train acc: 0.974 | Val acc: 0.974 | Val roc_auc: 0.920 | Training time: 0:02:12\n",
      "Epoch 003: | Loss: 33.322 | Train acc: 0.976 | Val acc: 0.975 | Val roc_auc: 0.900 | Training time: 0:02:12\n",
      "Epoch 004: | Loss: 32.508 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.901 | Training time: 0:02:12\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 24.485 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.940 | Training time: 0:02:12\n",
      "Epoch 006: | Loss: 20.906 | Train acc: 0.983 | Val acc: 0.975 | Val roc_auc: 0.935 | Training time: 0:02:12\n",
      "Epoch 007: | Loss: 18.632 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.937 | Training time: 0:02:13\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 13.959 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:02:13\n",
      "Epoch 009: | Loss: 12.064 | Train acc: 0.990 | Val acc: 0.977 | Val roc_auc: 0.939 | Training time: 0:02:13\n",
      "Epoch 010: | Loss: 11.348 | Train acc: 0.990 | Val acc: 0.977 | Val roc_auc: 0.936 | Training time: 0:02:12\n",
      "Epoch    10: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 011: | Loss: 10.107 | Train acc: 0.991 | Val acc: 0.978 | Val roc_auc: 0.938 | Training time: 0:02:12\n",
      "Early stopping. Best Val roc_auc: 0.940\n",
      "==================== Fold 2 ====================\n",
      "Epoch 001: | Loss: 31.778 | Train acc: 0.976 | Val acc: 0.968 | Val roc_auc: 0.812 | Training time: 0:02:13\n",
      "Epoch 002: | Loss: 27.951 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.822 | Training time: 0:02:13\n",
      "Epoch 003: | Loss: 26.807 | Train acc: 0.979 | Val acc: 0.968 | Val roc_auc: 0.820 | Training time: 0:02:13\n",
      "Epoch 004: | Loss: 25.694 | Train acc: 0.980 | Val acc: 0.969 | Val roc_auc: 0.811 | Training time: 0:02:13\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 17.700 | Train acc: 0.986 | Val acc: 0.970 | Val roc_auc: 0.832 | Training time: 0:02:13\n",
      "Epoch 006: | Loss: 13.132 | Train acc: 0.989 | Val acc: 0.973 | Val roc_auc: 0.834 | Training time: 0:02:13\n",
      "Epoch 007: | Loss: 11.615 | Train acc: 0.991 | Val acc: 0.972 | Val roc_auc: 0.836 | Training time: 0:02:13\n",
      "Epoch 008: | Loss: 8.815 | Train acc: 0.993 | Val acc: 0.973 | Val roc_auc: 0.833 | Training time: 0:02:12\n",
      "Epoch 009: | Loss: 7.369 | Train acc: 0.993 | Val acc: 0.968 | Val roc_auc: 0.824 | Training time: 0:02:12\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 5.645 | Train acc: 0.996 | Val acc: 0.975 | Val roc_auc: 0.829 | Training time: 0:02:12\n",
      "Early stopping. Best Val roc_auc: 0.836\n",
      "==================== Fold 3 ====================\n",
      "Epoch 001: | Loss: 22.981 | Train acc: 0.983 | Val acc: 0.975 | Val roc_auc: 0.849 | Training time: 0:02:12\n",
      "Epoch 002: | Loss: 20.934 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.849 | Training time: 0:02:12\n",
      "Epoch 003: | Loss: 19.914 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.849 | Training time: 0:02:13\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 11.863 | Train acc: 0.990 | Val acc: 0.979 | Val roc_auc: 0.859 | Training time: 0:02:12\n",
      "Epoch 005: | Loss: 8.096 | Train acc: 0.994 | Val acc: 0.979 | Val roc_auc: 0.861 | Training time: 0:02:12\n",
      "Epoch 006: | Loss: 6.456 | Train acc: 0.995 | Val acc: 0.976 | Val roc_auc: 0.858 | Training time: 0:02:13\n",
      "Epoch 007: | Loss: 5.115 | Train acc: 0.996 | Val acc: 0.979 | Val roc_auc: 0.858 | Training time: 0:02:12\n",
      "Epoch     7: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 008: | Loss: 3.573 | Train acc: 0.997 | Val acc: 0.980 | Val roc_auc: 0.861 | Training time: 0:02:12\n",
      "Early stopping. Best Val roc_auc: 0.861\n",
      "==================== Fold 4 ====================\n",
      "Epoch 001: | Loss: 17.121 | Train acc: 0.985 | Val acc: 0.981 | Val roc_auc: 0.860 | Training time: 0:02:12\n",
      "Epoch 002: | Loss: 16.394 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.859 | Training time: 0:02:12\n",
      "Epoch 003: | Loss: 14.564 | Train acc: 0.988 | Val acc: 0.975 | Val roc_auc: 0.849 | Training time: 0:02:13\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 7.876 | Train acc: 0.993 | Val acc: 0.983 | Val roc_auc: 0.863 | Training time: 0:02:12\n",
      "Epoch 005: | Loss: 4.387 | Train acc: 0.996 | Val acc: 0.983 | Val roc_auc: 0.865 | Training time: 0:02:12\n",
      "Epoch 006: | Loss: 4.104 | Train acc: 0.997 | Val acc: 0.983 | Val roc_auc: 0.864 | Training time: 0:02:12\n",
      "Epoch 007: | Loss: 3.802 | Train acc: 0.997 | Val acc: 0.984 | Val roc_auc: 0.865 | Training time: 0:02:12\n",
      "Epoch 008: | Loss: 2.807 | Train acc: 0.998 | Val acc: 0.980 | Val roc_auc: 0.865 | Training time: 0:02:12\n",
      "Epoch 009: | Loss: 2.613 | Train acc: 0.998 | Val acc: 0.983 | Val roc_auc: 0.866 | Training time: 0:02:12\n",
      "Epoch 010: | Loss: 1.991 | Train acc: 0.998 | Val acc: 0.983 | Val roc_auc: 0.864 | Training time: 0:02:12\n",
      "Epoch 011: | Loss: 2.491 | Train acc: 0.998 | Val acc: 0.982 | Val roc_auc: 0.863 | Training time: 0:02:12\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 1.994 | Train acc: 0.999 | Val acc: 0.984 | Val roc_auc: 0.864 | Training time: 0:02:12\n",
      "Early stopping. Best Val roc_auc: 0.866\n",
      "==================== Fold 5 ====================\n",
      "Epoch 001: | Loss: 13.107 | Train acc: 0.989 | Val acc: 0.982 | Val roc_auc: 0.875 | Training time: 0:02:12\n",
      "Epoch 002: | Loss: 11.661 | Train acc: 0.991 | Val acc: 0.972 | Val roc_auc: 0.817 | Training time: 0:02:12\n",
      "Epoch 003: | Loss: 13.449 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.871 | Training time: 0:02:12\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 5.604 | Train acc: 0.995 | Val acc: 0.984 | Val roc_auc: 0.875 | Training time: 0:02:12\n",
      "Epoch 005: | Loss: 3.430 | Train acc: 0.997 | Val acc: 0.986 | Val roc_auc: 0.876 | Training time: 0:02:12\n",
      "Epoch 006: | Loss: 2.537 | Train acc: 0.998 | Val acc: 0.986 | Val roc_auc: 0.875 | Training time: 0:02:12\n",
      "Epoch 007: | Loss: 2.393 | Train acc: 0.998 | Val acc: 0.985 | Val roc_auc: 0.877 | Training time: 0:02:13\n",
      "Epoch 008: | Loss: 1.776 | Train acc: 0.999 | Val acc: 0.986 | Val roc_auc: 0.876 | Training time: 0:02:12\n",
      "Epoch 009: | Loss: 1.682 | Train acc: 0.999 | Val acc: 0.985 | Val roc_auc: 0.876 | Training time: 0:02:12\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 1.769 | Train acc: 0.998 | Val acc: 0.987 | Val roc_auc: 0.877 | Training time: 0:02:12\n",
      "Epoch 011: | Loss: 1.230 | Train acc: 0.999 | Val acc: 0.988 | Val roc_auc: 0.876 | Training time: 0:02:13\n",
      "Epoch 012: | Loss: 1.301 | Train acc: 0.999 | Val acc: 0.986 | Val roc_auc: 0.876 | Training time: 0:02:12\n",
      "Epoch    12: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 013: | Loss: 0.786 | Train acc: 0.999 | Val acc: 0.987 | Val roc_auc: 0.876 | Training time: 0:02:12\n",
      "Early stopping. Best Val roc_auc: 0.877\n",
      "OOF: 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281k/281k [00:03<00:00, 91.1kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 19min 53s, sys: 35min 52s, total: 1h 55min 46s\n",
      "Wall time: 2h 2min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#224_224_GrayColorConstancy\n",
    "arch = EfficientNet.from_pretrained('efficientnet-b0')  # Going to use efficientnet-b0 NN architecture\n",
    "#EfficientNet.from_pretrained('efficientnet-b0',num_classes=targetのクラス数（今回だと2?）) \n",
    "skf = GroupKFold(n_splits=5)\n",
    "model_name = \"224_224_GrayColorConstancy\"\n",
    "train_folder = \"pad_jpg/train/\" + model_name\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "bat_size = [64, 32, 16] #train, val, test\n",
    "test_imfolder = [SIIM_ISIC_Melanoma_Classification + \"pad_jpg/test/\" + model_name]\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec_TTAmod(epochs, model_path, es_patience, bat_size, train_df, test_df, \n",
    "                                                    test_imfolder, arch, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2645433471f9401e97a82e33b5b45fe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fb13192f9df4107a57f93b4e473af68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2645433471f9401e97a82e33b5b45fe8",
       "max": 31519111,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b87e4be241954e789280916c41fe05e9",
       "value": 31519111
      }
     },
     "4649c58ae866408e8875c58165600cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ee6e0abb0e449b086afdc4303ba673c",
       "placeholder": "​",
       "style": "IPY_MODEL_d6200ba71ab54fbb979ec43b1608ff2c",
       "value": " 30.1M/30.1M [00:01&lt;00:00, 24.0MB/s]"
      }
     },
     "4ee6e0abb0e449b086afdc4303ba673c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ea58d39e9dd42e28160d8de49f05d37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b87e4be241954e789280916c41fe05e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d04e0dc2878340f88e0658c17fbd600d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3fb13192f9df4107a57f93b4e473af68",
        "IPY_MODEL_4649c58ae866408e8875c58165600cf3"
       ],
       "layout": "IPY_MODEL_5ea58d39e9dd42e28160d8de49f05d37"
      }
     },
     "d6200ba71ab54fbb979ec43b1608ff2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
