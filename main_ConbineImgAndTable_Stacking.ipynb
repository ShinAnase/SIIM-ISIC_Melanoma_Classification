{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtoolbox.transform as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## config(kernel使うときに変更すべき変数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "melanoma_external_malignant_256 = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/melanoma_external_malignant_256/\"\n",
    "SIIM_ISIC_Melanoma_Classification = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/SIIM-ISIC-Melanoma-Classification/\"\n",
    "Output = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/Output/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ加工部"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN(画像＋テーブル)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "train_concat&メタデータ込み：CV:0.974, LB:????<br>\n",
    "__ver2__<br>\n",
    "256*256：CV:0.885, LB:0.890<br>\n",
    "__verSN:1__<br>\n",
    "metaval:resizeのみ<br>\n",
    "192_192：OOF: 0.869 Wall time:  1h 33min LB: 0.861<br>\n",
    "224_224：OOF: 0.883 Wall time:  2h 07min LB: 0.862<br>\n",
    "256_256：OOF: 0.875 Wall time:  2h 36min LB: 0.882<br>\n",
    "382_382：OOF: 0.869 Wall time:  5h 10min LB: 0.854<br>\n",
    "512_512：OOF: 0.848 Wall time: 10h 29min LB: 0.852<br>\n",
    "__verSN:2__<br>\n",
    "metaval:metaの組み込み<br>\n",
    "64_64  ：OOF: 0.856 Wall time: 20min 50s LB: 0.852<br>\n",
    "256_256：OOF: 0.874 Wall time: 2h 31min 55s LB: 0.885<br>\n",
    "__verSN:3__<br>\n",
    "stackingに切り替え<br>\n",
    "64_64  ：OOF: 0.876 Wall time: 30min 59s    LB: 0.8779<br>\n",
    "128_128：OOF: 0.881 Wall time: about 50min  LB: 0.8756<br>\n",
    "192_192：OOF: 0.893 Wall time: 2h 10min 17s LB: 0.8813<br>\n",
    "224_224：OOF: 0.892 Wall time: 2h 41min 8s  LB: 0.8807<br>\n",
    "256_256：OOF: 0.897 Wall time: 3h 24min 25s LB: 0.8760<br>\n",
    "384_384：OOF: 0.872 Wall time: 7h 26min 48s LB: 0.8676<br>\n",
    "__verSN:4__<br>\n",
    "tfrecordによるfold + epoch20<br>\n",
    "64_64  ：OOF: 0.873 Wall time: 38min 15s    LB:0.8856 <br>\n",
    "96_96  ：OOF: 0.879 Wall time: 54min 34s    LB:0.8719 <br>\n",
    "128_128：OOF: 0.882 Wall time: 1h 20min 49s LB:0.8929 <br>\n",
    "160_160：OOF: 0.884 Wall time: 2h 8min 24s  LB:0.8678 <br>\n",
    "192_192：OOF: 0.885 Wall time: 不明         LB:0.8704 <br>\n",
    "__verSN:5__<br>\n",
    "2019データ<br>\n",
    "64_64  ：OOF: 0.903 Wall time: 30min 37s    LB:0.7135 <br>\n",
    "128_128：OOF: 0.924 Wall time: 不明         LB:0.7449 <br>\n",
    "__verSN:6__<br>\n",
    "train + malignant2019 merge<br>\n",
    "64_64  ：OOF: 0.821 Wall time: 24min 19s    LB:0.8924 <br>\n",
    "128_128：OOF: 0.891 Wall time: 1h 12min 48s LB:0.8891 <br>\n",
    "256_256：OOF: 0.900 Wall time: 4h 19min 32s LB:0.8857 <br>\n",
    "__verSN:7__<br>\n",
    "train + malignant2019 merge → BGR2GRAY<br>\n",
    "64_64  ：OOF: 0.812 Wall time: 27min        LB:0.8396 <br>\n",
    "128_128：OOF: 0.889 Wall time: 1h 5min 16s  LB:0.8633 <br>\n",
    "256_256：OOF: 0.897 Wall time: 3h 44min 52s LB:0.8523 <br>\n",
    "__verSN:8__<br>\n",
    "pad BGR2GRAY<br>\n",
    "64_64  ：OOF: 0.948 Wall time: 28min        LB:0.8758 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least fixing some random seeds. \n",
    "# It is still impossible to make results 100% reproducible when using GPU\n",
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, \n",
    "                 transforms = None,  meta_features = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description→学習に使わない\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n",
    "        x = cv2.imread(im_path)\n",
    "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
    "\n",
    "        if self.transforms:\n",
    "            #X_data_np = np.array(x)\n",
    "            #print(\"transfor前\")\n",
    "            #print(X_data_np.shape)\n",
    "            #y_data_np = np.array(y)\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.loc[index]['target']\n",
    "            #return (x, meta), y\n",
    "            #print(y)\n",
    "            #X_data_np = np.array(x)\n",
    "            #print(\"transform後\")\n",
    "            #print(X_data_np.shape)\n",
    "            #y_data_np = np.array(y)\n",
    "            #print(y_data_np.shape)\n",
    "            return (x, meta), y\n",
    "        else:\n",
    "            return (x, meta)\n",
    "            #return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, arch, n_meta_features: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        if 'ResNet' in str(arch.__class__):\n",
    "            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
    "        if 'EfficientNet' in str(arch.__class__):\n",
    "            self.arch._fc = nn.Linear(in_features=1280, out_features=500, bias=True)\n",
    "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
    "                                  nn.BatchNorm1d(500),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(500, 250),  # FC layer output will have 50 features\n",
    "                                  nn.BatchNorm1d(250),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2))\n",
    "        self.ouput = nn.Linear(500 + 250, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x, meta = inputs\n",
    "        cnn_features = self.arch(x)\n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.Cutout(scale=(0.05, 0.007), value=(0, 0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.Cutout(scale=(0.05, 0.007), value=(0, 0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "arch = EfficientNet.from_pretrained('efficientnet-b1')  # Going to use efficientnet-b0 NN architecture\n",
    "# skf = StratifiedKFold(n_splits=3, random_state=999, shuffle=True)\n",
    "skf = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableDataPreprocess2020(dt):\n",
    "    # One-hot encoding of anatom_site_general_challenge feature\n",
    "    concat = pd.concat([dt[0]['anatom_site_general_challenge'], dt[1]['anatom_site_general_challenge']], ignore_index=True)\n",
    "    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "    dt[0] = pd.concat([dt[0], dummies.iloc[:dt[0].shape[0]]], axis=1)\n",
    "    dt[1] = pd.concat([dt[1], dummies.iloc[dt[0].shape[0]:].reset_index(drop=True)], axis=1)\n",
    "    for df in dt:\n",
    "        df['sex'] = df['sex'].map({'male': 1, 'female': 0})\n",
    "        df['sex'] = df['sex'].fillna(-1)\n",
    "        df['age_approx'] /= df['age_approx'].max()\n",
    "        df['age_approx'] = df['age_approx'].fillna(0)\n",
    "        df['patient_id'] = df['patient_id'].fillna(0)\n",
    "    return dt\n",
    "\n",
    "def TableDataPreprocess2019(dt):\n",
    "    # One-hot encoding of anatom_site_general_challenge feature\n",
    "    concat = pd.concat([dt[0]['anatom_site_general_challenge'], dt[1]['anatom_site_general_challenge']], ignore_index=True)\n",
    "    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "    dt[0] = pd.concat([dt[0], dummies.iloc[:dt[0].shape[0]]], axis=1)\n",
    "    dt[1] = pd.concat([dt[1], dummies.iloc[dt[0].shape[0]:].reset_index(drop=True)], axis=1)\n",
    "    for df in dt:\n",
    "        df['sex'] = df['sex'].map({'male': 1, 'female': 0})\n",
    "        df['sex'] = df['sex'].fillna(-1)\n",
    "        df['age_approx'] /= df['age_approx'].max()\n",
    "        df['age_approx'] = df['age_approx'].fillna(0)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord = None):\n",
    "    \n",
    "    meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "    meta_features.remove('anatom_site_general_challenge')\n",
    "    \n",
    "    #sample_sub_metaval_stacking.csv用Imagename\n",
    "    ImgNm = train_df[['image_name']]\n",
    "    \n",
    "    \n",
    "    test = MelanomaDataset(df=test_df,\n",
    "                           imfolder = SIIM_ISIC_Melanoma_Classification + test_folder, \n",
    "                           train=False,\n",
    "                           transforms=test_transform,\n",
    "                           meta_features=meta_features)\n",
    "    oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "    \n",
    "    # We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "    # We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "    # since we only need `y` to stratify the data\n",
    "    # for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "    #for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=tfrecord['tfrecord'].tolist()), 1):\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        \n",
    "        best_val = None  # Best validation score within this fold\n",
    "        patience = es_patience  # Current patience counter\n",
    "        arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "        model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "        model = model.to(device)\n",
    "        \n",
    "        \n",
    "        optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True),  \n",
    "                                imfolder = SIIM_ISIC_Melanoma_Classification + train_folder, \n",
    "                                train=True, \n",
    "                                transforms=train_transform,\n",
    "                                meta_features=meta_features)\n",
    "        val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True),\n",
    "                              imfolder = SIIM_ISIC_Melanoma_Classification + train_folder,\n",
    "                              train=True,\n",
    "                              transforms=test_transform,\n",
    "                              meta_features=meta_features)\n",
    "    \n",
    "        train_loader = DataLoader(dataset=train, batch_size=bat_size[0], shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(dataset=val, batch_size=bat_size[1], shuffle=False, num_workers=2)\n",
    "        test_loader = DataLoader(dataset=test, batch_size=bat_size[2], shuffle=False, num_workers=2)\n",
    "        \n",
    "        del train, val\n",
    "        gc.collect()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            correct = 0\n",
    "            epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for x, y in train_loader:\n",
    "                x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "                x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "                y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "                \n",
    "                \n",
    "                optim.zero_grad()\n",
    "                z = model(x)\n",
    "                loss = criterion(z, y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "                correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "                \n",
    "            train_acc = correct / len(train_idx)\n",
    "    \n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "                val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "                val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "                \n",
    "                print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "                epoch + 1, \n",
    "                epoch_loss, \n",
    "                train_acc, \n",
    "                val_acc, \n",
    "                val_roc, \n",
    "                str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "                \n",
    "                scheduler.step(val_roc)\n",
    "                # During the first iteration (first epoch) best validation is set to None\n",
    "                if not best_val:\n",
    "                    best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                    torch.save(model, model_path)  # Saving the model\n",
    "                    continue\n",
    "                    \n",
    "                if val_roc >= best_val:\n",
    "                    best_val = val_roc\n",
    "                    patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                    torch.save(model, model_path)  # Saving current best model\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                    if patience == 0:\n",
    "                        print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                        break\n",
    "        \n",
    "        del train_loader, x, y\n",
    "        gc.collect()\n",
    "        \n",
    "        model = torch.load(model_path)  # Loading best model of this fold\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        test_preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test set\n",
    "        with torch.no_grad():\n",
    "            # Predicting on validation set once again to obtain data for OOF\n",
    "            for _ in range(TTA):\n",
    "                for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "            val_preds /= TTA\n",
    "            oof[val_idx] = val_preds.cpu()\n",
    "            del val_loader, x_val, y_val\n",
    "            gc.collect()\n",
    "            \n",
    "            # Predicting on test set\n",
    "            for _ in range(TTA):\n",
    "                for i, x_test in enumerate(test_loader):\n",
    "                    x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                    x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                    z_test = model(x_test)\n",
    "                    z_test = torch.sigmoid(z_test)\n",
    "                    test_preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "            test_preds /= TTA\n",
    "            del test_loader, x_test, z_test\n",
    "            gc.collect()\n",
    "        \n",
    "    test_preds /= skf.n_splits\n",
    "    \n",
    "    print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))\n",
    "    \n",
    "    return test_preds, oof, ImgNm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initData2020(Pre):\n",
    "    #train(train+2019malig)\n",
    "    train_malig = pd.read_csv(SIIM_ISIC_Melanoma_Classification + \"train_malig_2.csv\")\n",
    "    train_malig = train_malig[train_malig.tfrecord != -1]\n",
    "    train_malig = train_malig.drop(['diagnosis', 'benign_malignant', 'width', 'height', 'source', 'ext'], axis=1)\n",
    "    train_malig = train_malig.reset_index(drop=True)\n",
    "    tfrecord_malig = train_malig.loc[:,['tfrecord']]\n",
    "    tfrecord_malig = tfrecord_malig-15\n",
    "    \n",
    "    \n",
    "    train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train.csv')\n",
    "    train_df = train_df.drop(['diagnosis','benign_malignant'], axis=1)\n",
    "    train_df = train_df[train_df.tfrecord != -1]\n",
    "    train_df = train_df.drop(['width','height','patient_code'], axis=1)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    tfrecord = train_df.loc[:,['tfrecord']]\n",
    "    \n",
    "    #concate(train+2019malig)\n",
    "    train_df = pd.concat([train_df, train_malig], axis=0)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    \n",
    "    #padding (malignantOnly)\n",
    "    train_pad = train_df[train_df.target == 1]\n",
    "    train_pad = train_pad.reset_index(drop=True)\n",
    "    train_pad[['image_name']] = Pre + '_' + train_pad[['image_name']]\n",
    "    tfrecord_pad = train_pad.loc[:,['tfrecord']]\n",
    "    \n",
    "    #concate(train+2019malig) + BGR2GRAY(malignantOnly)\n",
    "    train_df = pd.concat([train_df, train_pad], axis=0)\n",
    "    train_df = train_df.drop(['tfrecord'], axis=1)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    tfrecord = pd.concat([tfrecord, tfrecord_malig, tfrecord_pad], axis=0)\n",
    "    tfrecord = tfrecord.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #test\n",
    "    test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "    \n",
    "    return train_df, test_df, tfrecord\n",
    "\n",
    "def initData2019():\n",
    "    train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train_2019year.csv')\n",
    "    train_df = train_df.drop(['diagnosis','benign_malignant'], axis=1)\n",
    "    train_df = train_df[train_df.tfrecord != -1]\n",
    "    train_df = train_df.drop(['width','height'], axis=1) \n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    tfrecord = train_df.loc[:,['tfrecord']]\n",
    "    train_df = train_df.drop(['tfrecord'], axis=1)\n",
    "    \n",
    "    test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "    \n",
    "    train_df = train_df.drop(['patient_id'], axis=1)\n",
    "    test_df = test_df.drop(['patient_id'], axis=1)\n",
    "    \n",
    "    return train_df, test_df, tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 105.343 | Train acc: 0.968 | Val acc: 0.939 | Val roc_auc: 0.958 | Training time: 0:04:31\n",
      "Epoch 002: | Loss: 86.838 | Train acc: 0.974 | Val acc: 0.959 | Val roc_auc: 0.971 | Training time: 0:04:31\n",
      "Epoch 003: | Loss: 79.692 | Train acc: 0.976 | Val acc: 0.959 | Val roc_auc: 0.971 | Training time: 0:04:31\n",
      "Epoch 004: | Loss: 76.978 | Train acc: 0.976 | Val acc: 0.949 | Val roc_auc: 0.968 | Training time: 0:04:32\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 60.895 | Train acc: 0.981 | Val acc: 0.961 | Val roc_auc: 0.977 | Training time: 0:04:32\n",
      "Epoch 006: | Loss: 56.753 | Train acc: 0.982 | Val acc: 0.964 | Val roc_auc: 0.975 | Training time: 0:04:32\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#trainRoman\n",
    "model_name = \"train_roman\"\n",
    "train_folder = \"jpeg/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "#train_df, test_df, tfrecord = initData2020()\n",
    "train_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train_roman.csv')\n",
    "test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.877 | Train acc: 0.964 | Val acc: 0.974 | Val roc_auc: 0.925 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.488 | Train acc: 0.976 | Val acc: 0.978 | Val roc_auc: 0.933 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 16.740 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.789 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.104 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 14.957 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.933 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 15.052 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 14.803 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.939 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 13.653 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 010: | Loss: 13.263 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:29\n",
      "Epoch 011: | Loss: 12.652 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.940 | Training time: 0:00:29\n",
      "Epoch    11: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 012: | Loss: 10.363 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 013: | Loss: 8.605 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:00:29\n",
      "Epoch 014: | Loss: 7.603 | Train acc: 0.987 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 015: | Loss: 6.945 | Train acc: 0.989 | Val acc: 0.973 | Val roc_auc: 0.940 | Training time: 0:00:28\n",
      "Epoch    15: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 016: | Loss: 5.558 | Train acc: 0.991 | Val acc: 0.975 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.768 | Train acc: 0.966 | Val acc: 0.974 | Val roc_auc: 0.935 | Training time: 0:00:30\n",
      "Epoch 002: | Loss: 18.830 | Train acc: 0.976 | Val acc: 0.976 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.815 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.407 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.959 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.851 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.955 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 15.739 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.960 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 14.986 | Train acc: 0.981 | Val acc: 0.973 | Val roc_auc: 0.962 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 14.223 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.959 | Training time: 0:00:29\n",
      "Epoch 009: | Loss: 14.718 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:00:29\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 010: | Loss: 11.488 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:00:29\n",
      "Epoch 011: | Loss: 10.712 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:00:30\n",
      "Epoch 012: | Loss: 9.422 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch    12: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 013: | Loss: 8.589 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.966\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.670 | Train acc: 0.965 | Val acc: 0.972 | Val roc_auc: 0.913 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.945 | Train acc: 0.977 | Val acc: 0.968 | Val roc_auc: 0.934 | Training time: 0:00:30\n",
      "Epoch 003: | Loss: 17.983 | Train acc: 0.977 | Val acc: 0.971 | Val roc_auc: 0.935 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 17.524 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.935 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.356 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.945 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 16.173 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.931 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 14.646 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 12.924 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 11.365 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:00:30\n",
      "Epoch 010: | Loss: 10.951 | Train acc: 0.984 | Val acc: 0.976 | Val roc_auc: 0.939 | Training time: 0:00:29\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 9.849 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 9.335 | Train acc: 0.985 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 8.942 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:00:29\n",
      "Epoch    13: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 014: | Loss: 8.557 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.943 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.160 | Train acc: 0.965 | Val acc: 0.971 | Val roc_auc: 0.931 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.672 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.990 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.856 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.929 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 16.263 | Train acc: 0.979 | Val acc: 0.970 | Val roc_auc: 0.931 | Training time: 0:00:29\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 13.635 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 12.726 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 11.720 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 10.434 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Early stopping. Best Val roc_auc: 0.948\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.873 | Train acc: 0.967 | Val acc: 0.972 | Val roc_auc: 0.936 | Training time: 0:00:30\n",
      "Epoch 002: | Loss: 19.225 | Train acc: 0.977 | Val acc: 0.973 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.626 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.030 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Epoch 005: | Loss: 15.676 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 16.026 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.666 | Train acc: 0.980 | Val acc: 0.974 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.026 | Train acc: 0.981 | Val acc: 0.972 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 13.679 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 010: | Loss: 10.864 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "OOF: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281k/281k [00:02<00:00, 109kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 49s, sys: 4min 47s, total: 30min 36s\n",
      "Wall time: 32min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_64_64_merge_BGR2GRAY(malignantOnly)\n",
    "model_name = \"PADDING_64_64_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"64_64\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [127, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initData2020() missing 1 required positional argument: 'Pre'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initData2020() missing 1 required positional argument: 'Pre'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_128_128_merge_BGR2GRAY(malignantOnly)\n",
    "model_name = \"PADDING_128_128_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [64, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exec() takes from 7 to 8 positional arguments but 9 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exec() takes from 7 to 8 positional arguments but 9 were given"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PADDING_256_256_merge_BGR2GRAY(malignantOnly)\n",
    "model_name = \"PADDING_256_256_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020()\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.672 | Train acc: 0.966 | Val acc: 0.972 | Val roc_auc: 0.928 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 18.408 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:00:29\n",
      "Epoch 003: | Loss: 17.589 | Train acc: 0.977 | Val acc: 0.972 | Val roc_auc: 0.932 | Training time: 0:00:29\n",
      "Epoch 004: | Loss: 16.706 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.934 | Training time: 0:00:28\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 14.138 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch 006: | Loss: 13.286 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:00:29\n",
      "Epoch 007: | Loss: 12.605 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.946 | Training time: 0:00:29\n",
      "Epoch 008: | Loss: 12.364 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:30\n",
      "Epoch 009: | Loss: 11.697 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 10.545 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:00:29\n",
      "Early stopping. Best Val roc_auc: 0.946\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 24.880 | Train acc: 0.968 | Val acc: 0.975 | Val roc_auc: 0.948 | Training time: 0:00:29\n",
      "Epoch 002: | Loss: 18.668 | Train acc: 0.976 | Val acc: 0.974 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.767 | Train acc: 0.978 | Val acc: 0.967 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 17.420 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 16.436 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.086 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 15.380 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.284 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 14.266 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.958 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 13.767 | Train acc: 0.982 | Val acc: 0.975 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 13.628 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 012: | Loss: 12.658 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.960 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 12.098 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch    13: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 014: | Loss: 10.499 | Train acc: 0.986 | Val acc: 0.980 | Val roc_auc: 0.962 | Training time: 0:00:28\n",
      "Epoch 015: | Loss: 8.247 | Train acc: 0.988 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:00:28\n",
      "Epoch 016: | Loss: 7.377 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.961 | Training time: 0:00:28\n",
      "Epoch 017: | Loss: 6.594 | Train acc: 0.990 | Val acc: 0.973 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 018: | Loss: 6.344 | Train acc: 0.990 | Val acc: 0.977 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 019: | Loss: 5.607 | Train acc: 0.992 | Val acc: 0.978 | Val roc_auc: 0.964 | Training time: 0:00:28\n",
      "Epoch 020: | Loss: 5.203 | Train acc: 0.993 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 25.120 | Train acc: 0.967 | Val acc: 0.977 | Val roc_auc: 0.930 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.488 | Train acc: 0.977 | Val acc: 0.977 | Val roc_auc: 0.928 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.390 | Train acc: 0.979 | Val acc: 0.958 | Val roc_auc: 0.911 | Training time: 0:00:28\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 15.411 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 13.816 | Train acc: 0.982 | Val acc: 0.977 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.221 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 007: | Loss: 12.165 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.946 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 11.659 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch     8: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 009: | Loss: 11.322 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.947 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 11.203 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 11.256 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 012: | Loss: 11.293 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.947\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 24.774 | Train acc: 0.968 | Val acc: 0.973 | Val roc_auc: 0.942 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.763 | Train acc: 0.976 | Val acc: 0.976 | Val roc_auc: 0.929 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 18.163 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.938 | Training time: 0:00:28\n",
      "Epoch     3: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 004: | Loss: 15.406 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 14.010 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 13.144 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch     6: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 007: | Loss: 12.120 | Train acc: 0.983 | Val acc: 0.976 | Val roc_auc: 0.944 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.949\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 26.178 | Train acc: 0.967 | Val acc: 0.967 | Val roc_auc: 0.914 | Training time: 0:00:28\n",
      "Epoch 002: | Loss: 18.696 | Train acc: 0.976 | Val acc: 0.972 | Val roc_auc: 0.936 | Training time: 0:00:28\n",
      "Epoch 003: | Loss: 17.651 | Train acc: 0.978 | Val acc: 0.973 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 004: | Loss: 16.799 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 005: | Loss: 15.994 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.937 | Training time: 0:00:28\n",
      "Epoch 006: | Loss: 15.792 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:00:28\n",
      "Epoch 007: | Loss: 14.637 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:00:28\n",
      "Epoch 008: | Loss: 14.016 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch 009: | Loss: 14.475 | Train acc: 0.981 | Val acc: 0.975 | Val roc_auc: 0.953 | Training time: 0:00:28\n",
      "Epoch 010: | Loss: 13.373 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:00:28\n",
      "Epoch 011: | Loss: 12.920 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.951 | Training time: 0:00:28\n",
      "Epoch    11: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 012: | Loss: 9.888 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:00:28\n",
      "Epoch 013: | Loss: 8.813 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:00:28\n",
      "Epoch 014: | Loss: 8.068 | Train acc: 0.988 | Val acc: 0.974 | Val roc_auc: 0.950 | Training time: 0:00:28\n",
      "Epoch    14: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 015: | Loss: 6.876 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.955 | Training time: 0:00:28\n",
      "Early stopping. Best Val roc_auc: 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF: 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282k/282k [00:05<00:00, 56.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 17s, sys: 4min 46s, total: 31min 3s\n",
      "Wall time: 33min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_64_64_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"64_64\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [127, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.032 | Train acc: 0.972 | Val acc: 0.962 | Val roc_auc: 0.930 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 33.780 | Train acc: 0.978 | Val acc: 0.975 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 32.439 | Train acc: 0.978 | Val acc: 0.980 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 29.797 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.947 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 28.804 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.759 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:01:15\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 23.448 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.949 | Training time: 0:01:14\n",
      "Epoch 008: | Loss: 20.699 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch 009: | Loss: 19.018 | Train acc: 0.985 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch 010: | Loss: 17.695 | Train acc: 0.987 | Val acc: 0.974 | Val roc_auc: 0.947 | Training time: 0:01:16\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.572 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.951 | Training time: 0:01:14\n",
      "Epoch 012: | Loss: 12.875 | Train acc: 0.990 | Val acc: 0.978 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Epoch 013: | Loss: 11.805 | Train acc: 0.991 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:01:14\n",
      "Epoch 014: | Loss: 11.324 | Train acc: 0.991 | Val acc: 0.977 | Val roc_auc: 0.953 | Training time: 0:01:14\n",
      "Epoch 015: | Loss: 10.261 | Train acc: 0.992 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch    15: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 016: | Loss: 8.907 | Train acc: 0.993 | Val acc: 0.976 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.554 | Train acc: 0.972 | Val acc: 0.972 | Val roc_auc: 0.938 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.433 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 31.661 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 33.129 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.961 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 30.326 | Train acc: 0.980 | Val acc: 0.980 | Val roc_auc: 0.967 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.272 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.963 | Training time: 0:01:14\n",
      "Epoch 007: | Loss: 28.235 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.400 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.969 | Training time: 0:01:14\n",
      "Epoch 009: | Loss: 20.450 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.968 | Training time: 0:01:14\n",
      "Epoch 010: | Loss: 18.052 | Train acc: 0.986 | Val acc: 0.976 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.651 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.969\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.167 | Train acc: 0.970 | Val acc: 0.977 | Val roc_auc: 0.924 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 32.737 | Train acc: 0.979 | Val acc: 0.973 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 31.603 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 29.660 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.934 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 29.193 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.935 | Training time: 0:01:14\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 23.019 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.009 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.952 | Training time: 0:01:14\n",
      "Epoch 008: | Loss: 18.119 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.948 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 15.317 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.959\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 44.295 | Train acc: 0.971 | Val acc: 0.970 | Val roc_auc: 0.934 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.470 | Train acc: 0.978 | Val acc: 0.976 | Val roc_auc: 0.945 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 31.976 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.949 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 30.258 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.943 | Training time: 0:01:14\n",
      "Epoch 005: | Loss: 28.737 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:01:14\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 23.106 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.086 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 18.181 | Train acc: 0.986 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 14.286 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.950 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.951\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 45.403 | Train acc: 0.972 | Val acc: 0.969 | Val roc_auc: 0.916 | Training time: 0:01:14\n",
      "Epoch 002: | Loss: 34.448 | Train acc: 0.978 | Val acc: 0.966 | Val roc_auc: 0.938 | Training time: 0:01:14\n",
      "Epoch 003: | Loss: 32.587 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.944 | Training time: 0:01:14\n",
      "Epoch 004: | Loss: 30.519 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 31.215 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.963 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:01:14\n",
      "Epoch 007: | Loss: 28.040 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.953 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.862 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 19.557 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 010: | Loss: 18.101 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:01:14\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.379 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:01:14\n",
      "Early stopping. Best Val roc_auc: 0.961\n",
      "OOF: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280k/280k [00:03<00:00, 89.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 35s, sys: 15min 37s, total: 1h 10min 12s\n",
      "Wall time: 1h 13min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_128_128_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [65, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.895 | Train acc: 0.972 | Val acc: 0.969 | Val roc_auc: 0.940 | Training time: 0:04:10\n",
      "Epoch 002: | Loss: 70.968 | Train acc: 0.977 | Val acc: 0.976 | Val roc_auc: 0.942 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 69.316 | Train acc: 0.979 | Val acc: 0.980 | Val roc_auc: 0.940 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 66.868 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:04:06\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 54.191 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.946 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 50.400 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.949 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 48.606 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.952 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 46.038 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 44.063 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 40.454 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 33.433 | Train acc: 0.987 | Val acc: 0.976 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 92.104 | Train acc: 0.971 | Val acc: 0.967 | Val roc_auc: 0.916 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 71.832 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 003: | Loss: 66.830 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 65.457 | Train acc: 0.980 | Val acc: 0.966 | Val roc_auc: 0.942 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 65.154 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:07\n",
      "Epoch 006: | Loss: 63.603 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:07\n",
      "Epoch 007: | Loss: 62.862 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.967 | Training time: 0:04:07\n",
      "Epoch 008: | Loss: 61.945 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.968 | Training time: 0:04:07\n",
      "Epoch 009: | Loss: 58.095 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.957 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 58.847 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.967 | Training time: 0:04:07\n",
      "Epoch    10: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 011: | Loss: 49.370 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.973 | Training time: 0:04:07\n",
      "Epoch 012: | Loss: 46.953 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.971 | Training time: 0:04:07\n",
      "Epoch 013: | Loss: 44.294 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.971 | Training time: 0:04:08\n",
      "Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 014: | Loss: 39.701 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.972 | Training time: 0:04:08\n",
      "Early stopping. Best Val roc_auc: 0.973\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.852 | Train acc: 0.971 | Val acc: 0.946 | Val roc_auc: 0.912 | Training time: 0:04:08\n",
      "Epoch 002: | Loss: 73.239 | Train acc: 0.977 | Val acc: 0.975 | Val roc_auc: 0.941 | Training time: 0:04:08\n",
      "Epoch 003: | Loss: 71.404 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:04:08\n",
      "Epoch 004: | Loss: 65.970 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.940 | Training time: 0:04:08\n",
      "Epoch 005: | Loss: 64.609 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.946 | Training time: 0:04:08\n",
      "Epoch 006: | Loss: 61.150 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.948 | Training time: 0:04:08\n",
      "Epoch 007: | Loss: 60.459 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.939 | Training time: 0:04:08\n",
      "Epoch 008: | Loss: 59.639 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:04:08\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 50.294 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:04:08\n",
      "Epoch 010: | Loss: 46.707 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.954 | Training time: 0:04:08\n",
      "Epoch 011: | Loss: 44.619 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 012: | Loss: 42.266 | Train acc: 0.985 | Val acc: 0.976 | Val roc_auc: 0.956 | Training time: 0:04:08\n",
      "Epoch 013: | Loss: 40.753 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:04:08\n",
      "Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 014: | Loss: 35.554 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:04:09\n",
      "Epoch 015: | Loss: 33.474 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 016: | Loss: 32.057 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.959 | Training time: 0:04:09\n",
      "Epoch    16: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 017: | Loss: 31.418 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:09\n",
      "Early stopping. Best Val roc_auc: 0.959\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.858 | Train acc: 0.972 | Val acc: 0.978 | Val roc_auc: 0.944 | Training time: 0:04:09\n",
      "Epoch 002: | Loss: 73.937 | Train acc: 0.977 | Val acc: 0.980 | Val roc_auc: 0.948 | Training time: 0:04:09\n",
      "Epoch 003: | Loss: 67.279 | Train acc: 0.979 | Val acc: 0.973 | Val roc_auc: 0.952 | Training time: 0:04:09\n",
      "Epoch 004: | Loss: 63.748 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:04:09\n",
      "Epoch 005: | Loss: 64.036 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.941 | Training time: 0:04:09\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 53.900 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 007: | Loss: 49.826 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 008: | Loss: 46.889 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:09\n",
      "Epoch 009: | Loss: 43.053 | Train acc: 0.984 | Val acc: 0.975 | Val roc_auc: 0.950 | Training time: 0:04:09\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 38.201 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.954 | Training time: 0:04:10\n",
      "Early stopping. Best Val roc_auc: 0.958\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.534 | Train acc: 0.972 | Val acc: 0.977 | Val roc_auc: 0.937 | Training time: 0:04:10\n",
      "Epoch 002: | Loss: 74.204 | Train acc: 0.977 | Val acc: 0.974 | Val roc_auc: 0.948 | Training time: 0:04:10\n",
      "Epoch 003: | Loss: 69.021 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.937 | Training time: 0:04:09\n",
      "Epoch 004: | Loss: 68.137 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:04:09\n",
      "Epoch 005: | Loss: 63.874 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.952 | Training time: 0:04:10\n",
      "Epoch 006: | Loss: 63.363 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.958 | Training time: 0:04:09\n",
      "Epoch 007: | Loss: 62.850 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.956 | Training time: 0:04:10\n",
      "Epoch 008: | Loss: 61.216 | Train acc: 0.980 | Val acc: 0.943 | Val roc_auc: 0.952 | Training time: 0:04:10\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 53.193 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.965 | Training time: 0:04:10\n",
      "Epoch 010: | Loss: 47.047 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.964 | Training time: 0:04:10\n",
      "Epoch 011: | Loss: 45.022 | Train acc: 0.984 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:10\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 41.640 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.963 | Training time: 0:04:10\n",
      "Early stopping. Best Val roc_auc: 0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278k/278k [00:05<00:00, 56.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 41s, sys: 1h 13min 58s, total: 4h 35min 39s\n",
      "Wall time: 4h 35min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_256_256_merge_ROTATE_90(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_90\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 64, 64] at entry 0 and [3, 91, 91] at entry 44\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0fa2c7208383>\u001b[0m in \u001b[0;36mExec\u001b[0;34m(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 64, 64] at entry 0 and [3, 91, 91] at entry 44\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_64_64_merge_ROTATE_225(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"64_64\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [127, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_225\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 128, 128] at entry 0 and [3, 181, 181] at entry 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0fa2c7208383>\u001b[0m in \u001b[0;36mExec\u001b[0;34m(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 128, 128] at entry 0 and [3, 181, 181] at entry 6\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_128_128_merge_ROTATE_225(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [65, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_225\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 256, 256] at entry 0 and [3, 362, 362] at entry 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0fa2c7208383>\u001b[0m in \u001b[0;36mExec\u001b[0;34m(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/tidal/anaconda3/envs/Melanoma_Classification/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 256, 256] at entry 0 and [3, 362, 362] at entry 5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_256_256_merge_ROTATE_225(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"ROTATE_225\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.927 | Train acc: 0.971 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.554 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.255 | Train acc: 0.979 | Val acc: 0.974 | Val roc_auc: 0.942 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 31.940 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.941 | Training time: 0:01:15\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 26.005 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 23.328 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.954 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.292 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 19.646 | Train acc: 0.986 | Val acc: 0.979 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 16.567 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.954\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.711 | Train acc: 0.973 | Val acc: 0.975 | Val roc_auc: 0.934 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 35.135 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 31.939 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.915 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 30.017 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.967 | Training time: 0:01:16\n",
      "Epoch 006: | Loss: 28.968 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:01:16\n",
      "Epoch 007: | Loss: 29.322 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.965 | Training time: 0:01:15\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 22.935 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.968 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 20.796 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.971 | Training time: 0:01:15\n",
      "Epoch 010: | Loss: 17.961 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.967 | Training time: 0:01:15\n",
      "Epoch 011: | Loss: 16.816 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.966 | Training time: 0:01:15\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 12.530 | Train acc: 0.989 | Val acc: 0.976 | Val roc_auc: 0.963 | Training time: 0:01:16\n",
      "Early stopping. Best Val roc_auc: 0.971\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.844 | Train acc: 0.972 | Val acc: 0.974 | Val roc_auc: 0.940 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.610 | Train acc: 0.978 | Val acc: 0.978 | Val roc_auc: 0.941 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.021 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.295 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.949 | Training time: 0:01:16\n",
      "Epoch 005: | Loss: 28.635 | Train acc: 0.981 | Val acc: 0.967 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch 006: | Loss: 27.869 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.947 | Training time: 0:01:16\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 22.159 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:01:16\n",
      "Epoch 008: | Loss: 19.112 | Train acc: 0.985 | Val acc: 0.977 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 009: | Loss: 17.107 | Train acc: 0.987 | Val acc: 0.974 | Val roc_auc: 0.949 | Training time: 0:01:16\n",
      "Epoch 010: | Loss: 15.875 | Train acc: 0.988 | Val acc: 0.970 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 12.664 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 45.002 | Train acc: 0.971 | Val acc: 0.974 | Val roc_auc: 0.933 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.860 | Train acc: 0.978 | Val acc: 0.979 | Val roc_auc: 0.943 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 33.039 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.949 | Training time: 0:01:15\n",
      "Epoch 004: | Loss: 31.003 | Train acc: 0.979 | Val acc: 0.972 | Val roc_auc: 0.944 | Training time: 0:01:16\n",
      "Epoch 005: | Loss: 29.689 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 24.511 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 007: | Loss: 21.373 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.948 | Training time: 0:01:15\n",
      "Epoch 008: | Loss: 19.602 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.952 | Training time: 0:01:15\n",
      "Epoch     8: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 009: | Loss: 15.939 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.950 | Training time: 0:01:15\n",
      "Early stopping. Best Val roc_auc: 0.955\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 43.579 | Train acc: 0.973 | Val acc: 0.973 | Val roc_auc: 0.945 | Training time: 0:01:15\n",
      "Epoch 002: | Loss: 34.826 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.947 | Training time: 0:01:15\n",
      "Epoch 003: | Loss: 32.623 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.954 | Training time: 0:01:16\n",
      "Epoch 004: | Loss: 30.895 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.960 | Training time: 0:01:15\n",
      "Epoch 005: | Loss: 29.714 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.955 | Training time: 0:01:15\n",
      "Epoch 006: | Loss: 28.563 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.942 | Training time: 0:01:16\n",
      "Epoch     6: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 007: | Loss: 24.721 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:01:16\n",
      "Epoch 008: | Loss: 21.443 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.962 | Training time: 0:01:16\n",
      "Epoch 009: | Loss: 20.386 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:01:16\n",
      "Epoch 010: | Loss: 17.798 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:01:15\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 14.105 | Train acc: 0.989 | Val acc: 0.978 | Val roc_auc: 0.960 | Training time: 0:01:16\n",
      "Early stopping. Best Val roc_auc: 0.962\n",
      "OOF: 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281k/281k [00:03<00:00, 81.8kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 39s, sys: 14min 41s, total: 1h 6min 20s\n",
      "Wall time: 1h 9min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_128_128_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"128_128\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [65, 32, 32] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.475 | Train acc: 0.972 | Val acc: 0.978 | Val roc_auc: 0.936 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 74.465 | Train acc: 0.977 | Val acc: 0.980 | Val roc_auc: 0.937 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 66.486 | Train acc: 0.979 | Val acc: 0.980 | Val roc_auc: 0.945 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 66.889 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.938 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 63.380 | Train acc: 0.980 | Val acc: 0.980 | Val roc_auc: 0.936 | Training time: 0:04:06\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 52.995 | Train acc: 0.982 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 49.486 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 46.823 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 44.841 | Train acc: 0.984 | Val acc: 0.980 | Val roc_auc: 0.950 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 41.863 | Train acc: 0.985 | Val acc: 0.980 | Val roc_auc: 0.951 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 36.103 | Train acc: 0.986 | Val acc: 0.978 | Val roc_auc: 0.952 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.953\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.009 | Train acc: 0.972 | Val acc: 0.975 | Val roc_auc: 0.947 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 70.192 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 70.119 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 68.307 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.938 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 65.614 | Train acc: 0.980 | Val acc: 0.979 | Val roc_auc: 0.966 | Training time: 0:04:06\n",
      "Epoch 006: | Loss: 67.500 | Train acc: 0.979 | Val acc: 0.978 | Val roc_auc: 0.959 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 61.093 | Train acc: 0.981 | Val acc: 0.978 | Val roc_auc: 0.965 | Training time: 0:04:06\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 52.809 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.969 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 50.425 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.972 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 47.979 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.970 | Training time: 0:04:06\n",
      "Epoch 011: | Loss: 46.206 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.971 | Training time: 0:04:06\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 42.974 | Train acc: 0.984 | Val acc: 0.978 | Val roc_auc: 0.969 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.972\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 88.327 | Train acc: 0.971 | Val acc: 0.976 | Val roc_auc: 0.940 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 76.511 | Train acc: 0.975 | Val acc: 0.977 | Val roc_auc: 0.943 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 66.024 | Train acc: 0.979 | Val acc: 0.976 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 004: | Loss: 66.049 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:04:06\n",
      "Epoch 005: | Loss: 64.303 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.941 | Training time: 0:04:06\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 54.505 | Train acc: 0.982 | Val acc: 0.978 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 50.404 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.955 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 48.299 | Train acc: 0.983 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 46.542 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 44.772 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 37.852 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:04:06\n",
      "Epoch 012: | Loss: 36.166 | Train acc: 0.985 | Val acc: 0.978 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch 013: | Loss: 34.061 | Train acc: 0.987 | Val acc: 0.979 | Val roc_auc: 0.958 | Training time: 0:04:06\n",
      "Epoch 014: | Loss: 32.971 | Train acc: 0.987 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Epoch 015: | Loss: 31.350 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    15: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 016: | Loss: 29.441 | Train acc: 0.988 | Val acc: 0.978 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.958\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 91.444 | Train acc: 0.971 | Val acc: 0.975 | Val roc_auc: 0.935 | Training time: 0:04:06\n",
      "Epoch 002: | Loss: 71.589 | Train acc: 0.978 | Val acc: 0.968 | Val roc_auc: 0.937 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 68.689 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.947 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 66.262 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.951 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 65.316 | Train acc: 0.979 | Val acc: 0.979 | Val roc_auc: 0.954 | Training time: 0:04:06\n",
      "Epoch 006: | Loss: 59.599 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.949 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 59.461 | Train acc: 0.981 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 51.603 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.960 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 46.863 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.953 | Training time: 0:04:06\n",
      "Epoch 010: | Loss: 45.415 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.957 | Training time: 0:04:06\n",
      "Epoch    10: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 011: | Loss: 40.424 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.956 | Training time: 0:04:06\n",
      "Early stopping. Best Val roc_auc: 0.960\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 89.409 | Train acc: 0.971 | Val acc: 0.973 | Val roc_auc: 0.948 | Training time: 0:04:07\n",
      "Epoch 002: | Loss: 69.343 | Train acc: 0.978 | Val acc: 0.972 | Val roc_auc: 0.946 | Training time: 0:04:06\n",
      "Epoch 003: | Loss: 69.309 | Train acc: 0.979 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:04:07\n",
      "Epoch 004: | Loss: 64.233 | Train acc: 0.980 | Val acc: 0.978 | Val roc_auc: 0.958 | Training time: 0:04:07\n",
      "Epoch 005: | Loss: 66.281 | Train acc: 0.978 | Val acc: 0.979 | Val roc_auc: 0.953 | Training time: 0:04:07\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 53.144 | Train acc: 0.982 | Val acc: 0.979 | Val roc_auc: 0.963 | Training time: 0:04:06\n",
      "Epoch 007: | Loss: 49.259 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.961 | Training time: 0:04:06\n",
      "Epoch 008: | Loss: 47.846 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.965 | Training time: 0:04:06\n",
      "Epoch 009: | Loss: 45.021 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.965 | Training time: 0:04:07\n",
      "Epoch 010: | Loss: 42.781 | Train acc: 0.984 | Val acc: 0.979 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch 011: | Loss: 40.446 | Train acc: 0.985 | Val acc: 0.979 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch    11: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 012: | Loss: 32.722 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.965 | Training time: 0:04:07\n",
      "Epoch 013: | Loss: 31.632 | Train acc: 0.988 | Val acc: 0.977 | Val roc_auc: 0.964 | Training time: 0:04:07\n",
      "Epoch 014: | Loss: 28.787 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.960 | Training time: 0:04:06\n",
      "Epoch    14: reducing learning rate of group 0 to 8.0000e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015: | Loss: 26.306 | Train acc: 0.989 | Val acc: 0.977 | Val roc_auc: 0.961 | Training time: 0:04:07\n",
      "Early stopping. Best Val roc_auc: 0.965\n",
      "OOF: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282k/282k [00:03<00:00, 87.7kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 43s, sys: 1h 15min 27s, total: 4h 37min 11s\n",
      "Wall time: 4h 37min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"PADDING_256_256_merge_BGR2GRAY(malignantOnly)\"\n",
    "train_folder = \"pad_jpg/train_pad/\" + model_name\n",
    "test_folder = \"pad_jpg/test/\" + \"256_256\"\n",
    "epochs = 20  # Number of epochs to run\n",
    "model_path =  Output + 'model/model_' + model_name + '.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "bat_size = [32, 16, 16] #train, val, test\n",
    "\n",
    "#データ整形\n",
    "train_df, test_df, tfrecord = initData2020(\"GR2GRAY\")\n",
    "dt = [train_df, test_df]\n",
    "[train_df, test_df] = TableDataPreprocess2020(dt)\n",
    "\n",
    "\n",
    "#実行\n",
    "test_preds, metaval_preds, metaval_ID = Exec(epochs, model_path, es_patience, TTA, bat_size, train_df, test_df, tfrecord)\n",
    "\n",
    "sns.kdeplot(pd.Series(test_preds.cpu().numpy().reshape(-1,)));\n",
    "sns.kdeplot(pd.Series(metaval_preds.reshape(-1,)));\n",
    "\n",
    "#test用\n",
    "test_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "test_ID['target'] = test_preds.cpu().numpy().reshape(-1,)\n",
    "test_ID.to_csv(Output + 'test/sub_test_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#metaval用\n",
    "#metaval_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_sub_metaval_stacking.csv')\n",
    "metaval_ID.loc[:,\"target\"] = 0\n",
    "metaval_ID['target'] = metaval_preds.reshape(-1,)\n",
    "metaval_ID.to_csv(Output + 'metaval/sub_metaval_stacking_' + model_name + '.csv', index=False)\n",
    "\n",
    "#test用submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'test/sub_test_stacking_' + model_name + '.csv'\n",
    "message = 'Imgprocessing Stacking' + model_name\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2645433471f9401e97a82e33b5b45fe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fb13192f9df4107a57f93b4e473af68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2645433471f9401e97a82e33b5b45fe8",
       "max": 31519111,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b87e4be241954e789280916c41fe05e9",
       "value": 31519111
      }
     },
     "4649c58ae866408e8875c58165600cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ee6e0abb0e449b086afdc4303ba673c",
       "placeholder": "​",
       "style": "IPY_MODEL_d6200ba71ab54fbb979ec43b1608ff2c",
       "value": " 30.1M/30.1M [00:01&lt;00:00, 24.0MB/s]"
      }
     },
     "4ee6e0abb0e449b086afdc4303ba673c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ea58d39e9dd42e28160d8de49f05d37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b87e4be241954e789280916c41fe05e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d04e0dc2878340f88e0658c17fbd600d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3fb13192f9df4107a57f93b4e473af68",
        "IPY_MODEL_4649c58ae866408e8875c58165600cf3"
       ],
       "layout": "IPY_MODEL_5ea58d39e9dd42e28160d8de49f05d37"
      }
     },
     "d6200ba71ab54fbb979ec43b1608ff2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
