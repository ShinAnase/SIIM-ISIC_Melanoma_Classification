{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtoolbox.transform as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config(kernel使うときに変更すべき変数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "melanoma_external_malignant_256 = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/melanoma_external_malignant_256/\"\n",
    "SIIM_ISIC_Melanoma_Classification = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/SIIM-ISIC-Melanoma-Classification/\"\n",
    "Output = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/Output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像処理部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least fixing some random seeds. \n",
    "# It is still impossible to make results 100% reproducible when using GPU\n",
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms = None, meta_features = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n",
    "        x = cv2.imread(im_path)\n",
    "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
    "\n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.loc[index]['target']\n",
    "            return (x, meta), y\n",
    "        else:\n",
    "            return (x, meta)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, arch, n_meta_features: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        if 'ResNet' in str(arch.__class__):\n",
    "            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
    "        if 'EfficientNet' in str(arch.__class__):\n",
    "            self.arch._fc = nn.Linear(in_features=1280, out_features=500, bias=True)\n",
    "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
    "                                  nn.BatchNorm1d(500),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(500, 250),  # FC layer output will have 50 features\n",
    "                                  nn.BatchNorm1d(250),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2))\n",
    "        self.ouput = nn.Linear(500 + 250, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x, meta = inputs\n",
    "        cnn_features = self.arch(x)\n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.Cutout(scale=(0.05, 0.007), value=(0, 0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "arch = EfficientNet.from_pretrained('efficientnet-b1')  # Going to use efficientnet-b0 NN architecture\n",
    "# skf = StratifiedKFold(n_splits=3, random_state=999, shuffle=True)\n",
    "skf = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(melanoma_external_malignant_256 + 'train_concat.csv')\n",
    "test_df = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of anatom_site_general_challenge feature\n",
    "concat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\n",
    "dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "train_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\n",
    "test_df = pd.concat([test_df, dummies.iloc[train_df.shape[0]:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Sex features\n",
    "train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\n",
    "test_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n",
    "train_df['sex'] = train_df['sex'].fillna(-1)\n",
    "test_df['sex'] = test_df['sex'].fillna(-1)\n",
    "\n",
    "# Age features\n",
    "train_df['age_approx'] /= train_df['age_approx'].max()\n",
    "test_df['age_approx'] /= test_df['age_approx'].max()\n",
    "train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
    "test_df['age_approx'] = test_df['age_approx'].fillna(0)\n",
    "\n",
    "train_df['patient_id'] = train_df['patient_id'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "meta_features.remove('anatom_site_general_challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MelanomaDataset(df=test_df,\n",
    "                       imfolder = melanoma_external_malignant_256 + 'test/test/', \n",
    "                       train=False,\n",
    "                       transforms=train_transform,\n",
    "                       meta_features=meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 114.118 | Train acc: 0.965 | Val acc: 0.943 | Val roc_auc: 0.962 | Training time: 0:04:29\n",
      "Epoch 002: | Loss: 89.910 | Train acc: 0.973 | Val acc: 0.930 | Val roc_auc: 0.965 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 87.178 | Train acc: 0.974 | Val acc: 0.945 | Val roc_auc: 0.971 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 81.887 | Train acc: 0.976 | Val acc: 0.947 | Val roc_auc: 0.965 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 79.648 | Train acc: 0.976 | Val acc: 0.959 | Val roc_auc: 0.978 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 78.084 | Train acc: 0.976 | Val acc: 0.949 | Val roc_auc: 0.975 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 75.031 | Train acc: 0.977 | Val acc: 0.946 | Val roc_auc: 0.974 | Training time: 0:04:30\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 60.893 | Train acc: 0.981 | Val acc: 0.950 | Val roc_auc: 0.974 | Training time: 0:04:30\n",
      "Early stopping. Best Val roc_auc: 0.978\n",
      "==================== Fold 2 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 122.510 | Train acc: 0.958 | Val acc: 0.971 | Val roc_auc: 0.955 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 101.052 | Train acc: 0.968 | Val acc: 0.970 | Val roc_auc: 0.969 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 94.338 | Train acc: 0.970 | Val acc: 0.976 | Val roc_auc: 0.972 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 88.417 | Train acc: 0.972 | Val acc: 0.971 | Val roc_auc: 0.969 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 86.979 | Train acc: 0.972 | Val acc: 0.976 | Val roc_auc: 0.969 | Training time: 0:04:30\n",
      "Epoch     5: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 006: | Loss: 68.550 | Train acc: 0.978 | Val acc: 0.977 | Val roc_auc: 0.976 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 62.647 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.976 | Training time: 0:04:30\n",
      "Epoch 008: | Loss: 60.345 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.976 | Training time: 0:04:30\n",
      "Epoch 009: | Loss: 58.184 | Train acc: 0.981 | Val acc: 0.976 | Val roc_auc: 0.975 | Training time: 0:04:30\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 49.870 | Train acc: 0.983 | Val acc: 0.977 | Val roc_auc: 0.977 | Training time: 0:04:30\n",
      "==================== Fold 3 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 122.470 | Train acc: 0.961 | Val acc: 0.964 | Val roc_auc: 0.953 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 95.796 | Train acc: 0.970 | Val acc: 0.964 | Val roc_auc: 0.959 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 90.747 | Train acc: 0.971 | Val acc: 0.967 | Val roc_auc: 0.962 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 87.368 | Train acc: 0.972 | Val acc: 0.972 | Val roc_auc: 0.964 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 82.650 | Train acc: 0.975 | Val acc: 0.966 | Val roc_auc: 0.960 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 82.282 | Train acc: 0.974 | Val acc: 0.971 | Val roc_auc: 0.966 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 78.912 | Train acc: 0.975 | Val acc: 0.962 | Val roc_auc: 0.958 | Training time: 0:04:30\n",
      "Epoch 008: | Loss: 76.468 | Train acc: 0.975 | Val acc: 0.965 | Val roc_auc: 0.961 | Training time: 0:04:30\n",
      "Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 009: | Loss: 61.713 | Train acc: 0.980 | Val acc: 0.977 | Val roc_auc: 0.973 | Training time: 0:04:30\n",
      "Epoch 010: | Loss: 57.391 | Train acc: 0.981 | Val acc: 0.971 | Val roc_auc: 0.972 | Training time: 0:04:30\n",
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 117.295 | Train acc: 0.961 | Val acc: 0.969 | Val roc_auc: 0.962 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 95.982 | Train acc: 0.968 | Val acc: 0.969 | Val roc_auc: 0.964 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 90.441 | Train acc: 0.972 | Val acc: 0.972 | Val roc_auc: 0.962 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 84.567 | Train acc: 0.972 | Val acc: 0.975 | Val roc_auc: 0.965 | Training time: 0:04:30\n",
      "Epoch 005: | Loss: 81.993 | Train acc: 0.974 | Val acc: 0.971 | Val roc_auc: 0.967 | Training time: 0:04:30\n",
      "Epoch 006: | Loss: 77.367 | Train acc: 0.975 | Val acc: 0.973 | Val roc_auc: 0.967 | Training time: 0:04:30\n",
      "Epoch 007: | Loss: 77.098 | Train acc: 0.975 | Val acc: 0.969 | Val roc_auc: 0.965 | Training time: 0:04:30\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 008: | Loss: 63.952 | Train acc: 0.979 | Val acc: 0.975 | Val roc_auc: 0.969 | Training time: 0:04:30\n",
      "Epoch 009: | Loss: 57.703 | Train acc: 0.981 | Val acc: 0.977 | Val roc_auc: 0.971 | Training time: 0:04:30\n",
      "Epoch 010: | Loss: 53.535 | Train acc: 0.982 | Val acc: 0.976 | Val roc_auc: 0.972 | Training time: 0:04:30\n",
      "==================== Fold 5 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Epoch 001: | Loss: 119.833 | Train acc: 0.961 | Val acc: 0.948 | Val roc_auc: 0.923 | Training time: 0:04:30\n",
      "Epoch 002: | Loss: 98.083 | Train acc: 0.969 | Val acc: 0.958 | Val roc_auc: 0.964 | Training time: 0:04:30\n",
      "Epoch 003: | Loss: 90.603 | Train acc: 0.971 | Val acc: 0.972 | Val roc_auc: 0.964 | Training time: 0:04:30\n",
      "Epoch 004: | Loss: 86.539 | Train acc: 0.973 | Val acc: 0.961 | Val roc_auc: 0.948 | Training time: 0:04:30\n",
      "Epoch     4: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 005: | Loss: 69.377 | Train acc: 0.978 | Val acc: 0.971 | Val roc_auc: 0.973 | Training time: 0:04:31\n",
      "Epoch 006: | Loss: 62.351 | Train acc: 0.980 | Val acc: 0.973 | Val roc_auc: 0.974 | Training time: 0:04:31\n",
      "Epoch 007: | Loss: 60.470 | Train acc: 0.980 | Val acc: 0.976 | Val roc_auc: 0.975 | Training time: 0:04:31\n",
      "Epoch 008: | Loss: 57.610 | Train acc: 0.981 | Val acc: 0.974 | Val roc_auc: 0.975 | Training time: 0:04:30\n",
      "Epoch 009: | Loss: 53.659 | Train acc: 0.982 | Val acc: 0.973 | Val roc_auc: 0.974 | Training time: 0:04:30\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 010: | Loss: 47.712 | Train acc: 0.983 | Val acc: 0.974 | Val roc_auc: 0.975 | Training time: 0:04:31\n",
      "Early stopping. Best Val roc_auc: 0.975\n",
      "CPU times: user 2h 42min 57s, sys: 1h 50s, total: 3h 43min 48s\n",
      "Wall time: 3h 44min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10  # Number of epochs to run\n",
    "model_path = Output + 'model.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "\n",
    "oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test test\n",
    "\n",
    "# We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "# We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "# since we only need `y` to stratify the data\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "    print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "    \n",
    "    best_val = None  # Best validation score within this fold\n",
    "    patience = es_patience  # Current patience counter\n",
    "    arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "    model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True), \n",
    "                            imfolder= melanoma_external_malignant_256 + 'train/train/',  \n",
    "                            train=True, \n",
    "                            transforms=train_transform,\n",
    "                            meta_features=meta_features)\n",
    "    val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True), \n",
    "                            imfolder= melanoma_external_malignant_256 + 'train/train/', \n",
    "                            train=True, \n",
    "                            transforms=test_transform,\n",
    "                            meta_features=meta_features)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(dataset=val, batch_size=16, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=16, shuffle=False, num_workers=2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "            x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            optim.zero_grad()\n",
    "            z = model(x)\n",
    "            loss = criterion(z, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            \n",
    "        train_acc = correct / len(train_idx)\n",
    "\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "            # Predicting on validation set\n",
    "            for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                z_val = model(x_val)\n",
    "                val_pred = torch.sigmoid(z_val)\n",
    "                val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "            val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "            val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "            \n",
    "            print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "            epoch + 1, \n",
    "            epoch_loss, \n",
    "            train_acc, \n",
    "            val_acc, \n",
    "            val_roc, \n",
    "            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "            \n",
    "            scheduler.step(val_roc)\n",
    "            # During the first iteration (first epoch) best validation is set to None\n",
    "            if not best_val:\n",
    "                best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                torch.save(model, model_path)  # Saving the model\n",
    "                continue\n",
    "                \n",
    "            if val_roc >= best_val:\n",
    "                best_val = val_roc\n",
    "                patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                torch.save(model, model_path)  # Saving current best model\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                    break\n",
    "                \n",
    "    model = torch.load(model_path)  # Loading best model of this fold\n",
    "    model.eval()  # switch model to the evaluation mode\n",
    "    val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        # Predicting on validation set once again to obtain data for OOF\n",
    "        for j, (x_val, y_val) in enumerate(val_loader):\n",
    "            x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "            x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "            z_val = model(x_val)\n",
    "            val_pred = torch.sigmoid(z_val)\n",
    "            val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "        oof[val_idx] = val_preds.cpu().numpy()\n",
    "        \n",
    "        # Predicting on test set\n",
    "        for _ in range(TTA):\n",
    "            for i, x_test in enumerate(test_loader):\n",
    "                x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                z_test = model(x_test)\n",
    "                z_test = torch.sigmoid(z_test)\n",
    "                preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "        preds /= TTA\n",
    "        \n",
    "    del train, val, train_loader, val_loader, x, y, x_val, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "preds /= skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF: 0.975\n"
     ]
    }
   ],
   "source": [
    "print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(pd.Series(preds.cpu().numpy().reshape(-1,)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ID = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "sub_ID['target'] = preds.cpu().numpy().reshape(-1,)\n",
    "sub_ID.to_csv(Output + 'submission_ID.csv', index=False)\n",
    "\n",
    "#画像認識モデルのみの投稿(基本はコメントアウト)\n",
    "#sub.to_csv(Output + 'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TableDataモデル部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33126, 8), (10982, 5), (10982, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TD = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train.csv')\n",
    "test_TD  = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "sub_TD   = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "\n",
    "train_TD.shape, test_TD.shape, sub_TD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TD['sex'] = train_TD['sex'].fillna('na')\n",
    "train_TD['age_approx'] = train_TD['age_approx'].fillna(0)\n",
    "train_TD['anatom_site_general_challenge'] = train_TD['anatom_site_general_challenge'].fillna('na')\n",
    "\n",
    "test_TD['sex'] = test_TD['sex'].fillna('na')\n",
    "test_TD['age_approx'] = test_TD['age_approx'].fillna(0)\n",
    "test_TD['anatom_site_general_challenge'] = test_TD['anatom_site_general_challenge'].fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>IP_6375035</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>IP_0589375</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                            na\n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity\n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso\n",
       "3  ISIC_0073313  IP_6375035  female        50.0                         torso\n",
       "4  ISIC_0073502  IP_0589375  female        45.0               lower extremity"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_TD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33126, 8), (10982, 5), (10982, 2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TD.shape, test_TD.shape, sub_TD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>na</td>\n",
       "      <td>0.008530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>IP_6375035</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>IP_0589375</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0.007548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                            na   \n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity   \n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso   \n",
       "3  ISIC_0073313  IP_6375035  female        50.0                         torso   \n",
       "4  ISIC_0073502  IP_0589375  female        45.0               lower extremity   \n",
       "\n",
       "         ll  \n",
       "0  0.008530  \n",
       "1  0.008428  \n",
       "2  0.014630  \n",
       "3  0.008416  \n",
       "4  0.007548  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 15\n",
    "feat = ['sex','age_approx','anatom_site_general_challenge']\n",
    "\n",
    "M = train_TD.target.mean()\n",
    "te = train_TD.groupby(feat)['target'].agg(['mean','count']).reset_index()\n",
    "te['ll'] = ((te['mean']*te['count'])+(M*L))/(te['count']+L)\n",
    "del te['mean'], te['count']\n",
    "\n",
    "test_TD = test_TD.merge( te, on=feat, how='left' )\n",
    "test_TD['ll'] = test_TD['ll'].fillna(M)\n",
    "\n",
    "test_TD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33126, 8), (10982, 6), (10982, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TD.shape, test_TD.shape, sub_TD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.008530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.007548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC_0074618</td>\n",
       "      <td>0.013768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISIC_0076801</td>\n",
       "      <td>0.022767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISIC_0077586</td>\n",
       "      <td>0.013768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISIC_0082004</td>\n",
       "      <td>0.015127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISIC_0082785</td>\n",
       "      <td>0.018668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_0052060  0.008530\n",
       "1  ISIC_0052349  0.008428\n",
       "2  ISIC_0058510  0.014630\n",
       "3  ISIC_0073313  0.008416\n",
       "4  ISIC_0073502  0.007548\n",
       "5  ISIC_0074618  0.013768\n",
       "6  ISIC_0076801  0.022767\n",
       "7  ISIC_0077586  0.013768\n",
       "8  ISIC_0082004  0.015127\n",
       "9  ISIC_0082785  0.018668"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_TD.target = test_TD.ll.values\n",
    "sub_TD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table dataモデルのpred\n",
    "sub_TD.to_csv(Output + 'submission_TD.csv', index=False)\n",
    "\n",
    "#table dataモデルのみの投稿(基本はコメントアウトすること。)\n",
    "#sub_TD.to_csv(Output + 'submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.008530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.007548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_0052060  0.008530\n",
       "1  ISIC_0052349  0.008428\n",
       "2  ISIC_0058510  0.014630\n",
       "3  ISIC_0073313  0.008416\n",
       "4  ISIC_0073502  0.007548"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sub = pd.read_csv(Output + 'submission_ID.csv')\n",
    "tabular_sub = pd.read_csv(Output + 'submission_TD.csv')\n",
    "tabular_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = image_sub.copy()\n",
    "sub.target = 0.9 * image_sub.target.values + 0.1 * tabular_sub.target.values\n",
    "sub.to_csv(Output + 'submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sub.target,bins=100)\n",
    "plt.ylim((0,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit(ここより先はkernelで入れなくて良い)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367k/367k [00:04<00:00, 85.9kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "csv_file_path = Output + 'submission.csv'\n",
    "message = 'first submit in local (Ensemble)'\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08559d17ed474da99a585584672cf77b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "14462874eaf1448cbaa4afdd027abee5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a4754ad6e5e44abb30eaa96ec39e253": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d416cf154ef43ceb78aa6f7dc0b28dd",
        "IPY_MODEL_de521914c10a451baa146eac6c395237"
       ],
       "layout": "IPY_MODEL_f0c6055ed5f247f8a44c79630930aa64"
      }
     },
     "5d416cf154ef43ceb78aa6f7dc0b28dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14462874eaf1448cbaa4afdd027abee5",
       "max": 31519111,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_99444e94fd4c4e34951fdb63ccf08e07",
       "value": 31519111
      }
     },
     "7e9cfd70314c445eaba91b88ea44c936": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99444e94fd4c4e34951fdb63ccf08e07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "de521914c10a451baa146eac6c395237": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7e9cfd70314c445eaba91b88ea44c936",
       "placeholder": "​",
       "style": "IPY_MODEL_08559d17ed474da99a585584672cf77b",
       "value": " 30.1M/30.1M [00:03&lt;00:00, 8.96MB/s]"
      }
     },
     "f0c6055ed5f247f8a44c79630930aa64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
