{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__verSN:1__<br>\n",
    "__Image__<br>\n",
    "metaval:resizeのみ<br>\n",
    "192_192：OOF: 0.869 Wall time:  1h 33min LB: 0.861<br>\n",
    "224_224：OOF: 0.883 Wall time:  2h 07min LB: 0.862<br>\n",
    "256_256：OOF: 0.875 Wall time:  2h 36min LB: 0.882<br>\n",
    "382_382：OOF: 0.869 Wall time:  5h 10min LB: 0.854<br>\n",
    "512_512：OOF: 0.848 Wall time: 10h 29min LB: 0.852<br>\n",
    "__Table__<br>\n",
    "patientid有、isnan有<br>\n",
    "lgb: CV mean score: 0.7306, std: 0.0175., LB: 0.6637<br>\n",
    "SVC: CV mean score: 0.6622, std: 0.0276., LB: 0.6637<br>\n",
    "__Blending__<br>\n",
    "blending model<br>\n",
    "lgb: CV mean score: 0.8838, std: 0.0172., LB: 0.8642<br>\n",
    "SVC: CV mean score: 0.8103, std: 0.0634., LB: 0.8342<br>\n",
    "BayesianOptimization<br>\n",
    "init_points = 50, n_iter = 10, CV:0.8981, LB:0.8811<br>\n",
    "init_points = 50, n_iter = 40, CV:0.8981, LB:0.8989<br>\n",
    "init_points = 100, n_iter = 30, CV:0.8983, LB:0.8813<br>\n",
    "__verSN:3__<br>\n",
    "__Stacking__<br>\n",
    "Stacking model<br>\n",
    "第一層最高スコア：\n",
    "192_192：OOF: 0.893 Wall time: 2h 10min 17s LB: 0.8813<br>\n",
    "BayesianOptimization<br>\n",
    "init_points = 100, n_iter = 30, CV:0.9160, LB:0.8874<br>\n",
    "init_points = 50, n_iter = 40, CV:0.9159, LB:0.8875<br>\n",
    "__verSN:4__<br>\n",
    "tfrecordによるfold + epoch20<br>\n",
    "第一層最高スコア：\n",
    "128_128：OOF: 0.882 Wall time: 1h 20min 49s LB:0.8929 <br>\n",
    "BayesianOptimization<br>\n",
    "init_points = 50, n_iter = 40, CV:0.9042, LB:0.8945<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__initialize__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "from  bayes_opt  import  BayesianOptimization\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "melanoma_external_malignant_256 = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/melanoma_external_malignant_256/\"\n",
    "SIIM_ISIC_Melanoma_Classification = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/SIIM-ISIC-Melanoma-Classification/\"\n",
    "Output = \"/home/tidal/ML_Data/SIIM-ISIC_Melanoma_Classification/Output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習用(metaval)/予測用(test)のテーブルデータ作成\n",
    "def generateTable(modelMtx, TrainOrTest):\n",
    "    if TrainOrTest == \"test\":\n",
    "        folder = 'test/sub_test_'\n",
    "        Table = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'test.csv')\n",
    "        Table = Table[[\"image_name\"]]\n",
    "        \n",
    "    elif TrainOrTest == \"train\":\n",
    "        folder = 'metaval/sub_metaval_'\n",
    "        #Table = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'metaval.csv')\n",
    "        Table = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'train.csv')\n",
    "        Table = Table[Table.tfrecord != -1]\n",
    "        Table = Table.reset_index(drop=True)\n",
    "        Table = Table[[\"image_name\", \"target\"]]\n",
    "    else:\n",
    "        print(\"err:TrainOrTest is only 'train' or 'test'\")\n",
    "    \n",
    "    for modelNM in modelMtx:\n",
    "        Tb_temp = pd.read_csv(Output + folder + modelNM + '.csv')\n",
    "        Tb_temp = Tb_temp.rename(columns={'target':'pred_' + modelNM})\n",
    "        Table = pd.merge(Table, Tb_temp, on=\"image_name\", how=\"inner\")\n",
    "    \n",
    "    return Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMtx = ['stacking_64_64', 'stacking_96_96', 'stacking_128_128', 'stacking_160_160', 'stacking_192_192']\n",
    "MVTable = generateTable(modelMtx = modelMtx, TrainOrTest = \"train\")\n",
    "TestTable = generateTable(modelMtx = modelMtx, TrainOrTest = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_stacking_64_64</th>\n",
       "      <th>pred_stacking_96_96</th>\n",
       "      <th>pred_stacking_128_128</th>\n",
       "      <th>pred_stacking_160_160</th>\n",
       "      <th>pred_stacking_192_192</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>0</td>\n",
       "      <td>2.542518e-04</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>0</td>\n",
       "      <td>5.107879e-05</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>0</td>\n",
       "      <td>2.654362e-05</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>0</td>\n",
       "      <td>3.180563e-04</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>0</td>\n",
       "      <td>3.063538e-09</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>ISIC_9999134</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32688</th>\n",
       "      <td>ISIC_9999320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32689</th>\n",
       "      <td>ISIC_9999515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32690</th>\n",
       "      <td>ISIC_9999666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32691</th>\n",
       "      <td>ISIC_9999806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32692 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  target  pred_stacking_64_64  pred_stacking_96_96  \\\n",
       "0      ISIC_2637011       0         2.542518e-04             0.000073   \n",
       "1      ISIC_0015719       0         5.107879e-05             0.000150   \n",
       "2      ISIC_0052212       0         2.654362e-05             0.000030   \n",
       "3      ISIC_0068279       0         3.180563e-04             0.000102   \n",
       "4      ISIC_0074268       0         3.063538e-09             0.000274   \n",
       "...             ...     ...                  ...                  ...   \n",
       "32687  ISIC_9999134       0         0.000000e+00             0.000000   \n",
       "32688  ISIC_9999320       0         0.000000e+00             0.000000   \n",
       "32689  ISIC_9999515       0         0.000000e+00             0.000000   \n",
       "32690  ISIC_9999666       0         0.000000e+00             0.000000   \n",
       "32691  ISIC_9999806       0         0.000000e+00             0.000000   \n",
       "\n",
       "       pred_stacking_128_128  pred_stacking_160_160  pred_stacking_192_192  \n",
       "0                   0.000663               0.000280               0.000244  \n",
       "1                   0.000019               0.000006               0.000026  \n",
       "2                   0.000012               0.000096               0.000296  \n",
       "3                   0.000027               0.003673               0.000306  \n",
       "4                   0.000276               0.000248               0.000066  \n",
       "...                      ...                    ...                    ...  \n",
       "32687               0.000000               0.000000               0.000000  \n",
       "32688               0.000000               0.000000               0.000000  \n",
       "32689               0.000000               0.000000               0.000000  \n",
       "32690               0.000000               0.000000               0.000000  \n",
       "32691               0.000000               0.000000               0.000000  \n",
       "\n",
       "[32692 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_stacking_64_64</th>\n",
       "      <th>pred_stacking_96_96</th>\n",
       "      <th>pred_stacking_128_128</th>\n",
       "      <th>pred_stacking_160_160</th>\n",
       "      <th>pred_stacking_192_192</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ISIC_0149568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ISIC_0188432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131746</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.070242</td>\n",
       "      <td>0.018949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ISIC_0207268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.006436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ISIC_0232101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064557</td>\n",
       "      <td>0.057155</td>\n",
       "      <td>0.030839</td>\n",
       "      <td>0.038145</td>\n",
       "      <td>0.038472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ISIC_0247330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32409</th>\n",
       "      <td>ISIC_9910791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0.261981</td>\n",
       "      <td>0.116740</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>0.020905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>ISIC_9955163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.122747</td>\n",
       "      <td>0.055658</td>\n",
       "      <td>0.061902</td>\n",
       "      <td>0.120427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32567</th>\n",
       "      <td>ISIC_9963177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.003498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32616</th>\n",
       "      <td>ISIC_9978107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32683</th>\n",
       "      <td>ISIC_9998682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  target  pred_stacking_64_64  pred_stacking_96_96  \\\n",
       "91     ISIC_0149568       1             0.000148             0.000089   \n",
       "235    ISIC_0188432       1             0.131746             0.023332   \n",
       "314    ISIC_0207268       1             0.003509             0.001744   \n",
       "399    ISIC_0232101       1             0.064557             0.057155   \n",
       "459    ISIC_0247330       1             0.007008             0.002558   \n",
       "...             ...     ...                  ...                  ...   \n",
       "32409  ISIC_9910791       1             0.026637             0.261981   \n",
       "32536  ISIC_9955163       1             0.019845             0.122747   \n",
       "32567  ISIC_9963177       1             0.005939             0.008116   \n",
       "32616  ISIC_9978107       1             0.000000             0.000000   \n",
       "32683  ISIC_9998682       1             0.000000             0.000000   \n",
       "\n",
       "       pred_stacking_128_128  pred_stacking_160_160  pred_stacking_192_192  \n",
       "91                  0.000080               0.000134               0.000361  \n",
       "235                 0.060053               0.070242               0.018949  \n",
       "314                 0.006967               0.002109               0.006436  \n",
       "399                 0.030839               0.038145               0.038472  \n",
       "459                 0.003712               0.000059               0.002430  \n",
       "...                      ...                    ...                    ...  \n",
       "32409               0.116740               0.023513               0.020905  \n",
       "32536               0.055658               0.061902               0.120427  \n",
       "32567               0.020201               0.001160               0.003498  \n",
       "32616               0.000000               0.000000               0.000000  \n",
       "32683               0.000000               0.000000               0.000000  \n",
       "\n",
       "[581 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVTable[MVTable.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>pred_stacking_64_64</th>\n",
       "      <th>pred_stacking_96_96</th>\n",
       "      <th>pred_stacking_128_128</th>\n",
       "      <th>pred_stacking_160_160</th>\n",
       "      <th>pred_stacking_192_192</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>9.026283e-07</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.754260e-05</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6.276972e-07</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2.867150e-06</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>2.446350e-05</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  pred_stacking_64_64  pred_stacking_96_96  \\\n",
       "0      ISIC_0052060             0.001755             0.000083   \n",
       "1      ISIC_0052349             0.000156             0.000007   \n",
       "2      ISIC_0058510             0.000072             0.000006   \n",
       "3      ISIC_0073313             0.000080             0.000036   \n",
       "4      ISIC_0073502             0.000166             0.000008   \n",
       "...             ...                  ...                  ...   \n",
       "10977  ISIC_9992485             0.000000             0.000000   \n",
       "10978  ISIC_9996992             0.000000             0.000000   \n",
       "10979  ISIC_9997917             0.000000             0.000000   \n",
       "10980  ISIC_9998234             0.000000             0.000000   \n",
       "10981  ISIC_9999302             0.000000             0.000000   \n",
       "\n",
       "       pred_stacking_128_128  pred_stacking_160_160  pred_stacking_192_192  \n",
       "0                   0.000028           9.026283e-07               0.000046  \n",
       "1                   0.000007           1.754260e-05               0.000009  \n",
       "2                   0.000009           6.276972e-07               0.000016  \n",
       "3                   0.000028           2.867150e-06               0.000012  \n",
       "4                   0.000068           2.446350e-05               0.000073  \n",
       "...                      ...                    ...                    ...  \n",
       "10977               0.000000           0.000000e+00               0.000000  \n",
       "10978               0.000000           0.000000e+00               0.000000  \n",
       "10979               0.000000           0.000000e+00               0.000000  \n",
       "10980               0.000000           0.000000e+00               0.000000  \n",
       "10981               0.000000           0.000000e+00               0.000000  \n",
       "\n",
       "[10982 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes test\n",
    "#parameter(重み)の範囲を定義。\n",
    "params = {}\n",
    "for c in MVTable.columns.drop(['target','image_name']):\n",
    "    params[c] = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_stacking_64_64': (0, 1),\n",
       " 'pred_stacking_96_96': (0, 1),\n",
       " 'pred_stacking_128_128': (0, 1),\n",
       " 'pred_stacking_160_160': (0, 1),\n",
       " 'pred_stacking_192_192': (0, 1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最大化させたい関数\n",
    "def ROC_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    s = sum(params.values())\n",
    "    for p in params:\n",
    "        params[p] = params[p] / s\n",
    "    \n",
    "    test_pred_proba = pd.Series(np.zeros(MVTable.shape[0]), index = MVTable.index)\n",
    "    \n",
    "    feats = [f for f in MVTable.columns if f not in ['target','image_name', 'index']]\n",
    "    \n",
    "    for f in feats:\n",
    "        test_pred_proba += MVTable[f] * params[f]\n",
    "    \n",
    "    return roc_auc_score(MVTable['target'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitBayesian(MVTable, TestTable, init_points, n_iter):\n",
    "    params = {}\n",
    "    for c in MVTable.columns.drop(['target','image_name']):\n",
    "        params[c] = (0, 1)\n",
    "        \n",
    "    bo = BayesianOptimization(ROC_evaluate, params)\n",
    "    #init_points:random explorationのステップ数。exploration space(探索空間)に多様性をもたらす。\n",
    "    #n_iter:bayesian optimizationのステップ数\n",
    "    bo.maximize(init_points = init_points, n_iter = n_iter)\n",
    "    best_params = bo.max['params']\n",
    "    best_normalized_params = {}\n",
    "    \n",
    "    s = sum(best_params.values())\n",
    "    for p in best_params:\n",
    "        best_normalized_params[p] = best_params[p] / s\n",
    "\n",
    "    prediction_train = pd.Series(np.zeros(MVTable.shape[0]), index = MVTable.index)\n",
    "    prediction_test = pd.Series(np.zeros(TestTable.shape[0]), index = TestTable.index)\n",
    "        \n",
    "    feats = [f for f in MVTable.columns if f not in ['target','image_name', 'index']]\n",
    "        \n",
    "    for f in feats:\n",
    "        prediction_train += MVTable[f] * best_normalized_params[f]\n",
    "        prediction_test += TestTable[f] * best_normalized_params[f]\n",
    "        \n",
    "    train_score = roc_auc_score(MVTable['target'], prediction_train)\n",
    "    \n",
    "    print(\"init_points = {0}, n_iter = {1}, CV:{2:.4f}\".format(init_points, n_iter, train_score))\n",
    "    \n",
    "    return prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | pred_s... | pred_s... | pred_s... | pred_s... | pred_s... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 0.4044  \u001b[0m | \u001b[0m 0.0514  \u001b[0m | \u001b[0m 0.7695  \u001b[0m | \u001b[0m 0.6805  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.903   \u001b[0m | \u001b[95m 0.7337  \u001b[0m | \u001b[95m 0.8063  \u001b[0m | \u001b[95m 0.4057  \u001b[0m | \u001b[95m 0.3047  \u001b[0m | \u001b[95m 0.9222  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.902   \u001b[0m | \u001b[0m 0.4252  \u001b[0m | \u001b[0m 0.09007 \u001b[0m | \u001b[0m 0.533   \u001b[0m | \u001b[0m 0.2399  \u001b[0m | \u001b[0m 0.06763 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.901   \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.02843 \u001b[0m | \u001b[0m 0.6945  \u001b[0m | \u001b[0m 0.3627  \u001b[0m | \u001b[0m 0.5965  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9025  \u001b[0m | \u001b[0m 0.8843  \u001b[0m | \u001b[0m 0.7334  \u001b[0m | \u001b[0m 0.2972  \u001b[0m | \u001b[0m 0.06735 \u001b[0m | \u001b[0m 0.8095  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9028  \u001b[0m | \u001b[0m 0.07702 \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.3497  \u001b[0m | \u001b[0m 0.2601  \u001b[0m | \u001b[0m 0.1635  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9026  \u001b[0m | \u001b[0m 0.2996  \u001b[0m | \u001b[0m 0.6433  \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.8261  \u001b[0m | \u001b[0m 0.03255 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9027  \u001b[0m | \u001b[0m 0.8377  \u001b[0m | \u001b[0m 0.334   \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.2817  \u001b[0m | \u001b[0m 0.8251  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.9041  \u001b[0m | \u001b[95m 0.8398  \u001b[0m | \u001b[95m 0.8484  \u001b[0m | \u001b[95m 0.5274  \u001b[0m | \u001b[95m 0.4957  \u001b[0m | \u001b[95m 0.152   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9037  \u001b[0m | \u001b[0m 0.2252  \u001b[0m | \u001b[0m 0.6774  \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 0.2449  \u001b[0m | \u001b[0m 0.3276  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.903   \u001b[0m | \u001b[0m 0.593   \u001b[0m | \u001b[0m 0.5554  \u001b[0m | \u001b[0m 0.9792  \u001b[0m | \u001b[0m 0.882   \u001b[0m | \u001b[0m 0.5541  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.7396  \u001b[0m | \u001b[0m 0.5301  \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.4785  \u001b[0m | \u001b[0m 0.7804  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9029  \u001b[0m | \u001b[0m 0.3122  \u001b[0m | \u001b[0m 0.3487  \u001b[0m | \u001b[0m 0.7041  \u001b[0m | \u001b[0m 0.2778  \u001b[0m | \u001b[0m 0.5775  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9017  \u001b[0m | \u001b[0m 0.2558  \u001b[0m | \u001b[0m 0.4659  \u001b[0m | \u001b[0m 0.4587  \u001b[0m | \u001b[0m 0.4493  \u001b[0m | \u001b[0m 0.9628  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9029  \u001b[0m | \u001b[0m 0.1662  \u001b[0m | \u001b[0m 0.481   \u001b[0m | \u001b[0m 0.2691  \u001b[0m | \u001b[0m 0.231   \u001b[0m | \u001b[0m 0.4536  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.901   \u001b[0m | \u001b[0m 0.8418  \u001b[0m | \u001b[0m 0.04086 \u001b[0m | \u001b[0m 0.4046  \u001b[0m | \u001b[0m 0.2036  \u001b[0m | \u001b[0m 0.4719  \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.9041  \u001b[0m | \u001b[95m 0.7286  \u001b[0m | \u001b[95m 0.8564  \u001b[0m | \u001b[95m 0.9924  \u001b[0m | \u001b[95m 0.3205  \u001b[0m | \u001b[95m 0.3689  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9024  \u001b[0m | \u001b[0m 0.5757  \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 0.07248 \u001b[0m | \u001b[0m 0.1138  \u001b[0m | \u001b[0m 0.1333  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9022  \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.2279  \u001b[0m | \u001b[0m 0.6422  \u001b[0m | \u001b[0m 0.06044 \u001b[0m | \u001b[0m 0.6474  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.899   \u001b[0m | \u001b[0m 0.161   \u001b[0m | \u001b[0m 0.9587  \u001b[0m | \u001b[0m 0.03907 \u001b[0m | \u001b[0m 0.8118  \u001b[0m | \u001b[0m 0.9576  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9014  \u001b[0m | \u001b[0m 0.6488  \u001b[0m | \u001b[0m 0.323   \u001b[0m | \u001b[0m 0.4437  \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 0.6083  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 0.3233  \u001b[0m | \u001b[0m 0.4534  \u001b[0m | \u001b[0m 0.1666  \u001b[0m | \u001b[0m 0.4522  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9021  \u001b[0m | \u001b[0m 0.3448  \u001b[0m | \u001b[0m 0.5048  \u001b[0m | \u001b[0m 0.126   \u001b[0m | \u001b[0m 0.599   \u001b[0m | \u001b[0m 0.1179  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9016  \u001b[0m | \u001b[0m 0.5224  \u001b[0m | \u001b[0m 0.1411  \u001b[0m | \u001b[0m 0.9276  \u001b[0m | \u001b[0m 0.3651  \u001b[0m | \u001b[0m 0.07757 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9008  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.1399  \u001b[0m | \u001b[0m 0.8945  \u001b[0m | \u001b[0m 0.9581  \u001b[0m | \u001b[0m 0.06487 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.7514  \u001b[0m | \u001b[0m 0.9888  \u001b[0m | \u001b[0m 0.5665  \u001b[0m | \u001b[0m 0.3526  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 0.4338  \u001b[0m | \u001b[0m 0.9887  \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 0.8609  \u001b[0m | \u001b[0m 0.8932  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9028  \u001b[0m | \u001b[0m 0.5554  \u001b[0m | \u001b[0m 0.6111  \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 0.9637  \u001b[0m | \u001b[0m 0.5784  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9025  \u001b[0m | \u001b[0m 0.5035  \u001b[0m | \u001b[0m 0.5085  \u001b[0m | \u001b[0m 0.5267  \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.7661  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.5961  \u001b[0m | \u001b[0m 0.2766  \u001b[0m | \u001b[0m 0.2812  \u001b[0m | \u001b[0m 0.2025  \u001b[0m | \u001b[0m 0.2346  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8991  \u001b[0m | \u001b[0m 0.6575  \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 0.08467 \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.6754  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9013  \u001b[0m | \u001b[0m 0.941   \u001b[0m | \u001b[0m 0.3379  \u001b[0m | \u001b[0m 0.242   \u001b[0m | \u001b[0m 0.9642  \u001b[0m | \u001b[0m 0.16    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 0.5158  \u001b[0m | \u001b[0m 0.7495  \u001b[0m | \u001b[0m 0.3231  \u001b[0m | \u001b[0m 0.5919  \u001b[0m | \u001b[0m 0.4294  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 0.8194  \u001b[0m | \u001b[0m 0.6292  \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 0.6659  \u001b[0m | \u001b[0m 0.4766  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.3349  \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.07368 \u001b[0m | \u001b[0m 0.5925  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9015  \u001b[0m | \u001b[0m 0.2636  \u001b[0m | \u001b[0m 0.3524  \u001b[0m | \u001b[0m 0.6016  \u001b[0m | \u001b[0m 0.9286  \u001b[0m | \u001b[0m 0.1539  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9029  \u001b[0m | \u001b[0m 0.5694  \u001b[0m | \u001b[0m 0.2934  \u001b[0m | \u001b[0m 0.4122  \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 0.2938  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.9025  \u001b[0m | \u001b[0m 0.8841  \u001b[0m | \u001b[0m 0.2516  \u001b[0m | \u001b[0m 0.8242  \u001b[0m | \u001b[0m 0.6556  \u001b[0m | \u001b[0m 0.4435  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 0.156   \u001b[0m | \u001b[0m 0.8776  \u001b[0m | \u001b[0m 0.6242  \u001b[0m | \u001b[0m 0.416   \u001b[0m | \u001b[0m 0.5603  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9024  \u001b[0m | \u001b[0m 0.03616 \u001b[0m | \u001b[0m 0.7901  \u001b[0m | \u001b[0m 0.4464  \u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 0.5655  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9017  \u001b[0m | \u001b[0m 0.8281  \u001b[0m | \u001b[0m 0.7476  \u001b[0m | \u001b[0m 0.2033  \u001b[0m | \u001b[0m 0.749   \u001b[0m | \u001b[0m 0.9796  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.9479  \u001b[0m | \u001b[0m 0.6289  \u001b[0m | \u001b[0m 0.1333  \u001b[0m | \u001b[0m 0.894   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.8639  \u001b[0m | \u001b[0m 0.1082  \u001b[0m | \u001b[0m 0.1054  \u001b[0m | \u001b[0m 0.03948 \u001b[0m | \u001b[0m 0.3263  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.7044  \u001b[0m | \u001b[0m 0.8442  \u001b[0m | \u001b[0m 0.1526  \u001b[0m | \u001b[0m 0.3559  \u001b[0m | \u001b[0m 0.1759  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.904   \u001b[0m | \u001b[0m 0.6471  \u001b[0m | \u001b[0m 0.6547  \u001b[0m | \u001b[0m 0.6415  \u001b[0m | \u001b[0m 0.2335  \u001b[0m | \u001b[0m 0.4514  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 0.8314  \u001b[0m | \u001b[0m 0.4104  \u001b[0m | \u001b[0m 0.6616  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9027  \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.1834  \u001b[0m | \u001b[0m 0.6488  \u001b[0m | \u001b[0m 0.3469  \u001b[0m | \u001b[0m 0.2752  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.9026  \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 0.7817  \u001b[0m | \u001b[0m 0.2249  \u001b[0m | \u001b[0m 0.6536  \u001b[0m | \u001b[0m 0.6721  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.8988  \u001b[0m | \u001b[0m 0.2956  \u001b[0m | \u001b[0m 0.06385 \u001b[0m | \u001b[0m 0.4466  \u001b[0m | \u001b[0m 0.9325  \u001b[0m | \u001b[0m 0.4478  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.482   \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 0.6791  \u001b[0m | \u001b[0m 0.7959  \u001b[0m | \u001b[0m 0.003275\u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.6642  \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.9882  \u001b[0m | \u001b[0m 0.2053  \u001b[0m | \u001b[0m 0.0205  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9028  \u001b[0m | \u001b[0m 0.7522  \u001b[0m | \u001b[0m 0.9687  \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.00227 \u001b[0m | \u001b[0m 0.07041 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.9279  \u001b[0m | \u001b[0m 0.9792  \u001b[0m | \u001b[0m 0.9476  \u001b[0m | \u001b[0m 0.09835 \u001b[0m | \u001b[0m 0.08791 \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.03812 \u001b[0m | \u001b[0m 0.9455  \u001b[0m | \u001b[0m 0.8773  \u001b[0m | \u001b[0m 0.009686\u001b[0m | \u001b[0m 0.08023 \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9038  \u001b[0m | \u001b[0m 0.9259  \u001b[0m | \u001b[0m 0.9943  \u001b[0m | \u001b[0m 0.9478  \u001b[0m | \u001b[0m 0.0656  \u001b[0m | \u001b[0m 0.2392  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 0.895   \u001b[0m | \u001b[0m 0.9577  \u001b[0m | \u001b[0m 0.9408  \u001b[0m | \u001b[0m 0.01119 \u001b[0m | \u001b[0m 0.19    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.8949  \u001b[0m | \u001b[0m 0.9353  \u001b[0m | \u001b[0m 0.9968  \u001b[0m | \u001b[0m 0.04286 \u001b[0m | \u001b[0m 0.9984  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9039  \u001b[0m | \u001b[0m 0.8877  \u001b[0m | \u001b[0m 0.9736  \u001b[0m | \u001b[0m 0.9709  \u001b[0m | \u001b[0m 0.2723  \u001b[0m | \u001b[0m 0.05571 \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9025  \u001b[0m | \u001b[0m 0.934   \u001b[0m | \u001b[0m 0.915   \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.01301 \u001b[0m | \u001b[0m 0.02596 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.9679  \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 0.9808  \u001b[0m | \u001b[0m 0.009671\u001b[0m | \u001b[0m 0.1559  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.902   \u001b[0m | \u001b[0m 0.9423  \u001b[0m | \u001b[0m 0.8637  \u001b[0m | \u001b[0m 0.9382  \u001b[0m | \u001b[0m 0.000409\u001b[0m | \u001b[0m 0.007799\u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.7951  \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9981  \u001b[0m | \u001b[0m 0.03778 \u001b[0m | \u001b[0m 0.957   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 0.7808  \u001b[0m | \u001b[0m 0.9282  \u001b[0m | \u001b[0m 0.9785  \u001b[0m | \u001b[0m 0.007657\u001b[0m | \u001b[0m 0.7965  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9015  \u001b[0m | \u001b[0m 0.0749  \u001b[0m | \u001b[0m 0.9736  \u001b[0m | \u001b[0m 0.9811  \u001b[0m | \u001b[0m 0.01983 \u001b[0m | \u001b[0m 0.1837  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9039  \u001b[0m | \u001b[0m 0.9093  \u001b[0m | \u001b[0m 0.9923  \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.2925  \u001b[0m | \u001b[0m 0.04068 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.9923  \u001b[0m | \u001b[0m 0.9772  \u001b[0m | \u001b[0m 0.6551  \u001b[0m | \u001b[0m 0.958   \u001b[0m | \u001b[0m 0.05493 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 0.9991  \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 0.9291  \u001b[0m | \u001b[0m 0.9342  \u001b[0m | \u001b[0m 0.722   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.904   \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.9362  \u001b[0m | \u001b[0m 0.9344  \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 0.4245  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 0.9863  \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 0.6795  \u001b[0m | \u001b[0m 0.5243  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.8341  \u001b[0m | \u001b[0m 0.9195  \u001b[0m | \u001b[0m 0.009254\u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.9851  \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.5066  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9037  \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 0.9187  \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 0.9626  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.9012  \u001b[0m | \u001b[0m 0.9881  \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.08309 \u001b[0m | \u001b[0m 0.1197  \u001b[0m | \u001b[0m 0.01532 \u001b[0m |\n",
      "| \u001b[95m 74      \u001b[0m | \u001b[95m 0.9042  \u001b[0m | \u001b[95m 0.8174  \u001b[0m | \u001b[95m 0.9973  \u001b[0m | \u001b[95m 0.8888  \u001b[0m | \u001b[95m 0.6162  \u001b[0m | \u001b[95m 0.4143  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.9803  \u001b[0m | \u001b[0m 0.9977  \u001b[0m | \u001b[0m 0.8763  \u001b[0m | \u001b[0m 0.6649  \u001b[0m | \u001b[0m 0.5038  \u001b[0m |\n",
      "| \u001b[95m 76      \u001b[0m | \u001b[95m 0.9042  \u001b[0m | \u001b[95m 0.9697  \u001b[0m | \u001b[95m 0.9808  \u001b[0m | \u001b[95m 0.8712  \u001b[0m | \u001b[95m 0.4912  \u001b[0m | \u001b[95m 0.506   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.9502  \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 0.9867  \u001b[0m | \u001b[0m 0.9907  \u001b[0m | \u001b[0m 0.7834  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9027  \u001b[0m | \u001b[0m 0.9875  \u001b[0m | \u001b[0m 0.8802  \u001b[0m | \u001b[0m 0.9589  \u001b[0m | \u001b[0m 0.03554 \u001b[0m | \u001b[0m 0.02113 \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.904   \u001b[0m | \u001b[0m 0.9741  \u001b[0m | \u001b[0m 0.9581  \u001b[0m | \u001b[0m 0.9741  \u001b[0m | \u001b[0m 0.5626  \u001b[0m | \u001b[0m 0.6556  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 0.947   \u001b[0m | \u001b[0m 0.9248  \u001b[0m | \u001b[0m 0.9746  \u001b[0m | \u001b[0m 0.9556  \u001b[0m | \u001b[0m 0.0638  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.9916  \u001b[0m | \u001b[0m 0.2962  \u001b[0m | \u001b[0m 0.9911  \u001b[0m |\n",
      "| \u001b[95m 82      \u001b[0m | \u001b[95m 0.9042  \u001b[0m | \u001b[95m 0.8293  \u001b[0m | \u001b[95m 0.9971  \u001b[0m | \u001b[95m 0.9489  \u001b[0m | \u001b[95m 0.5538  \u001b[0m | \u001b[95m 0.4572  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9042  \u001b[0m | \u001b[0m 0.8961  \u001b[0m | \u001b[0m 0.9932  \u001b[0m | \u001b[0m 0.7219  \u001b[0m | \u001b[0m 0.57    \u001b[0m | \u001b[0m 0.4498  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.9461  \u001b[0m | \u001b[0m 0.9856  \u001b[0m | \u001b[0m 0.9867  \u001b[0m | \u001b[0m 0.7488  \u001b[0m | \u001b[0m 0.4417  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9032  \u001b[0m | \u001b[0m 0.964   \u001b[0m | \u001b[0m 0.9912  \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.01141 \u001b[0m | \u001b[0m 0.9926  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9042  \u001b[0m | \u001b[0m 0.6723  \u001b[0m | \u001b[0m 0.9855  \u001b[0m | \u001b[0m 0.9837  \u001b[0m | \u001b[0m 0.5589  \u001b[0m | \u001b[0m 0.3265  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9035  \u001b[0m | \u001b[0m 0.9746  \u001b[0m | \u001b[0m 0.9726  \u001b[0m | \u001b[0m 0.9822  \u001b[0m | \u001b[0m 0.1194  \u001b[0m | \u001b[0m 0.9253  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9042  \u001b[0m | \u001b[0m 0.9782  \u001b[0m | \u001b[0m 0.9843  \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 0.5453  \u001b[0m | \u001b[0m 0.43    \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.9626  \u001b[0m | \u001b[0m 0.942   \u001b[0m | \u001b[0m 0.9943  \u001b[0m | \u001b[0m 0.5172  \u001b[0m | \u001b[0m 0.5371  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 0.9607  \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 0.9938  \u001b[0m | \u001b[0m 0.06977 \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "=====================================================================================\n",
      "init_points = 50, n_iter = 40, CV:0.9042\n"
     ]
    }
   ],
   "source": [
    "prediction_test = fitBayesian(MVTable, TestTable, init_points=50, n_iter=40)\n",
    "\n",
    "csv_file_path = Output + 'submit/sub_stacking.csv'\n",
    "sub = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "sub.target = prediction_test\n",
    "sub.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375k/375k [00:04<00:00, 84.0kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "message = \"blending BayesianOptimization \"\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, \n",
    "                               plot_feature_importance=False, model=None, verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of classification models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    :params: verbose - parameters for gradient boosting models\n",
    "    :params: early_stopping_rounds - parameters for gradient boosting models\n",
    "    :params: n_estimators - parameters for gradient boosting models\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns == None else columns\n",
    "    X_test = X_test[columns]\n",
    "    #X_metaval = X_metaval[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': 'auc',\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros((len(X), len(set(y.values))))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros((len(X_test), oof.shape[1]))\n",
    "    #prediction_MV = np.zeros((len(X_metaval), oof.shape[1]))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid, num_iteration=model.best_iteration_)\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
    "            #y_pred_MV = model.predict_proba(X_metaval, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, \n",
    "                              early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict_proba(xgb.DMatrix(X_valid, feature_names=X.columns), \n",
    "                                         ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            #y_pred_MV = model.predict(xgb.DMatrix(X_metaval, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)#.reshape(-1,)\n",
    "            #print(len(y_pred_valid))\n",
    "            #print(len(y_valid))\n",
    "            #print(y_pred_valid)\n",
    "            #print(y_valid)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1])\n",
    "            print(f'Fold {fold_n + 1}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "            #y_pred_MV = model.predict_proba(X_metaval)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "            #y_pred_MV = model.predict(X_metaval)\n",
    "        \n",
    "        #print(oof.shape)\n",
    "        #print(oof[valid_index])\n",
    "        oof[valid_index] = y_pred_valid\n",
    "        scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1]))#0 or 1の問題にしか対応してない\n",
    "\n",
    "        prediction += y_pred    \n",
    "        #prediction_MV += y_pred_MV    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    #prediction_MV /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    #result_dict['prediction_MV'] = prediction_MV\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__run__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sun Jul 19 16:44:41 2020\n",
      "Fold 1. auc: 0.8720.\n",
      "\n",
      "Fold 2 started at Sun Jul 19 16:44:41 2020\n",
      "Fold 2. auc: 0.7798.\n",
      "\n",
      "Fold 3 started at Sun Jul 19 16:44:41 2020\n",
      "Fold 3. auc: 0.8699.\n",
      "\n",
      "Fold 4 started at Sun Jul 19 16:44:42 2020\n",
      "Fold 4. auc: 0.7029.\n",
      "\n",
      "Fold 5 started at Sun Jul 19 16:44:42 2020\n",
      "Fold 5. auc: 0.8268.\n",
      "\n",
      "CV mean score: 0.8103, std: 0.0634.\n",
      "CPU times: user 1.3 s, sys: 5.76 ms, total: 1.31 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SVM\n",
    "#交差検証\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "m_type = \"sklearn\"\n",
    "\n",
    "params = None\n",
    "C = 0.09\n",
    "gamma = 'auto'\n",
    "\n",
    "#data\n",
    "y = MVTable[\"target\"]\n",
    "X = MVTable.drop(['target','image_name'], axis=1)\n",
    "X_test = TestTable.drop(['image_name'], axis=1)\n",
    "\n",
    "#support vector machine\n",
    "model = SVC(C=C, gamma=gamma, probability=True)\n",
    "result_dict = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type=m_type, eval_metric='auc',\n",
    "                                         plot_feature_importance=True, verbose=1000, early_stopping_rounds=200, n_estimators=10000, model = model)\n",
    "\n",
    "csv_file_path = Output + 'submit/sub_blending.csv'\n",
    "sub = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "sub.target = result_dict[\"prediction\"][:,1]\n",
    "sub.to_csv(csv_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sun Jul 19 16:00:36 2020\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-c4976f46786d>\u001b[0m in \u001b[0;36mtrain_model_classification\u001b[0;34m(X, X_test, y, params, folds, model_type, eval_metric, columns, plot_feature_importance, model, verbose, early_stopping_rounds, n_estimators)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0my_pred_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.reshape(-1,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;31m#print(len(y_pred_valid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m#print(len(y_valid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Linear\n",
    "#交差検証\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "m_type = \"sklearn\"\n",
    "\n",
    "params = None\n",
    "\n",
    "#data\n",
    "y = MVTable[\"target\"]\n",
    "X = MVTable.drop(['target','image_name'], axis=1)\n",
    "X_test = TestTable.drop(['image_name'], axis=1)\n",
    "\n",
    "#support vector machine\n",
    "model = LinearRegression()\n",
    "result_dict = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type=m_type, eval_metric='auc',\n",
    "                                         plot_feature_importance=True, verbose=1000, early_stopping_rounds=200, n_estimators=10000, model = model)\n",
    "\n",
    "csv_file_path = Output + 'submit/sub_blending.csv'\n",
    "sub = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "sub.target = result_dict[\"prediction\"][:,1]\n",
    "sub.to_csv(csv_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sun Jul 19 15:42:02 2020\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.0795649\ttraining's auc: 0.964909\tvalid_1's binary_logloss: 0.0800094\tvalid_1's auc: 0.885671\n",
      "Fold 2 started at Sun Jul 19 15:42:02 2020\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.0629722\ttraining's auc: 0.978919\tvalid_1's binary_logloss: 0.0756656\tvalid_1's auc: 0.856793\n",
      "Fold 3 started at Sun Jul 19 15:42:03 2020\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.0393994\ttraining's auc: 0.995215\tvalid_1's binary_logloss: 0.0840326\tvalid_1's auc: 0.884971\n",
      "Fold 4 started at Sun Jul 19 15:42:03 2020\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.0771374\ttraining's auc: 0.962198\tvalid_1's binary_logloss: 0.0789313\tvalid_1's auc: 0.910922\n",
      "Fold 5 started at Sun Jul 19 15:42:03 2020\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.0765215\ttraining's auc: 0.964099\tvalid_1's binary_logloss: 0.0768518\tvalid_1's auc: 0.880558\n",
      "CV mean score: 0.8838, std: 0.0172.\n",
      "CPU times: user 20.3 s, sys: 6.48 ms, total: 20.3 s\n",
      "Wall time: 1.48 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAALJCAYAAADWL1JOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdfbhtZVkv/u8NW0ABQQHdKiKYRb4hlkoKSWpR2jHfskR0U5GkgtqpzDyZx2N1/ZLS0hSKY2RomvlWJob5I19y+wrKO4gpGqJpmIhuBRXu88ccW6bLtfdaG/faD3uvz+e65rXGHM8Yz3OPCXL5nc8Yz6zuDgAAADDOTqMLAAAAgNVOOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwBgm6mqXavq4qpaO7qWbaWqDq6qj1XVV6vqmUsc+0tV9b7NtL+7qn51iT52rapLq+p2N7VmALY94RwANqGqPl1VP7mJtj2r6iXTMRuq6j+q6o1V9YC5Y3pq+1pVXVVVr6uqvZcY7xvT8Rtfd/w+r+Enquqz308fW9nxSd7b3f85upBt6LeTvLu79+zul630YN19XZLTkjxnpccCYOsRzgFgC1XVrkn+Ncm9k/yPJLdOcvckf5fkEQsOv09375Hkrkluk+QFS3T/yO7eY+71ua1a/BaqqjVbuctfS/LqrdznzULNLPb/re6S5KJtXM5rkxw7/bsKwHZAOAeALffkJPsneXR3X9jd13f3hu5+Y3e/YLETuvuaJG9Nco+bMmBV/VhVvb+qrq6q86rqJ+bafrmqLplum/5UVf3atH/3JP+c5I7zM/FV9aqq+oO5879rdn2awX9OVZ2fZENVrZnOe1NV/VdVXT5/e3ZVPaCqzq6qa6rqC1X1kk1cwwFJfiDJh+b2/ex0y/c1VXVFVb1gru3MqjpxQR/nVdVjp+2jqurjVfWVqjq5qt6zqVu+p1u9/6yqPje9/mxjcJ0+u/8xd+ya6U6HH1nGZ//uqvrDqlqf5OuZfQkzP+6/JnlIkpdPn/8PVdVeVXX69Fl+pqqet4lQn6r6qekW9a9U1cuT1Fzb3aZr/spU7+s3tnX3Z5N8OcmPLdYvADc/wjkAbLmfTPKO7t6w3BOq6jZJHp3kg1s6WFXdKckZSf4gyW2T/FaSN1XVftMhX8yNM/i/nORPq+pHpvoenuRzN2Em/ugkP5tk7yQ3JPmnJOcluVOShyX59ar66enYlyZ5aXffOrPw/feb6PPeST7V3d+e27chybppnJ9N8rSqevTU9tqpjo2fwz0ym4U+o6r2TfLGJM9Nsk+Sjyd50Gau53czC6qHJrlPkgcked7U9rr5cZL8dJKruvujy/jsk9mXNccn2TPJZ+YH7e6HJvm3JCdOn/9lSf48yV6ZBfkjp+v/5YUFT9f4pqnOfZN8Msnhc4f8fpJ/yeyOjP2nfuddMl0rANsB4RwAtty+Sb7zzHRVHTrNql5TVR9fcOxHq+rqJFclOSDJXy7R9z9MfV1dVf8w7XtSkrd399u7+4bufmeSszPdQt/dZ3T3J3vmPZkFth//Pq/xZd19RXd/I8n9k+zX3S/s7m9296eS/N8kT5iO/VaSu1XVvt39te7e1BcQeyf56vyO7n53d18wXdf5mQXlI6fmtyQ5tKruMr0/Jsmbp2eqH5Hkou5+8xT2X5a5fyaLOCbJC7v7i939X0n+T2ahOpl9CfBzVXWr6f0Tp33JEp/95FXdfVF3f7u7v7WZGlJVOyf5xSTP7e6vdvenk7x4rpZ5j0hy8XRHxreS/NmCa/xWZl9W3LG7r+3uhQvJfTWzzxyA7YBwDgBb7ktJ7rDxTXef2917J3lskoXP+P7I1LZbklOS/FtV7baZvh/d3XtPr40zyHdJ8vi50H51kiM21lBVD6+qD1bVf09tj8jsC4TvxxVz23fJ7Nb4+fH/V5LbT+3HJfmhJJdW1UfmbxFf4MuZzS5/R1UdVlXvmm7x/kqSp26svbu/mtms9cYvAZ6Q5G+n7TvO19jdnWRzC9/dMd89q/2ZaV+6+98zm2V+5BTQfy43hvPNfvaT+c9qKfsm2WWRWu60iZoXXuP8WL+d2W3uH66qi6rqVxacv2eSq7egNgAGEs4BYMudleSo6ZnuZZlmPl+Z5KAk99rC8a5I8uq50L53d+/e3X80PTf9piR/kuT20xcBb8+Nzyb3Iv1tSHKrufeL/azZ/HlXJLl8wfh7dvfGmftPdPfRSW6X5EVJ3riJz+b8JHet715k7rWZPYt/5+7eK8lfzNWeTLecV9UDk9wyybum/Z/P7FbuJLPF2ObfL+JzmQXtjQ6Y9n3XOEkeldls9b/PXfuin/3cuYt9xptyVW6c8Z6v5cpFjv18kjtvfDNd43fed/d/dvdTuvuOmS20d3JV3W3u/Ltn9igCANsB4RwANu8WVbXb3GtNktMzC05vqap7VdXO02z4/TbVyXQ78y8n+UaST21hDa/JbFb3pzeOVbNF3PbPbBZ21yT/leTbVfXwJEfNnfuFJPtU1V5z+85N8oiqum3Nfm/815cY/8NJrqnZInG3nGq4V1Xdf7q2J1XVft19Q26cqb1+YSfTImWfyOx57432TPLf3X1tzX6G7okLTnt7ZkH2hUleP42RzGbU711Vj57+mZyQxb9k2Oh1SZ5XVftNz3I/P7PPdaO/y+xze1punDVPNv/Zb7Huvj6zZ/L/sGY/x3eXJL+xoJaNzkhyz6p67HSNz5y/xqp6/FwdX87sS4Lrp7Y7ZfaM/BavcQDAGMI5AGze2zML1BtfL+juazNbgfvizALUNZktSHb/JL+w4PzzquprmYWnY5M8prv/e0sK6O4rMpvR/V+ZhfArkjw7yU7Trd/PzCzwfTmzcPvWuXMvzSyYfmq6LfuOmf2U2XlJPp3Z8+nfWeV7E+Nfn+SRmS2mdnlms7+vzGxRsyT5mSQXTdf50iRPmD6jxfxlvvv56qcneWFVfTWzwPxdi8lNz5e/ObNF+F47t/+qJI9PclJmjxncI7Nnwa/bxLh/MLWfn+SCJB+d9m3s7/NJPpDZonLzq55v8rPfxDjL8YzM7l74VJL3Tdd12sKD5q7xjzK7xh9Msn7ukPsn+dD0ub81ybO6+/Kp7YlJ/mb6/ADYDtTs8SUAgJU33Yb/sSQPmwLx1up3p8yeOT+mu9+11PE7sukzPi/Jg7v7i6PrAWB5hHMAYLs0/ZTbhzK7o+HZmd3aftdphXkA2K64rR0A2F49MLPf/r4qs9vuHy2YA7C9MnMOAAAAg5k5BwAAgMHWLH0I28q+++7bBx544OgyAAAAWAHnnHPOVd2932JtwvnNyIEHHpizzz57dBkAAACsgKr6zKba3NYOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMNia0QVwo0s++6X86LNPH10GADuAc/543egSAIAtYOYcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4XwTquprm2k7sKou/H76AAAAgI3WjC5gW6qqnbv7+tF1sLrs/ol/yU7f3DC6DGCVWbfu/x9dAgBsU2vXrs1JJ500uoybbIcJ51V1YJIzk3woyX2TXJZkXZKLk5yW5KgkL6+qjyR5RZL9knw9yVO6+9KqOijJazP7TM7cgnFvleRVSX44ySVJDkxyQnefPbW/OMlDknw5yRO6+78WnH98kuOTZJc999ni6+bmb6dvbsjO110zugxglbnySv/dAYDtyQ4TzicHJzmuu9dX1WlJnj7tv7a7j0iSqjoryVO7+xNVdViSk5M8NMlLk5zS3adX1QlbMObTk3y5uw+pqnslOXeubfckH+3u36yq5yf530lOnD+5u09NcmqS7L72oN7SC+bm74Zddh9dArAKHbDvnqNLAIBtau3ataNL+L7saOH8iu5eP22/Jskzp+3XJ0lV7ZHkQUneUFUbz9l1+nt4ksdN269O8qJljnlEZsE+3X1hVZ0/13bDxrGnet687Cthh7HhB48aXQKwCp3+x+tGlwAAbIEdLZwvnHne+H7jA787Jbm6uw9d5vnLUUsf8n31DwAAwA5uR1ut/YCqeuC0fXSS9803dvc1SS6vqscnSc3cZ2pen+QJ0/YxWzDm+5L8wtTfPZLce65tpyQ/P20/cWE9AAAAkOx44fySJMdOt5bfNskpixxzTJLjquq8JBcledS0/1lJTpgWjNtrC8Y8Ocl+05jPSXJ+kq9MbRuS3LOqzsnsufYXbuH1AAAAsArsaLe139DdT12w78D5N919eZKfWXjitP+Bc7v+aFODdPenk9xrenttkid197VV9QNJzkrymem4PaZjfm/5lwAAAMBqs6OF8xFuleRdVXWLzJ4/f1p3f3NwTQAAAGxHdphwvmA2e6uoqntntnL7vOu6+7C5cb+a5H5bc1wAAABWlx0mnK+E7r4gyaZWdgcAAICtYkdbEA4AAAC2O8I5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGBrRhfAje6+/z45+4/XjS4DAACAbczMOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGBrRhfAjb75+YvyHy+89+gyAFaFA55/wegSAAC+w8w5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBg2004r6qvbabt0Kr6QFVdVFXnV9UvzrX9bVV9vKourKrTquoWC869f1VdX1U/P6p/AAAAVrc1Iwevqp27+/qt0NXXk6zr7k9U1R2TnFNV7+juq5P8bZInTce9NsmvJjll4/hJXpTkHYP7ZzvwJ+fvnauu3W6+zwKWsGbdutElALAdWLt2bU466aTRZbAKrFg4r6oDk5yZ5ENJ7pvksiTrklyc5LQkRyV5eVV9JMkrkuyXWQh+SndfWlUHZRZ210z9bFJ3Xza3/bmq+uLU39Xd/fa5mj6cZP+5U5+R5E1J7j+q/6o6PsnxSXKnvW6xqcO4Gbjq2p3yhW8M/T4L2JquvHJ0BQAA37HSSePgJMd19/qqOi3J06f913b3EUlSVWcleeo0K31YkpOTPDTJS5Oc0t2nV9UJyx2wqh6QZJckn1yw/xZJnpzkWdP7OyV5zDTWZsP5Svbf3acmOTVJDrnTLXu5dbDt7bvbDUm+PboMYCtZc9u7jC4BgO3A2rVrR5fAKrHS4fyK7l4/bb8myTOn7dcnSVXtkeRBSd5QVRvP2XX6e3iSx03br87s9vDNqqo7TMce2903LGg+Ocl7u/vfpvd/luQ53X393NhD++fm7bcOuXp0CcBWdMDz3zO6BACA71jpcL5wJnjj+w3T350yuzX80GWev0lVdeskZyR5Xnd/cEHb/87sNvRfm9t9vyR/NwXnfZM8oqq+3d3/MKJ/AAAAVq+VXt3qgKp64LR9dJL3zTd29zVJLq+qxydJzdxnal6f5AnT9jGbG6SqdknyliSnd/cbFrT9apKfTnL0/Gx3dx/U3Qd294FJ3pjk6ZsJ5ivaPwAAAKvbSofzS5IcW1XnJ7ltplXMFzgmyXFVdV6Si5I8atr/rCQnTAvG7bXEOL+Q5MFJfqmqzp1eG2fj/yLJ7ZN8YNr//JtwHSvdPwAAAKtYda/MGmTTau1v6+57rcgAO6BD7nTLftuv3W10GQCrwgHPv2B0CQDAKlNV53T3/RZr86PNAAAAMNiKLQjX3Z9OslVnzavq3pmtlj7vuu4+bHvoHwAAABaz0qu1b1XdfUGSTa3sfrPvHwAAABbjtnYAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMHWjC6AG+1yh3vmgOefPboMAAAAtjEz5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMNia0QVwo0u/eGkO//PDR5cBcLO0/hnrR5cAALBizJwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAy23YTzqvraEu3XV9W50+utc/tPrKp/r6quqn3n9h9TVedPr/dX1X2W6P/TVXXB1P/Zc/sfX1UXVdUNVXW/uf0/VVXnTOecU1UPvWlXDgAAwI5uzcjBq2rn7r5+K3X3je4+dJH965O8Lcm7F+y/PMmR3f3lqnp4klOTHLbEGA/p7qsW7LswyWOT/OWC/VcleWR3f66q7pXkHUnutPRlsCm3WH+L1NdrdBnAIOs+sm50CQDs4NauXZuTTjppdBmsUisWzqvqwCRnJvlQkvsmuSzJuiQXJzktyVFJXl5VH0nyiiT7Jfl6kqd096VVdVCS1041nnlT6+juj031LNz//rm3H0yy/03s/5JN9P+xubcXJdmtqnbt7uvmj6uq45McnyS73GaXm1LCqlFfr+y0Ybu52QPYyq7ccOXoEgAAVsxKz5wfnOS47l5fVaclefq0/9ruPiJJquqsJE/t7k9U1WFJTk7y0CQvTXJKd59eVScsY6zdptvNv53kj7r7H7agzuOS/PMSx3SSf6mqTvKX3X3qFvT/uCQfWxjMk2Tq59Qk2eOAPXoL+lx1+ladG3LD6DKAQe68951HlwDADm7t2rWjS2AVW+lwfkV3r5+2X5PkmdP265OkqvZI8qAkb5ibed51+nt4ZqE2SV6d5EVLjHXAdAv5XZP8a1Vd0N2fXKrAqnpIZuH8iCUOPXzq/3ZJ3llVl3b3e5fR/z2n2o9a6lg271uHf2t0CcBApz/j9NElAACsmJUO5wtngje+3zD93SnJ1Zt4Vnyx8zc9UPfnpr+fqqp3Z3Yr/WbDeVUdkuSVSR7e3V9aZv9frKq3JHlAks2G86raP8lbkqxbzhcFAAAArE4r/QDvAVX1wGn76CTvm2/s7muSXF5Vj0+Smtm4avr6JE+Yto/Z3CBVdZuq2nXa3jezWfeLlzjngCRvTvLk7r5siWN3r6o9N25nNgt+4RLn7J3kjCTPnbt7AAAAAL7HSofzS5IcW1XnJ7ltklMWOeaYJMdV1XmZLZz2qGn/s5KcMC0Yt9cS49w9ydlTH+/K7Jnzi5Okqp5ZVZ/NbMG386vqldM5z0+yT5KTF/482iJun+R9U/8fTnJGd5859f+Yqf8HJjmjqt4xnXNikrsl+b25n3i73RLXAQAAwCpU3SuzBtm0WvvbuvteKzLADmiPA/bo+zx7sz+3DrBqrX+Gm5AAgO1bVZ3T3fdbrM3vUgEAAMBgK7YgXHd/OslWnTWvqntntnL7vOu6+7Ct1P8+Sc5apOlhSy0YBwAAADfVSq/WvlV19wVJNrWy+9bo/0sr2T8AAAAsxm3tAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDrRldADf64dv9cNY/Y/3oMgAAANjGzJwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBga0YXwI2++vGP5z0PPnJ0GQDDHPne94wuAQBgCDPnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDLRnOq+r2VfVXVfXP0/t7VNVxK18aAAAArA7LmTl/VZJ3JLnj9P6yJL++UgUBAADAarOccL5vd/99khuSpLu/neT6Fa0KAAAAVpHlhPMNVbVPkk6SqvqxJF9Z0aoAAABgFVmzjGN+I8lbk/xAVa1Psl+Sn1/RqgAAAGAV2Ww4r6qdkuyW5MgkByepJB/v7m9tg9oAAABgVdhsOO/uG6rqxd39wCQXbaOaAAAAYFVZzjPn/1JVj6uqWvFqAAAAYBVa7jPnuyf5dlVdm9mt7d3dt17RygAAAGCVWDKcd/ee26IQAAAAWK2WDOdV9eDF9nf3e7d+OQAAALD6LOe29mfPbe+W5AFJzkny0BWpCAAAAFaZJReE6+5Hzr1+Ksm9knxh5Uv7blX1tSXaz6yqq6vqbQv2P7SqPlpVF1bV31TVmmn/MVV1/vR6f1XdZ4n+T6uqL1bVhQv236eqPlBVF1TVP1XVraf9P1VV50z7z6kqX2YAAACwqOWs1r7QZzML6N+3qtp5a/Qz+eMkT17Q/05J/ibJE7r7Xkk+k+TYqfnyJEd29yFJfj/JqUv0/6okP7PI/lcm+Z3uvneSt+TGOw2uSvLIaf+xSV69pRcEAADA6rCcZ87/PElPb3dKcmiS85Zx3oFJzkzyoST3TXJZknVJLk5yWpKjkry8qj6S5BVJ9kvy9SRP6e5Lq+qgJK+dajxzqfG6+6yq+okFu/dJcl13Xza9f2eS5yb5q+5+/9xxH0yy/xL9v3e6poUOTrLx+ft3JnlHkt/r7o/NHXNRkt2qatfuvm6pa+F7vWbnnXK1X/ODHd5frVs3ugQAbsbWrl2bk046aXQZsCKW88z52XPb307yuu5ev8z+D05yXHevr6rTkjx92n9tdx+RJFV1VpKndvcnquqwJCdn9jz7S5Oc0t2nV9UJyxxvoauS3KKq7tfdZyf5+SR3XuS445L8800c48IkP5fkH5M8fhP9Py7JxxYL5lV1fJLjk+T2u+56E0vY8V1dlf8WzmHHd+WVoysAABhiOeF87+5+6fyOqnrWwn2bcMVckH9NkmdO26+f+tkjyYOSvKFuDF4bE+rhmYXaZHZL+IuWMd536e6uqick+dOq2jXJv2T2BcP8tTwks3B+xJb2P/mVJC+rqucneWuSby7o/55T7UdtosZTM91Sf/Cee/Zix5Ds3T4aWA1uuf9mb2ICYJVbu3bt6BJgxSwnnB+b2Sz2vF9aZN9iFiaqje83TH93SnJ1dx+6zPO3WHd/IMmPJ0lVHZXkhza2VdUhmT0z/vDu/tJN7P/STMG7qn4oyc/O9b9/Zs+hr+vuT97UayB50vU3jC4B2AaOPP300SUAAAyxyQXhquroqvqnJAdV1VvnXu9Kstwge0BVPXDaPjrJ++Ybu/uaJJdX1eOnMWtu1fT1SZ4wbR+zzPEWu47bTX93TfKcJH8xvT8gyZuTPHnumfTvp/+dkjxvrv+9k5yR5Llb8BgAAAAAq9DmVmt/f5IXJ7l0+rvx9ZtZfNXyxVyS5NiqOj/JbZOcssgxxyQ5rqrOy2zhtEdN+5+V5IRpwbi9lhqoqv4tyRuSPKyqPltVPz01PbuqLklyfpJ/6u5/nfY/P7MF406uqnOr6uzv7fW7+n9dkg8kOXjq/7ip6eiquiyzz+lzSf562n9ikrsl+b2p/3M3BnkAAACYV71Cz/JOK5u/bfoJM5bh4D337FPv+yOjywAY5sj3vmd0CQAAK6aqzunu+y3WtuTvnFfVj1XVR6rqa1X1zaq6vqqu2fplAgAAwOq0nAXhXp7Zs99vSHK/zH6r/G5LndTdn06yVWfNq+xtCXYAAB1gSURBVOrema3cPu+67j5sK/W/T5KzFml62E1dMA4AAACWspxwnu7+96raubuvT/LXVfX+Fa5rU3VckGRTK7tvjf6/tJL9AwAAwGKWE86/XlW7JDm3qk5K8vkku69sWQAAALB6LPnMeZInT8edmNnvk985yeNWsigAAABYTZacOe/uz1TVLZPcobv/zzaoCQAAAFaV5azW/sgk5yY5c3p/aFW9daULAwAAgNViObe1vyDJA5JcnSTdfW6SA1euJAAAAFhdlhPOv93dX1nxSgAAAGCVWs5q7RdW1ROT7FxVP5jkmUmG/JQaAAAA7Ig2OXNeVa+eNj+Z5J5JrkvyuiTXJPn1lS8NAAAAVofNzZz/aFXdJckvJnlIkhfPtd0qybUrWRgAAACsFpsL53+R2Qrtd01y9tz+StLTfgAAAOD7tMnb2rv7Zd199ySndfdd514HdbdgDgAAAFvJkqu1d/fTtkUhAAAAsFot56fUAAAAgBUknAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYGtGF8CN9jz44Bz53veMLgMAAIBtzMw5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYGtGF8CNvvjZr+Tlv/lPo8sA2GZOfPEjR5cAAHCzYOYcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAbbbsJ5VX1tM22HVtUHquqiqjq/qn5xru1VVXV5VZ07vQ6da/uJad9FVfWezfR/56p6V1VdMh37rLm2F1TVlXP9P2Ku7ZC5ui6oqt2+v08BAACAHdGakYNX1c7dff1W6OrrSdZ19yeq6o5Jzqmqd3T31VP7s7v7jQvG3jvJyUl+prv/o6put5n+v53kN7v7o1W159T/O7v74qn9T7v7Txb0vybJa5I8ubvPq6p9knzr+79UAAAAdjQrFs6r6sAkZyb5UJL7JrksybokFyc5LclRSV5eVR9J8ook+2UWsp/S3ZdW1UFJXjvVeObmxuruy+a2P1dVX5z6u3rTZ+WJSd7c3f8xnffFzfT/+SSfn7a/WlWXJLnTdC2bclSS87v7vOm8L23uGlgZ6z/55mz45jWjywA24cPr3jC6BABuorVr1+akk04aXQbsMFZ65vzgJMd19/qqOi3J06f913b3EUlSVWcleeo0631YZrPZD03y0iSndPfpVXXCcgesqgck2SXJJ+d2/2FVPT/JWUl+p7uvS/JDSW5RVe9OsmeSl3b36cvo/8DMvmz40NzuE6tqXZKzM5th//LUf1fVOzL7ouDvuvt7/utVVccnOT5JbrPnfsu9TJZpwzevyYbrNvcdDTDShiv97xMAIFn5cH5Fd6+ftl+T5JnT9uuTpKr2SPKgJG+oqo3n7Dr9PTzJ46btVyd50VKDVdUdpmOP7e4bpt3PTfKfmQX2U5M8J8kLM7v2H03ysCS3TPKBqvrg/Cz8Iv3vkeRNSX69uzdOx56S5PeT9PT3xUl+Zer/iCT3z+yOgLOq6pzuPmu+z+4+daorB6z9wV7qGtkyu+9y69ElAJux9767jy4BgJto7dq1o0uAHcpKh/OFYXPj+w3T352SXN3dh2Zxyw6rVXXrJGckeV53f/A7HcxuSU+S66rqr5P81vT+s0mu6u4NSTZU1XuT3Cez2+8X6/8WmQXzv+3uN8/1/4W5Y/5vkrfN9f+e7r5qant7kh/JbPaebeTwH3js6BKAzTjxxY8cXQIAwM3CSq/WfkBVPXDaPjrJ++Ybp9nny6vq8UlSM/eZmtcnecK0fczmBqmqXZK8Jcnp3f2GBW132Nh3kkcnuXBq+sckP15Va6rqVkkOS3LJJvqvJH+V5JLufsli/U8eM9f/O5IcUlW3mhaHOzKbf0YdAACAVWqlw/klSY6tqvOT3DazW8AXOibJcVV1XpKLkjxq2v+sJCdMC8bttcQ4v5DkwUl+aZGfTPvbqrogyQVJ9k3yB0nS3ZdkttDc+Uk+nOSV3X3h93adZHaL/ZOTPHSRn0w7afqZtPOTPCTJ/5z6/3KSlyT5SJJzk3y0u89Y4joAAABYhap7ZR5znhZOe1t332tFBtgBHbD2B/u3j3nJ0gcC7CDc1g4ArCbTOmT3W6xtpWfOAQAAgCWs2IJw3f3pJFt11ryq7p3Zauzzruvuw7ZS//tk8QXbHuZ3ygEAAFgpK71a+1bV3Rck2dTK7luj/y+tZP8AAACwGLe1AwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMtmZ0AdzodvvvlRNf/MjRZQAAALCNmTkHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYbM3oArjR5y//ZP7wST8/ugxgmX73NW8cXQIAADsIM+cAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wAAADCYcA4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAINtV+G8qr62mba7VNU5VXVuVV1UVU+dazu6qi6oqvOr6syq2nfBub9VVb1w/4JjHjWdf25VnV1VR8y1nTSNeUlVvayqasG5b62qC2/aVQMAALCjWzO6gKraubuv3wpdfT7Jg7r7uqraI8mFVfXWJF9M8tIk9+juq6rqpCQnJnnBNP6dk/xUkv9Yov+zkry1u7uqDkny90l+uKoelOTwJIdMx70vyZFJ3j31/9gkm/xSgZmPfemrufb6G0aXAVtk3bp1o0sAdgBr167NSSedNLoMAAZb0XBeVQcmOTPJh5LcN8llSdYluTjJaUmOSvLyqvpIklck2S/J15M8pbsvraqDkrx2qvPMzY3V3d+ce7trbrwroKbX7lX1pSS3TvLvc8f+aZLfTvKPS/Q/H7B3T9Ibm5LslmSXaZxbJPnCdP17JPmNJMdnFua/R1UdP7Vnr1vdcnMl7NCuvf6GfEM4Zztz5ZVXji4BAIAdxLaYOT84yXHdvb6qTkvy9Gn/td19RJJU1VlJntrdn6iqw5KcnOShmc14n9Ldp1fVCUsNNM2Cn5Hkbkme3d2fm/Y/LckFSTYk+USSE6b9P5fkyu4+b8Gd6Jvq/zFJ/r8kt0vys0nS3R+oqndlNnNfSV7e3ZdMp/x+khdn9oXDorr71CSnJsmd9rlNb+q4Hd1uO29XT1hAkuS2a+8wugRgB7B27drRJQBwM7AtwvkV3b1+2n5NkmdO269PvjO7/KAkb5gLyLtOfw9P8rhp+9VJXrS5gbr7iiSHVNUdk/xDVb0xyX8neVpmM/efSvLnSZ5bVS9J8ruZzd4vS3e/JclbqurBmQXvn6yquyW5e5L9p8PeObVfk+Ru3f0/pzsI2Iz77rPn6BJgi/3u6aePLgEAgB3EtgjnC2eDN77fMP3dKcnV3X3oMs9fesDuz1XVRUl+PMlnpn2fTJKq+vskv5PZbewHJdk4a75/ko9W1QO6+z+X6P+9VfUD0wJyj0nywY23vVfVPyf5sSRfTfKjVfXpzD7n21XVu7v7J7b0egAAANixbYt7iQ+oqgdO20dntmDad3T3NUkur6r/1969x1pWlncA/r0yKBcVb2hAtINoBYuAOF4hiqJGqxWaSsFio4bGtlKLtqbRmrTVxqZN7IV6oRq8EG1RxEuVeMFa6gUbBBQYLFBFUBEErCKoBYu8/WMt5DjODCPOzLc3PE9yctZtr/Xt82avvX/nW+vbhyVJTfadV5+e5Ih5+siNHaSqdquq7efpe2bqdb8oyTeTPKyqdp43fWqSC7p7bXfft7tXd/fqJJcl2X9DwbyqHnzzKOxVtX+me8z/J9NAck+sqlVVtW2mweAu6O7junvXed8HJvlvwRwAAID12Rrh/IIkz6+q85LcK8lx69nmyCRHVdW5Sb6U5JB5+TFJjp4HjNvpVo6zV5Iz5n18Ksnr5gB+eZJXJ/n03Ib9kvzVbXgev5FpBPhzMg1ed3h3d5KTk1yc6Z72c5Oc290fvg37BwAA4A6qpny5hXY+3Wt9SnfvvcUOcjty/3vfs1/8jINHNwPYRK9618mjmwAAwBKpqrO7e8361hkiGwAAAAbbogPCdfelSTZrr3lVPTzTyO0r3dDdj9lM+39hpsvpVzq9u2/1q9wAAADgttgao7VvVt29NtN941tq/29P8vYttX8AAABYl8vaAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGAw4RwAAAAGE84BAABgMOEcAAAABhPOAQAAYDDhHAAAAAYTzgEAAGCwVaMbwC122X2PvOpdJ49uBgAAAFuZnnMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABhMOAcAAIDBhHMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABjsDh/Oq+r7G1l3p6r6x6o6v6rWVtWZVbV7Vb2jqn53nW0PraqPzNNdVe9csW5VVV1dVadsuWcCAADAsrpdhvOq2mYz7erwJLsm2ae7H57k15Nck+TEJEess+0R8/Ik+UGSvatq+3n+qUm+uZnaBAAAwO3M0oXzqlpdVRdW1QlVdV5VnVxVO1TVpVX1Z1X12SSHVdUeVfWxqjq7qj5TVXvOj9+9qv5z7gX/y1s53C5Jrujum5Kkuy/r7u8m+bcke1bVLvM+d0jylCQfXPHYjyZ55jz93NwS3Nd9Pi+qqrOq6qyrr776Nv5VAAAAWGZLF85nD03ylu7eJ8m1SV48L7++uw/s7ncneUuSl3T3I5O8PMmb5m2OTXJcdz8qybdu5TgnJfm1qjqnqv62qh6RJN394yTvT/Kb83bPTnJad1+34rHvTnJEVW2XZJ8kZ6zvAN39lu5e091rdt55503+AwAAAHD7sazh/Bvdffo8/a4kB87T70mSqrprkscneW9VnZPkzZl6wZPkgNzSi/2T+8LXp7svy/SPgFcmuSnJJ6vq4Hn1ykvbV17SfvNjz0uyOlOv+Ud+vqcHAADAHcmq0Q24jXoD8z+Yf98pyTXdvd8mPn7DB+q+IdMl6h+tqiuTHJrkk0lOT7JLVe2b6R8B696DniQfSvK6JAclufemHhMAAIA7lmXtOX9gVT1unn5uks+uXNnd1ya5pKoOS5Ka7DuvPj23BOkjN3aQqtq/qnadp++U6fL0r83H6EyXvZ+Q5CPdff16dvG2JK/p7rU/5/MDAADgDmRZw/kFSZ5fVecluVeS49azzZFJjqqqc5N8Kckh8/JjkhxdVWcm2elWjnPfJB+uqvOTnJfkxiRvWLH+xCT7Zrq//GfMA8gdu2lPCQAAgDuqmjqAl0dVrU5ySnfvPbgpm92aNWv6rLPOGt0MAAAAtoCqOru716xv3bL2nAMAAMDtxtINCNfdlybZrL3mVfXw/OzI7Td092M253EAAABgfZYunG8J84BtGxrZHQAAALYol7UDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYMI5AAAADCacAwAAwGDCOQAAAAwmnAMAAMBgwjkAAAAMJpwDAADAYNXdo9vArKquS3LR6Hawye6T5NujG8EmUavloVbLRb2Wh1otD7VaHmq1XBalXr/U3Tuvb8Wqrd0SNuqi7l4zuhFsmqo6S72Wg1otD7VaLuq1PNRqeajV8lCr5bIM9XJZOwAAAAwmnAMAAMBgwvliecvoBvBzUa/loVbLQ62Wi3otD7VaHmq1PNRquSx8vQwIBwAAAIPpOQcAAIDBhHMAAAAYTDhfEFX19Kq6qKq+UlWvGN0eblFVb6uqq6rq/BXL7lVVn6iqL8+/7zmyjUyq6gFVdVpVXVBVX6qqY+bl6rWAqmq7qvp8VZ071+vV8/Ldq+qMuV7vqao7j24rk6rapqq+WFWnzPNqtYCq6tKqWltV51TVWfMy58EFVVX3qKqTq+rC+f3rceq1eKrqofNr6uafa6vqpWq1mKrqZfNni/Or6sT5M8fCv2cJ5wugqrZJ8sYkz0jysCTPraqHjW0VK7wjydPXWfaKJJ/s7ock+eQ8z3g3Jvnj7t4ryWOTHD2/ltRrMd2Q5MndvW+S/ZI8vaoem+Rvkvz9XK/vJjlqYBv5acckuWDFvFotrid1934rvtPXeXBxHZvkY929Z5J9M73G1GvBdPdF82tqvySPTPLDJB+IWi2cqrp/kj9Msqa7906yTZIjsgTvWcL5Ynh0kq9091e7+0dJ3p3kkMFtYtbdn07ynXUWH5LkhHn6hCSHbtVGsV7dfUV3f2Gevi7TB5z7R70WUk++P89uO/90kicnOXlerl4Loqp2S/LMJMfP8xW1WibOgwuoqu6e5AlJ3pok3f2j7r4m6rXoDk5ycXd/LWq1qFYl2b6qViXZIckVWYL3LOF8Mdw/yTdWzF82L2Nx3a+7r0imQJjkvoPbwzqqanWSRyQ5I+q1sObLpM9JclWSTyS5OMk13X3jvInz4eL4hyR/kuSmef7eUatF1UlOraqzq+pF8zLnwcX0oCRXJ3n7fMvI8VW1Y9Rr0R2R5MR5Wq0WTHd/M8nrknw9Uyj/XpKzswTvWcL5Yqj1LPMdd3AbVdVdk7wvyUu7+9rR7WHDuvvH8yWCu2W6imiv9W22dVvFuqrqWUmu6u6zVy5ez6ZqtRgO6O79M90ud3RVPWF0g9igVUn2T3Jcdz8iyQ/isuiFNt+n/Owk7x3dFtZvvu//kCS7J9k1yY6ZzofrWrj3LOF8MVyW5AEr5ndLcvmgtrBprqyqXZJk/n3V4PYwq6ptMwXzf+7u98+L1WvBzZdx/kemsQLuMV+GljgfLooDkjy7qi7NdOvVkzP1pKvVAuruy+ffV2W6J/bRcR5cVJcluay7z5jnT84U1tVrcT0jyRe6+8p5Xq0Wz1OSXNLdV3f3/yV5f5LHZwnes4TzxXBmkofMIwjeOdOlMh8a3CY27kNJnj9PPz/Jvw5sC7P5Hti3Jrmgu/9uxSr1WkBVtXNV3WOe3j7Tm+kFSU5L8px5M/VaAN39yu7erbtXZ3qP+vfuPjJqtXCqasequtvN00meluT8OA8upO7+VpJvVNVD50UHJ/mvqNcie25uuaQ9UatF9PUkj62qHebPhje/rhb+Pau6F643/w6pqn41Uy/ENkne1t2vHdwkZlV1YpKDktwnyZVJ/jzJB5OclOSBmU4Ah3X3uoPGsZVV1YFJPpNkbW65L/ZPM913rl4Lpqr2yTQgyzaZ/ll8Une/pqoelKl39l5Jvpjked19w7iWslJVHZTk5d39LLVaPHNNPjDPrkryL9392qq6d5wHF1JV7ZdpoMU7J/lqkhdmPidGvRZKVe2QaZyoB3X39+ZlXlsLaP561sMzfZPPF5P8TqZ7zBf6PUs4BwAAgMFc1g4AAACDCecAAAAwmHAOAAAAgwnnAAAAMJhwDgAAAIMJ5wDAT1TV57by8VZX1W9tzWMCwCISzgGAn+jux2+tY1XVqiSrkwjnANzh+Z5zAOAnqur73X3XqjooyauTXJlkvyTvT7I2yTFJtk9yaHdfXFXvSHJ9kl9Jcr8kf9Tdp1TVdkmOS7ImyY3z8tOq6gVJnplkuyQ7JtkhyV5JLklyQpIPJHnnvC5J/qC7Pze35y+SfDvJ3knOTvK87u6qelSSY+fH3JDk4CQ/TPLXSQ5Kcpckb+zuN2/mPxcAbDarRjcAAFhY+2YKzt9J8tUkx3f3o6vqmCQvSfLSebvVSZ6YZI8kp1XVg5McnSTd/fCq2jPJqVX1y/P2j0uyT3d/Zw7dL+/uZyVJVe2Q5KndfX1VPSTJiZkCfpI8ItM/AS5PcnqSA6rq80nek+Tw7j6zqu6e5H+THJXke939qKq6S5LTq+rU7r5kC/ydAOAXJpwDABtyZndfkSRVdXGSU+fla5M8acV2J3X3TUm+XFVfTbJnkgOTvD5JuvvCqvpakpvD+Se6+zsbOOa2Sd5QVfsl+fGKxyTJ57v7srk952T6p8D3klzR3WfOx7p2Xv+0JPtU1XPmx+6U5CGZeugBYOEI5wDAhtywYvqmFfM35ac/Q6x7j1wnqY3s9wcbWfeyTJfS75tpbJzrN9CeH89tqPUcP/Pyl3T3xzdyLABYGAaEAwB+UYdV1Z2qao8kD0pyUZJPJzkySebL2R84L1/XdUnutmJ+p0w94Tcl+e0k29zKsS9Msut833mq6m7zQHMfT/L7VbXtzW2oqh03sh8AGErPOQDwi7ooyacyDQj3e/P94m9K8k9VtTbTgHAv6O4bqn6mQ/28JDdW1blJ3pHkTUneV1WHJTktG+9lT3f/qKoOT/L6qto+0/3mT0lyfKbL3r9Q00GvTnLo5niyALAlGK0dALjN5tHaT+nuk0e3BQCWmcvaAQAAYDA95wAAADCYnnMAAAAYTDgHAACAwYRzAAAAGEw4BwAAgMGEcwAAABjs/wEIeAf+MNA2DwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#lgb\n",
    "#交差検証\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "m_type = \"lgb\"\n",
    "\n",
    "params = {\"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.01,\n",
    "          #'max_depth': 7,\n",
    "          #'num_leaves': 31,\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          #'reg_alpha': 0,\n",
    "          #'reg_lambda': 0,\n",
    "         }\n",
    "\n",
    "#data\n",
    "y = MVTable[\"target\"]\n",
    "X = MVTable.drop(['target','image_name'], axis=1)\n",
    "X_test = TestTable.drop(['image_name'], axis=1)\n",
    "\n",
    "#lgb(決定木)で学習実行\n",
    "result_dict = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type=m_type, eval_metric='auc',\n",
    "                                         plot_feature_importance=True, verbose=1000, early_stopping_rounds=200, n_estimators=10000)\n",
    "\n",
    "\n",
    "csv_file_path = Output + 'submit/sub_blending.csv'\n",
    "sub = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "sub.target = result_dict[\"prediction\"][:,1]\n",
    "sub.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sun Jul 19 15:54:39 2020\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'subsample_freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-c4976f46786d>\u001b[0m in \u001b[0;36mtrain_model_classification\u001b[0;34m(X, X_test, y, params, folds, model_type, eval_metric, columns, plot_feature_importance, model, verbose, early_stopping_rounds, n_estimators)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n\u001b[0;32m---> 94\u001b[0;31m                                       loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'subsample_freq'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#xgb\n",
    "#交差検証\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "m_type = \"cat\"\n",
    "\n",
    "params = {\"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.01,\n",
    "          #'max_depth': 7,\n",
    "          #'num_leaves': 31,\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          #'reg_alpha': 0,\n",
    "          #'reg_lambda': 0,\n",
    "         }\n",
    "\n",
    "#data\n",
    "y = MVTable[\"target\"]\n",
    "X = MVTable.drop(['target','image_name'], axis=1)\n",
    "X_test = TestTable.drop(['image_name'], axis=1)\n",
    "\n",
    "#lgb(決定木)で学習実行\n",
    "result_dict = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type=m_type, eval_metric='auc',\n",
    "                                         plot_feature_importance=True, verbose=1000, early_stopping_rounds=200, n_estimators=10000)\n",
    "\n",
    "\n",
    "csv_file_path = Output + 'submit/sub_blending.csv'\n",
    "sub = pd.read_csv(SIIM_ISIC_Melanoma_Classification + 'sample_submission.csv')\n",
    "\n",
    "sub.target = result_dict[\"prediction\"][:,1]\n",
    "sub.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355k/355k [00:03<00:00, 91.7kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to SIIM-ISIC Melanoma Classification"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # 認証を通す\n",
    "message = \"blending\"\n",
    "competition_id = 'siim-isic-melanoma-classification'\n",
    "api.competition_submit(csv_file_path, message, competition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
